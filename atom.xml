<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhisheng的博客</title>
  
  <subtitle>坑要一个个填，路要一步步走！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.54tianzhisheng.cn/"/>
  <updated>2020-08-13T13:38:53.000Z</updated>
  <id>http://www.54tianzhisheng.cn/</id>
  
  <author>
    <name>zhisheng</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink 精进学习知识星球内容整理</title>
    <link href="http://www.54tianzhisheng.cn/2020/08/09/flink-zsxq/"/>
    <id>http://www.54tianzhisheng.cn/2020/08/09/flink-zsxq/</id>
    <published>2020-08-08T16:00:00.000Z</published>
    <updated>2020-08-13T13:38:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>整理自己发在知识星球和公众号的系列文章，方便查找。</p><a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p><br />进知识星球的小伙伴有的是刚接触 Flink 的，有的是根本没接触过的<img src="https://cdn.nlark.com/yuque/0/2020/png/311057/1596964608579-e55b42ad-54e1-4390-bdad-1c290b1476aa.png#align=left&amp;display=inline&amp;height=20&amp;margin=%5Bobject%20Object%5D&amp;originHeight=48&amp;originWidth=48&amp;size=0&amp;status=done&amp;style=none&amp;width=20" alt="">，有的是已经用 Flink 很久的，所以很难适合所有的口味。<br /><br><br />我一向认为对一门技术的学习方式应该是：<br /></p><ul><li>了解（知道它的相关介绍、用处）</li><li>用（了解常用 API）</li><li>用熟（对常用 API 能够用熟来，并了解一些高级 API）</li><li>解决问题（根据业务场景遇到的问题能够定位问题并解决）</li><li>看源码（深入源码的实现，此种情况主要是兴趣爱好驱动）</li></ul><p><br />这里先把《从 0 到 1 学习 Flink》的系列文章给列出来，我觉得从这个系列文章的顺序来学习起码可以让你先达到第四个步骤，如果有什么疑问或者文章不足之处欢迎指出。</p><p><a name="kPvuh"></a></p><h3 id="《从-0-到-1-学习-Flink》系列"><a href="#《从-0-到-1-学习-Flink》系列" class="headerlink" title="《从 0 到 1 学习 Flink》系列"></a>《从 0 到 1 学习 Flink》系列</h3><ul><li><a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从 0 到 1 学习 —— Apache Flink 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从 0 到 1 学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从 0 到 1 学习 —— Flink 配置文件详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从 0 到 1 学习 —— Flink JobManager 高可用性配置</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从 0 到 1 学习 —— Data Source 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从 0 到 1 学习 —— 如何自定义 Data Source ？</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从 0 到 1 学习 —— Data Sink 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从 0 到 1 学习 —— 如何自定义 Data Sink ？</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从 0 到 1 学习 —— Flink Data transformation(转换)</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— 介绍Flink中的Stream Windows</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239105&amp;idx=1&amp;sn=be0c2c5bd4396e94561e8aa08d98625c&amp;chksm=8f5a1addb82d93cb184b782ac059c61230dc2f9b18604eb71542385647a094a21c30c5732447&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 流计算编程–看看别人怎么用 Session Window</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239498&amp;idx=2&amp;sn=1b3d429f615d9bd9b0226f8737671546&amp;chksm=8f5a1856b82d9140c6ccc90e8ef1aeb7654da8187122a6e1722225b305c2c5a0534eed6ae992&amp;token=1858295303&amp;lang=zh_CN#rd">这一次带你彻底搞懂 Flink Watermark</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从 0 到 1 学习 —— Flink 中几种 Time 详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从 0 到 1 学习 —— Flink 项目如何运行？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从 0 到 1 学习 —— Flink parallelism 和 Slot 介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从 0 到 1 学习 —— Flink 写入数据到 ElasticSearch</a> </li><li><a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从 0 到 1 学习 —— </a><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238504&amp;idx=1&amp;sn=7756ce7af39b2068eb72ced6f67cf992&amp;chksm=8f5a0474b82d8d6202674cb5b6eafc35f5e006111bc94c19a900da12a5ce416c1731a924055a&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 实时写入数据到 ElasticSearch 性能调优</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从 0 到 1 学习 —— Flink 写入数据到 Kafka</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从 0 到 1 学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从 0 到 1 学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从 0 到 1 学习 —— 你上传的 jar 包藏到哪里去了?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— Flink 中如何管理配置？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从 0 到 1 学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint 轻量级分布式快照</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/uRN3VfA">使用 Prometheus Grafana 监控 Flink</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/yVnaYR7">使用 InflubDB 和 Grafana 监控 Flink JobManager TaskManager 和作业</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/vbIMJAu">从0到1搭建一套 Flink 监控系统</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="http://www.54tianzhisheng.cn/2019/11/23/flink-metrics/">详解 Flink Metrics 原理与监控实战</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/RJqj6YV">Flink 读取 Kafka 商品数据后写入到 Redis</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 —— </a><a href="https://t.zsxq.com/ny3Z3rb">一文搞懂 Flink 网络流控与反压机制</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/UVfqfae">一文搞懂Flink内部的Exactly Once和At Least Once</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/eYNBaAa">Flink On K8s</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://t.zsxq.com/zjQvjeM">Apache Flink 是如何管理好内存的?</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650241012&amp;idx=1&amp;sn=1fc2d3848c957f759036a5d2a55ae09f&amp;chksm=8f5a1da8b82d94be63cbd12d4ceac54442b353f3d1453d02de72898e7b4af7e0f1affca1d568&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 参数配置和常见参数调优</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239999&amp;idx=1&amp;sn=5183e97f78d35b59cb6cdc318de114a7&amp;chksm=8f5a19a3b82d90b59fe7cf9bf894f37245f722ed342fcc3a7fa046fe28cb8d4d6643c9c1cc84&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 状态生存时间（State TTL）机制的底层实现</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239366&amp;idx=2&amp;sn=7489bf383e2deb3921daf6480887e090&amp;chksm=8f5a1bdab82d92cc6dcdf71ea51663b7d647f2259fe6e27b5244a66891c0156f6dfe233a7fe8&amp;token=1858295303&amp;lang=zh_CN#rd">Flink State 最佳实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239077&amp;idx=2&amp;sn=39bedd4f5a381f06a133acae290edd86&amp;chksm=8f5a1a39b82d932fb1000ad1f45492b1b42c1eec3bb40ec40198bbc71d3e03b2134c2d242f7f&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用大状态时的一点优化</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239265&amp;idx=2&amp;sn=cbc2bda736883cd9f695893a19e50544&amp;chksm=8f5a1b7db82d926b20f0e2740303227da5b47bac2a661ccd61257c18b7d26b8207eab045abff&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用 broadcast 实现维表或配置的实时更新</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238830&amp;idx=2&amp;sn=8791a75eb00b50f3a687527fe9e10667&amp;chksm=8f5a0532b82d8c2443cd6c0f9f0ddaff0be73cfda21a1db0a66cf7c586eed4f9b77bf3eb7b68&amp;token=1858295303&amp;lang=zh_CN#rd">Spark/Flink广播实现作业配置动态更新</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239009&amp;idx=2&amp;sn=2c63bcba31f91a15ca2e2cf3cacf5566&amp;chksm=8f5a1a7db82d936bc6114dacfed17ca9ad4a92eab2c941ad35bfd90aefb67d35f741ace80563&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 清理过期 Checkpoint 目录的正确姿势</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238962&amp;idx=1&amp;sn=b66c4940b1243fa74343650d1b3dc93a&amp;chksm=8f5a05aeb82d8cb8453aee1435114a0fcfe50dc219fd1b3dfdf074d39f8ca6e7de802d5bae23&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 状态管理与 Checkpoint 机制</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/">Flink 能否动态更改 Checkpoint 配置</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/">Flink Checkpoint 问题排查实用指南</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238609&amp;idx=2&amp;sn=ad36eb812f8d487895300d0cfe2b1604&amp;chksm=8f5a04cdb82d8ddb73c8624c20a7875f197f67bcf5569e1077f4df49107e494aa2c277beaae8&amp;token=1858295303&amp;lang=zh_CN#rd">Apache Flink 管理大型状态之增量 Checkpoint 详解</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238515&amp;idx=2&amp;sn=980e495c5373e64ef249c1ab1b6e072c&amp;chksm=8f5a046fb82d8d79032fffb76cabdbcccf60518ec54451ae4f2db6a5a89ffb0ed3ffe8132e4c&amp;token=1858295303&amp;lang=zh_CN#rd">深入理解 Flink 容错机制</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239239&amp;idx=2&amp;sn=8ea3e361350f7e5475d2f5acab24fe48&amp;chksm=8f5a1b5bb82d924d8d3b091cd8c6f756f984de3fcec945f08d59973b01454e86c73684982c8c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 使用 connect 实现双流匹配</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239115&amp;idx=2&amp;sn=f6ff30687c0ecaf2e10b23434674257e&amp;chksm=8f5a1ad7b82d93c1f2f492f70ea5257671eba44f48c00c1be8008310af15ad857c66fbbbc2cf&amp;token=1858295303&amp;lang=zh_CN#rd">Flink流计算编程–Flink扩容、程序升级前后的思考</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239150&amp;idx=2&amp;sn=738a83a0c4981ac851c077d27fc390bb&amp;chksm=8f5a1af2b82d93e42d24119e8563a6ec50968e5c3d9bce7f075777baff37f63583a169055a6d&amp;token=1858295303&amp;lang=zh_CN#rd">Flink HDFS Sink 如何保证 exactly-once 语义</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/08/24/Flink-Connector/">Flink Connector 深度解析</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">如何使用 Side Output 来分流？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 不可以连续 Split(分流)？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238825&amp;idx=1&amp;sn=28da5840a8c22c7c675d7d4987824f33&amp;chksm=8f5a0535b82d8c232681d2bc935bf99fa7c3d05f0406c184f71722e53a5209b2f19816f31ae1&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 全链路端到端延迟的测量方法</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238573&amp;idx=2&amp;sn=7d2488578fc93bfeaa58ddb4279925ce&amp;chksm=8f5a0431b82d8d272250167dd261369a9ed824f94a1edc9ac49e73f16368b29b1e538bbfc62a&amp;token=1858295303&amp;lang=zh_CN#rd">Flink on Yarn / K8s 原理剖析及实践</a></li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238455&amp;idx=2&amp;sn=1b8cec83df9c72a4dbe56b11d6d3e7f0&amp;chksm=8f5a07abb82d8ebddb349f2f48cae697a6a39a9bab16b80fba4850bb325ee2010c6df0cf8599&amp;token=1858295303&amp;lang=zh_CN#rd">如何使用 Kubernetes 部署 Flink 应用</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238685&amp;idx=2&amp;sn=b023313ecbaf30d9a66e75636c6dfa7a&amp;chksm=8f5a0481b82d8d970433c857c11a4e5af971f21d6c9c4e70eb619cfeb2b871a344b3a7764830&amp;token=1858295303&amp;lang=zh_CN#rd">一张图轻松掌握 Flink on YARN 基础架构与启动流程</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238700&amp;idx=2&amp;sn=a391c6cf1f1e4d6e22f6453a4033f575&amp;chksm=8f5a04b0b82d8da68459f17ea2105b9f5f130b5aff498579e6cf4cb426cd6109a3a2462f1f5c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink on YARN 常见问题与排查思路</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238695&amp;idx=2&amp;sn=222d820e2a0485ab31811b6ab774b0b2&amp;chksm=8f5a04bbb82d8dad2650a4e751743d950a64082f2b7ba7796f8d35a936c076453b1cf3f0abbb&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 单并行度内使用多线程来提高作业性能</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238477&amp;idx=1&amp;sn=fe053b103d62978274a6163110ee7b7a&amp;chksm=8f5a0451b82d8d471d071e3260eb4acb20e7e3633d36bcd557f43d1065842305e183f0f9a0df&amp;token=1858295303&amp;lang=zh_CN#rd">Flink中资源管理机制解读与展望</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从 0 到 1 学习 ——</a> <a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238405&amp;idx=1&amp;sn=a262bef27509f0017688e16374ad44c0&amp;chksm=8f5a0799b82d8e8f99a365822bc678b77ced5dc03c3c4817a4f8635d9b77e96e0ac258e88ffa&amp;token=1858295303&amp;lang=zh_CN#rd">Flink Back Pressure(背压)是怎么实现的？有什么绝妙之处？</a> </li></ul><p><br /><br><a name="0yw1g"></a></p><h3 id="Flink-SQL"><a href="#Flink-SQL" class="headerlink" title="Flink SQL"></a>Flink SQL</h3><ul><li><a href="https://wx.zsxq.com/dweb2/index/tags/Flink%20SQL/828214288542">知识星球 Flink 标签所有内容</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240680&amp;idx=1&amp;sn=4046b105912524306ca4ceb4a598a251&amp;chksm=8f5a1cf4b82d95e251b6caf14715d992d213219006b9bddb7883cdd203960fe6eaf5f796af47&amp;token=1858295303&amp;lang=zh_CN#rd">Java SPI 机制在 Flink SQL 中的应用</a> </li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 通过 DDL 和 SQL 来实现读取 Kafka 数据并处理后将数据写回 Kafka</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink SQL 实战——读取Kafka数据处理后写入 ElasticSearch 6 和 7 两种版本</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239141&amp;idx=2&amp;sn=4b441f383f479215ebd5e1f5bb8a650f&amp;chksm=8f5a1af9b82d93ef123a7789811551fe5d7d3e0360a7b48ead90befdbdf8b75ce7ad2cf1629c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 聚合性能优化 – MiniBatch 分析</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239126&amp;idx=1&amp;sn=10b51d1409f5b3461294139aa5cc7e9e&amp;chksm=8f5a1acab82d93dcd301ab695419ce829e7623c708d8cc8ed3099c7d00882f0211431b3c68e2&amp;token=1858295303&amp;lang=zh_CN#rd">Flink流计算编程：双流中实现Inner Join、Left Join与Right Join</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238819&amp;idx=2&amp;sn=97f1b2ddca379a28e390b21858bfc05b&amp;chksm=8f5a053fb82d8c29881f4a788cd254322223cb39299c6211ec93bdccae13162dd023a38dea1f&amp;token=1858295303&amp;lang=zh_CN#rd">Flink SQL 如何实现数据流的 Join？</a> </li></ul><p><a name="86fd4aa6"></a></p><h3 id="《Flink-各版本功能特性解读》"><a href="#《Flink-各版本功能特性解读》" class="headerlink" title="《Flink 各版本功能特性解读》"></a>《Flink 各版本功能特性解读》</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a> </li><li><a href="https://t.zsxq.com/rFEUVBA">Flink 1.11 日志文件该如何配置？</a> </li><li><a href="https://t.zsxq.com/a27yRJu">Flink 1.11 Release 文档解读</a></li><li><a href="https://t.zsxq.com/NNNVj2j">Apache Flink 1.10 TaskManager 内存管理优化</a> </li><li><a href="https://t.zsxq.com/3BEemeq">Flink 版本升级方案</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240568&amp;idx=2&amp;sn=49a5e1418e6974584f404de03a6bc9d2&amp;chksm=8f5a1c64b82d957287c1fefa6bf89a0da3c596c9b33f8c289e47aaf2c82d7aafeabe3785ccbe&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 1.11 新特性详解:【非对齐】Unaligned Checkpoint 优化高反压</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240506&amp;idx=2&amp;sn=de3023a00224753985258156174f7103&amp;chksm=8f5a1fa6b82d96b0592606cdf12ced520d108dac8c2bc867f9fb16ed1243cff3c8418cad68a8&amp;token=1858295303&amp;lang=zh_CN#rd">千呼万唤，Apache Flink 1.11.0 新功能正式介绍</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239638&amp;idx=1&amp;sn=24f51ee03ca45304aa46ebeda2ac95b1&amp;chksm=8f5a18cab82d91dcd8dd1d3953f2979ccc83f86256eacb286f8c6f52e76c185ca084ebbe6719&amp;token=1858295303&amp;lang=zh_CN#rd">重磅！Apache Flink 1.11 会有哪些牛逼的功能</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239034&amp;idx=2&amp;sn=484ee31a60a14245bff0c07260537398&amp;chksm=8f5a1a66b82d93700626252ecab8766d19900543eb1e65c74ee9c99eb3c91d7f3fc944a90807&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 1.10 新特性研究</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/22/flink-1.9/">修改代码150万行！Apache Flink 1.9.0做了这些重大修改！</a> </li></ul><p><br /></p><p><a name="fGimX"></a></p><h3 id="《Flink-在大厂的实践与应用》"><a href="#《Flink-在大厂的实践与应用》" class="headerlink" title="《Flink 在大厂的实践与应用》"></a>《Flink 在大厂的实践与应用》</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">携程——如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a> </li><li><a href="https://t.zsxq.com/v7QzNZ3">数据仓库、数据库的对比介绍与实时数仓案例分享</a> </li><li><a href="https://t.zsxq.com/MniUnqb">基于 Apache Flink 的监控告警系统 文章</a></li><li><a href="http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/">基于 Apache Flink 的监控告警系统 视频</a></li><li><a href="https://t.zsxq.com/FMRNvr7">如何利用Flink Rest API 监控满足生产环境非常刚需的需求</a></li><li><a href="https://t.zsxq.com/NvnuRNj">无流量 Flink 作业告警</a> </li><li><a href="https://t.zsxq.com/MRvzfAA">Apache Flink 维表关联实战</a> </li><li><a href="https://t.zsxq.com/2NbQFqF">如何利用 Flink 实时将应用 Error 日志告警？</a> </li><li><a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里 的实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240828&amp;idx=2&amp;sn=d05803fdf6f436fe1e61b6bc60eba375&amp;chksm=8f5a1d60b82d94769b7e787773f82e7d339dd495d4d46bd8916585212cbbda145fbf99e731b9&amp;token=1858295303&amp;lang=zh_CN#rd">基于 Flink 搭建实时个性化营销平台？</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650240481&amp;idx=1&amp;sn=1f33c26869d87d0093232c5b70a0c02a&amp;chksm=8f5a1fbdb82d96ab07611d1a18d12645b2b0c0b339e27338c9c7203045b06d838ae88f31ae1d&amp;token=1858295303&amp;lang=zh_CN#rd">基于 Flink 和 Drools 的实时日志处理</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239383&amp;idx=1&amp;sn=10933a52ddf0d7da1f8714076721c93a&amp;chksm=8f5a1bcbb82d92dd6fac7130b8de1505d6333619f7f47fc85fda53825191a24f88b8ccc922b2&amp;token=1858295303&amp;lang=zh_CN#rd">新一代大数据实时数据架构到底长啥样</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239356&amp;idx=1&amp;sn=01af257bbe0f0ac4e55120fd223081bf&amp;chksm=8f5a1b20b82d92361e759118362e832bfd30ff1a47530494122ee880a47f3faf7c49bc55ba4b&amp;token=1858295303&amp;lang=zh_CN#rd">从 Spark Streaming 到 Apache Flink：bilibili 实时平台的架构与实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239347&amp;idx=1&amp;sn=a5793f0e4f832ae6eb7d9583e1f4ec91&amp;chksm=8f5a1b2fb82d92395ef6262c1217dbda64a1601103c6d3672a35d760f58148db0febcb62d7ae&amp;token=1858295303&amp;lang=zh_CN#rd">日均万亿条数据如何处理？爱奇艺实时计算平台这样做</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239313&amp;idx=1&amp;sn=ea9865bb3fe191ef0c1839638e46f866&amp;chksm=8f5a1b0db82d921bae1a6cf70f008b7486f5f8f7d72f14e90f9ef0d00ba15b588d224340e732&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 流批一体的实践与探索</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239311&amp;idx=2&amp;sn=8045b336e524067172ecd407ae35898a&amp;chksm=8f5a1b13b82d920556ab98abe5a2c02edd3672299884b2ef99c8efde49465483854e9cf96d68&amp;token=1858295303&amp;lang=zh_CN#rd">趣头条基于 Flink+ClickHouse 构建实时数据分析平台</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239271&amp;idx=1&amp;sn=490e5ce1363fe73ef4b9b785bdaee46f&amp;chksm=8f5a1b7bb82d926dcfcf9515ee36a28bbee67c3aa15490a2889ded545a68f37a12258348f53c&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 维表关联多种方案对比</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/">美团点评基于 Flink 的实时数仓平台实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/">基于 Apache Flink 的大规模准实时数据分析平台</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/">阿里巴巴 Flink 踩坑经验：如何大幅降低 HDFS 压力？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/">58 同城基于 Flink 的千亿级实时计算平台架构实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/11/30/flink-aqniu/">基于 Flink 构建关联分析引擎的挑战和实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/25/flink-didi/">滴滴实时计算发展之路及平台架构实践</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/23/flink-ebay/">如何使用 Flink 每天实时处理百亿条日志？</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/08/20/Flink-meituan-dw/">美团点评基于 Flink 的实时数仓建设实践</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238820&amp;idx=1&amp;sn=652c34aff71827174011e999caaad037&amp;chksm=8f5a0538b82d8c2e6203f921cf2fdd0ceab0bc54e9bdd2696036887ffc1cbeb6f8f25bfe0df1&amp;token=1858295303&amp;lang=zh_CN#rd">基于Kafka+Flink+Redis的电商大屏实时计算案例</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238731&amp;idx=1&amp;sn=706a72f5ad2e4c3bb1ce22980886af46&amp;chksm=8f5a0557b82d8c41312f88d1baf3feb1dca719805645938e2e1cc691402b18c65215d73ef43b&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 在小红书推荐系统中的应用</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238450&amp;idx=1&amp;sn=109ecd71a60b1f96c6d8a020e08ab65e&amp;chksm=8f5a07aeb82d8eb8bbd8bfb10febc977a42df7633cee79162c5300da0ce40ed93cabedb59b05&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 实战 | 贝壳找房基于Flink的实时平台建设</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238345&amp;idx=2&amp;sn=f62f1dca57a5782bc3c68e63699ce4a4&amp;chksm=8f5a07d5b82d8ec36f3931bb7da3fc24c4a2bc0ecf60b686cc3fb33c45eba02aca833c4a4cb9&amp;token=1858295303&amp;lang=zh_CN#rd">Flink 在趣头条的应用与实践</a> </li></ul><p><br /><br><br /></p><p><a name="0ycqX"></a></p><h3 id="《Flink-实战与性能优化》专栏部分文章"><a href="#《Flink-实战与性能优化》专栏部分文章" class="headerlink" title="《Flink 实战与性能优化》专栏部分文章"></a>《Flink 实战与性能优化》专栏部分文章</h3><p><br />因为这个专栏是一开始自己写的，当时还没有和任何一家公司签协议，所以当时就是想放在知识星球的，后面有公司联系，才有完整的专栏文章诞生出来，否则自己也不知道是否可以坚持写完这个系列，所以后面合作开这个专栏后新写的文章就没放在星球了，因为签了合同的，是不能够在其他平台公开的，这里希望大家可以体谅，但是已经早公开的依旧不会删除掉的，有如下这些文章：<br /></p><ul><li><a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹实时计算框架Flink</a> </li><li><a href="https://t.zsxq.com/fqfuVRR">《大数据重磅炸弹——实时计算引擎 Flink》开篇词</a> </li></ul><p><strong>预备篇</strong>：</p><ul><li><a href="https://t.zsxq.com/emMBaQN">你公司到底需不需要引入实时计算引擎？</a> </li><li><a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a> </li><li><a href="https://t.zsxq.com/eAyRz7Y">别再傻傻的分不清大数据框架Flink、Blink、Spark Streaming、Structured Streaming和Storm之间的区别了</a> </li><li><a href="https://t.zsxq.com/iaMJAe6">Flink 环境准备看这一篇就够了</a>  </li><li><a href="https://t.zsxq.com/iaMJAe6">一文讲解从 Flink 环境安装到源码编译运行</a>  </li><li><a href="https://t.zsxq.com/eaIIiAm">通过 WordCount 程序教你快速入门上手 Flink</a> </li><li><a href="https://t.zsxq.com/Vnq72jY">Flink 如何处理 Socket 数据及分析实现过程</a> </li><li><a href="https://t.zsxq.com/BiyvFUZ">Flink job 如何在 Standalone、YARN、Mesos、K8S 上部署运行？</a>   </li></ul><p><br /><strong>基础篇 :</strong></p><ul><li><a href="https://t.zsxq.com/fufUBiA">Flink 数据转换必须熟悉的算子（Operator)</a>   </li><li><a href="https://t.zsxq.com/r7aYB2V">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a>  </li><li><a href="https://t.zsxq.com/byZbyrb">如何使用 Flink Window 及 Window 基本概念与实现原理</a>   </li><li><a href="https://t.zsxq.com/VzNBi2r">如何使用 DataStream API 来处理数据？</a>  </li><li><a href="https://t.zsxq.com/Iub6IQf">Flink WaterMark 详解及结合 WaterMark 处理延迟数据</a> </li></ul><p><a name="5CT86"></a></p><h3 id="《Flink-源码解析文章》"><a href="#《Flink-源码解析文章》" class="headerlink" title="《Flink 源码解析文章》"></a>《Flink 源码解析文章》</h3><ul><li><a href="https://t.zsxq.com/UZfaYfE">Flink 源码解析 —— 源码编译运行</a>   </li><li><a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— 项目结构一览</a>   </li><li><a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— </a><a href="https://t.zsxq.com/fEQN7Aa">Flink 源码的结构和其对应的功能点</a></li><li><a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析—— local 模式启动流程</a>   </li><li><a href="https://t.zsxq.com/QZVRZJA">Flink 源码解析 —— standalonesession 模式启动流程</a>  </li><li><a href="https://t.zsxq.com/u3fayvf">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a>   </li><li><a href="https://t.zsxq.com/MnQRByb">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a>   </li><li><a href="https://t.zsxq.com/YJ2Zrfi">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a>  </li><li><a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a>  </li><li><a href="https://t.zsxq.com/naaMf6y">Flink 源码解析 —— 如何获取 JobGraph？</a>  </li><li><a href="https://t.zsxq.com/qRFIm6I">Flink 源码解析 —— 如何获取 StreamGraph？</a>  </li><li><a href="https://t.zsxq.com/2VRrbuf">Flink 源码解析 —— Flink JobManager 有什么作用？</a>  </li><li><a href="https://t.zsxq.com/RZbu7yN">Flink 源码解析 —— Flink TaskManager 有什么作用</a>   </li><li><a href="https://t.zsxq.com/3JQJMzZ">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a>  </li><li><a href="https://t.zsxq.com/eu7mQZj">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a>  </li><li><a href="https://t.zsxq.com/ynQNbeM">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a>  </li><li><a href="https://t.zsxq.com/JaQfeMf">Flink 源码解析 —— 深度解析 Flink 序列化机制</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-core 源码解析</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-datadog 源码解析</a>   </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-dropwizard 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-graphite 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-influxdb 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-jmx 源码解析</a> </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-slf4j 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-statsd 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-prometheus 源码解析</a>  </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink 注解源码解析</a> </li><li><a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 ——</a> <a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 实战</a> </li></ul><p><br /></p><p><a name="8rxG3"></a></p><h3 id="《Flink-自己录制过的视频》"><a href="#《Flink-自己录制过的视频》" class="headerlink" title="《Flink 自己录制过的视频》"></a>《Flink 自己录制过的视频》</h3><ul><li><a href="https://t.zsxq.com/RJqj6YV">Flink 整合 Apollo 动态更新配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 整合 Nacos 动态更新配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 专栏的开篇词</a> </li><li><a href="https://t.zsxq.com/RJqj6YV">你公司到底需不需要引入实时计算引擎</a></li><li><a href="https://t.zsxq.com/RJqj6YV">一文让你彻底了解大数据实时计算框架 Flink</a></li><li><a href="https://t.zsxq.com/RJqj6YV">别再傻傻的分不清大数据框架 Flink、Blink、Spark Streaming、Structured Streaming 和 Storm 之间的区别了</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink环境准备</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink环</a><a href="https://t.zsxq.com/RJqj6YV">境</a><a href="https://t.zsxq.com/RJqj6YV">安装</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink WordCount 程序入门上手及分析实现过程</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 如何处理 Socket 数据及分析实现过程</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a></li><li><a href="https://t.zsxq.com/RJqj6YV">如何使用 Flink Window 及 Window 基本概念与实现原理</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink_Window组件深度讲解和如何自定义Window</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 读取 Kafka 商品数据后写入到 Redis</a></li><li><a href="https://t.zsxq.com/RJqj6YV">基于 Apache Flink 的监控告警系统</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink源码解析01——源码编译运行</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析02——源码结构一览</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析03——源码阅读规划</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析04——flink-example模块源码结构</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析05——flink-example模块源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析06——flink-example-streaming 异步IO源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析07——flink-example-streaming SideOutput源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析08——flink-example-streaming Socket源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析09——flink-example-streaming window和join源码分析</a></li><li><a href="https://t.zsxq.com/BaIQBqr">Flink源码解析10——flink-example-streaming 源码分析总结</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink到底是否可以动态更改checkpoint配置</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink 通过 DDL 和 SQL 来实现读取 Kafka 数据并处理后将数据写回 Kafka</a></li><li><a href="https://t.zsxq.com/RJqj6YV">Flink SQL 实战——读取Kafka数据处理后写入 ElasticSearch 6 和 7 两种版本</a></li></ul><p><br /><br><br /></p><p><a name="R5umY"></a></p><h3 id="其他资源下载"><a href="#其他资源下载" class="headerlink" title="其他资源下载"></a>其他资源下载</h3><ul><li><a href="http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/">Flink Forward Asia 2019 的 PPT和视频下载</a></li><li><a href="http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/">Flink Forward 2020 PPT 下载</a> </li><li><a href="https://t.zsxq.com/emuVZrb">实时计算平台架构（上）</a></li><li><a href="https://t.zsxq.com/UnmMZN7">实时计算平台架构（下）</a></li><li><a href="https://t.zsxq.com/VfQ76iU">基于Flink实现的商品实时推荐系统</a></li><li><a href="https://t.zsxq.com/jIYB6QR">Flink1.8学习路线</a></li><li><a href="https://t.zsxq.com/6Q3vN3b">Kafka 学习文章和视频</a> </li><li><a href="https://t.zsxq.com/UNvnae6">数据分析指南</a> </li><li><a href="https://t.zsxq.com/jei27QZ">TimeoutException The heartbeat of TaskManager</a> </li><li><a href="https://t.zsxq.com/nu3fyV7">Flink on RocksDB 参数调优指南</a> </li><li><a href="https://t.zsxq.com/RRvjAyn">2020最新Java面试题及答案</a> </li><li><a href="https://t.zsxq.com/vBuzVj6">以业务为核心的中台体系建设</a> </li><li><a href="https://t.zsxq.com/Q7uVrvz">Skip List–跳表(全网最详细的跳表文章没有之一)</a> </li><li><a href="https://t.zsxq.com/N37mUzB">Stream Processing with Apache Flink</a> </li><li><a href="https://t.zsxq.com/NZf2JAq">假如我是面试官，我会问你这些问题，请接招</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239970&amp;idx=2&amp;sn=8703de96f1657bd811953dfff4d6abdd&amp;chksm=8f5a19beb82d90a8949b3bdd0c517ae66becede295307d6e3d7f8e634b82a2972797ef8648b9&amp;token=1858295303&amp;lang=zh_CN#rd">YARN 运行机制分析</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650239168&amp;idx=1&amp;sn=2e3e8d26b3eec376782b4415be86b399&amp;chksm=8f5a1a9cb82d938afc6c842187b255120624bfaa7c8090a9554277f08f279c28500d1191dd8a&amp;token=1858295303&amp;lang=zh_CN#rd">企业大数据平台仓库架构建设思路</a> </li><li><a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a> </li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIxMTE0ODU5NQ==&amp;mid=2650238519&amp;idx=1&amp;sn=7967857af5e7c435715c388592e326f9&amp;chksm=8f5a046bb82d8d7d15c678d21e274301183a446911dd66739a8728aa6794033eb6cea7d62ea5&amp;token=1858295303&amp;lang=zh_CN#rd">吐血之作 | 流系统Spark/Flink/Kafka/DataFlow端到端一致性实现对比</a> </li></ul><p><br /><br><br /><br><br />另外就是星球里可以向我提问，我看到问题会及时回答的，发现提问的还是比较少，想想当初就该还是要所有的都付费才能进，免费进的就会让你不珍惜自己付出的钱💰，自己也不会持续跟着一直学习下去。后面我会根据提问情况把长期潜水且当初是没付费的移除掉！<br /><br><br />还有就是群里的一些问题解答会同步到这里沉淀下来！如果你对这些问题还有更好的解答也欢迎提出你的回答，如果觉得棒的话我会进行一定额度的打赏！<br /><br><br />打赏包括但不限制于：<br /></p><ul><li>高质量的问题</li><li>学习资料资源分享</li><li>问题全面的解答</li><li>分享自己的建议</li></ul><p><br />好好做好这几点，肯定会把入知识星球的钱赚到！<br /><br><br />为什么要做一个这样的 Flink 知识星球？<br /></p><ul><li>帮助他人成长就是自己在成长</li><li>主动促使自己去深入这门技术（心里总觉得要对得起付费玩家）</li><li>真的想遇到那么一两个人可以一直好好学习下去（学习真特么是孤独的，一个人学习确实遇到的坑很多，效率肯定也低点，如果没有找到的话，那么还是我自己的那句话：坑要自己一个个填，路要自己一步步走！）</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><p><br />一个人走的快一些，一群人走的远一些，欢迎扫码上面的二维码加入知识星球，我们一起向前！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;整理自己发在知识星球和公众号的系列文章，方便查找。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.11 日志该如何配置？</title>
    <link href="http://www.54tianzhisheng.cn/2020/08/02/flink-1.11-log/"/>
    <id>http://www.54tianzhisheng.cn/2020/08/02/flink-1.11-log/</id>
    <published>2020-08-01T16:00:00.000Z</published>
    <updated>2020-07-09T04:39:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.11 日志升级到了 Log4j2，并且 Web UI 增强了功能。</p><a id="more"></a><h3 id="Flink-1-11-之前"><a href="#Flink-1-11-之前" class="headerlink" title="Flink 1.11 之前"></a>Flink 1.11 之前</h3><p>在 Flink 1.11 之前，Flink 使用的日志是 Log4j，配置文件 <code>log4j.properties</code> 中的内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, file</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given file</span><br><span class="line">log4j.appender.file=org.apache.log4j.FileAppender</span><br><span class="line">log4j.appender.file.file=$&#123;log.file&#125;</span><br><span class="line">log4j.appender.file.append=false</span><br><span class="line">log4j.appender.file.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.file.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, file</span><br></pre></td></tr></table></figure><p>该配置文件会将 JobManager 和 TaskManager 的日志分别打印在不同的文件中，每个文件的日志大小一直会增加，如果想配置日志文件按大小滚动的话可以使用 RollingFileAppender，则要将配置文件改成如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, RFA</span><br><span class="line"> </span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"> </span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">log4j.appender.RFA=org.apache.log4j.RollingFileAppender</span><br><span class="line">log4j.appender.RFA.File=$&#123;log.file&#125;</span><br><span class="line">log4j.appender.RFA.MaxFileSize=256MB</span><br><span class="line">log4j.appender.RFA.Append=true</span><br><span class="line">log4j.appender.RFA.MaxBackupIndex=10</span><br><span class="line">log4j.appender.RFA.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.RFA.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %t %-5p %-60c %x - %m%n</span><br><span class="line"> </span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, RFA</span><br></pre></td></tr></table></figure><p><strong>为什么要在生产环境下将日志文件改成按照大小滚动呢？</strong></p><p>无非是在生产情况下，流数据是非常大的，有的时候自己可能会通过 print() 打印出来流数据进来验证结果，有的时候可能是打印的日志记录做 debug 用，然后到生产忘记关了，结果到生产就全部将流数据打印出来，这种情况下，就会导致 TaskManager 的日志文件会非常大，那么我们打开 Web UI 查看可能就会很卡，这也就是为啥我们有时候打开 Web UI 查看日志的时候，非常卡顿，加载不出来的原因了，主要原因就是日志文件太大导致的。</p><p>当然有的同学可能会想着将 Flink 作业的日志发到 Kafka 做统一的收集，然后做一些日志分析告警和再消费发到 ElasticSearch 等去做日志搜索，如果是发到 Kafka，可以使用 KafkaLog4jAppender，日志文件配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">log4j.rootLogger=INFO, kafka</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#log4j.logger.org.apache.flink=INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">log4j.logger.akka=INFO</span><br><span class="line">log4j.logger.org.apache.kafka=INFO</span><br><span class="line">log4j.logger.org.apache.hadoop=INFO</span><br><span class="line">log4j.logger.org.apache.zookeeper=INFO</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># log send to kafka</span><br><span class="line">log4j.appender.kafka=org.apache.kafka.log4jappender.KafkaLog4jAppender</span><br><span class="line">log4j.appender.kafka.brokerList=localhost:9092</span><br><span class="line">log4j.appender.kafka.topic=flink_logs</span><br><span class="line">log4j.appender.kafka.compressionType=none</span><br><span class="line">log4j.appender.kafka.requiredNumAcks=0</span><br><span class="line">log4j.appender.kafka.syncSend=false</span><br><span class="line">log4j.appender.kafka.layout=org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.kafka.layout.ConversionPattern=%d&#123;yyyy-MM-dd HH:mm:ss&#125; %-5p %c&#123;1&#125;:%L - %m%n</span><br><span class="line">log4j.appender.kafka.level=INFO</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline=ERROR, kafka</span><br></pre></td></tr></table></figure><h3 id="Flink-1-11"><a href="#Flink-1-11" class="headerlink" title="Flink 1.11"></a>Flink 1.11</h3><p>在 Flink 1.11 中，将 Log4j 升级到了 Log4j2，可以通过查看 <a href="https://github.com/apache/flink/pull/11073">FLINK-15672</a> 可以知道变更的文件很多，</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-152451.png" alt=""></p><p>新版本的日志配置文件还是叫 <code>log4j.properties</code>，配置如下所示，不清楚为啥 FLINK-15672 代码提交中改了很多地方的配置文件名为 <code>log4j2.properties</code>，但是 Flink 最后打包的 conf 目录下还是保持和之前一样的文件名，按道理不是也应该进行更改成 <code>log4j2.properties</code> 的吗？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">rootLogger.level = INFO</span><br><span class="line">rootLogger.appenderRef.file.ref = MainAppender</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#logger.flink.name = org.apache.flink</span><br><span class="line">#logger.flink.level = INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">logger.akka.name = akka</span><br><span class="line">logger.akka.level = INFO</span><br><span class="line">logger.kafka.name= org.apache.kafka</span><br><span class="line">logger.kafka.level = INFO</span><br><span class="line">logger.hadoop.name = org.apache.hadoop</span><br><span class="line">logger.hadoop.level = INFO</span><br><span class="line">logger.zookeeper.name = org.apache.zookeeper</span><br><span class="line">logger.zookeeper.level = INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given file</span><br><span class="line">appender.main.name = MainAppender</span><br><span class="line">appender.main.type = File</span><br><span class="line">appender.main.append = false</span><br><span class="line">appender.main.fileName = $&#123;sys:log.file&#125;</span><br><span class="line">appender.main.layout.type = PatternLayout</span><br><span class="line">appender.main.layout.pattern = %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline</span><br><span class="line">logger.netty.level = OFF</span><br></pre></td></tr></table></figure><p>默认这个配置也是不会对日志文件进行按照大小滚动的，那么如果我们要保持和之前的效果一样（按照日志大小滚动日志文件）该怎么做呢？你可以更改配置文件的内容如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># This affects logging for both user code and Flink</span><br><span class="line">rootLogger.level = INFO</span><br><span class="line">rootLogger.appenderRef.rolling.ref = RollingFileAppender</span><br><span class="line"></span><br><span class="line"># Uncomment this if you want to _only_ change Flink&apos;s logging</span><br><span class="line">#logger.flink.name = org.apache.flink</span><br><span class="line">#logger.flink.level = INFO</span><br><span class="line"></span><br><span class="line"># The following lines keep the log level of common libraries/connectors on</span><br><span class="line"># log level INFO. The root logger does not override this. You have to manually</span><br><span class="line"># change the log levels here.</span><br><span class="line">logger.akka.name = akka</span><br><span class="line">logger.akka.level = INFO</span><br><span class="line">logger.kafka.name= org.apache.kafka</span><br><span class="line">logger.kafka.level = INFO</span><br><span class="line">logger.hadoop.name = org.apache.hadoop</span><br><span class="line">logger.hadoop.level = INFO</span><br><span class="line">logger.zookeeper.name = org.apache.zookeeper</span><br><span class="line">logger.zookeeper.level = INFO</span><br><span class="line"></span><br><span class="line"># Log all infos in the given rolling file</span><br><span class="line">appender.rolling.name = RollingFileAppender</span><br><span class="line">appender.rolling.type = RollingFile</span><br><span class="line">appender.rolling.append = false</span><br><span class="line">appender.rolling.fileName = $&#123;sys:log.file&#125;</span><br><span class="line">appender.rolling.filePattern = $&#123;sys:log.file&#125;.%i</span><br><span class="line">appender.rolling.layout.type = PatternLayout</span><br><span class="line">appender.rolling.layout.pattern = %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span><br><span class="line">appender.rolling.policies.type = Policies</span><br><span class="line">appender.rolling.policies.size.type = SizeBasedTriggeringPolicy</span><br><span class="line">appender.rolling.policies.size.size = 200MB</span><br><span class="line">appender.rolling.strategy.type = DefaultRolloverStrategy</span><br><span class="line">appender.rolling.strategy.max = 10</span><br><span class="line"></span><br><span class="line"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span><br><span class="line">logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline</span><br><span class="line">logger.netty.level = OFF</span><br></pre></td></tr></table></figure><p>如果你升级了到 1.11 版本，不能继续延用之前 1.11 之前的配置的那种日志文件滚动的配置了，需要做点变更。上面配置的表示日志文件以每隔 200MB 会进行切分，然后日志切分后的文件名是 <code>${sys:log.file}.%i</code>，以数字结尾。</p><p>1.11 进行了配置厚度的效果如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-154604.jpg" alt="TaskManager 日志列表展示"></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-08-03-154643.jpg" alt="JobManager 日志列表展示"></p><p>从上面图中可以发现 1.11 对于查看日志比之前友好了不少，多个日志文件都有列表展示，而不再是之前只能查看单个日志文件了。</p><p>注：为了演示日志文件滚动的效果，测试的时候设置的日志 <code>appender.rolling.policies.size.size</code> 是 1KB</p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.11 日志升级到了 Log4j2，并且 Web UI 增强了功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.11 Release 文档解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/06/29/flink-1.11/"/>
    <id>http://www.54tianzhisheng.cn/2020/06/29/flink-1.11/</id>
    <published>2020-06-28T16:00:00.000Z</published>
    <updated>2020-06-30T00:14:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.11 快要发布了，这里提前解读一下 Release 文档</p><a id="more"></a><h3 id="集群和部署"><a href="#集群和部署" class="headerlink" title="集群和部署"></a>集群和部署</h3><ul><li><strong>支持 Hadoop 3.0 及更高的版本</strong>：Flink 不再提供任何 <code>flink-shaded-hadoop-</code> 依赖。用户可以通过配置 HADOOP_CLASSPATH 环境变量(推荐)或在 lib 文件夹下放入 Hadoop 依赖项。另外 <code>include-hadoop</code> Maven profile 也已经被移除了。</li><li><strong>移除了 LegacyScheduler</strong>：Flink 不再支持 legacy scheduler，如果你设置了 <code>jobmanager.scheduler: legacy</code> 将不再起作用并且会抛出 IllegalArgumentException 异常，该参数的默认值并且是唯一选项为 ng。</li><li><strong>将用户代码的类加载器和 slot 的生命周期进行绑定</strong>：只要为单个作业分配了至少一个 slot，TaskManager 就会重新使用用户代码的类加载器。这会稍微改变 Flink 的恢复行为，从而不会重新加载静态字段。这样做的好处是，可以大大减轻对 JVM metaspace 的压力。</li><li><strong>slave 文件重命名为 workers</strong>：对于 Standalone 模式安装，worker 节点文件不再是 slaves 而是 workers，以前使用 <code>start-cluster.sh</code>  和 <code>stop-cluster.sh</code>  脚本的设置需要重命名该文件。</li><li><strong>完善 Flink 和 Docker 的集成</strong>： <code>Dockerfiles</code> 文件样例和 <code>build.sh</code> Docker 镜像文件都从 Flink GitHub 仓库中移除了，这些示例社区不再提供，因此 <code>flink-contrib/docker-flink</code> 、 <code>flink-container/docker</code> 和 <code>flink-container/kubernetes</code> 模块都已删除了。目前你可以通过查看 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/deployment/docker.html">Flink Docker integration</a> 官方文档学会如何使用和自定义 Flink Docker 镜像，文档中包含了 docker run、docker compose、docker swarm 和 standalone Kubernetes。</li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><ul><li><strong>JobManager 使用新的内存模型</strong>：可以参考 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-116%3A+Unified+Memory+Configuration+for+Job+Managers">FLIP-116</a>，介绍了 JobManager 新的内存模型，提供了新的配置选项来控制 JobManager 的进程内存消耗，这种改变会影响 Standalone、YARN、Mesos 和 Active Kubernetes。如果你尝试在不做任何调整的情况下重用以前的Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能发生变化甚至失败，可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/memory/mem_migration.html#migrate-job-manager-memory-configuration">Migrate Job Manager Memory Configuration</a> 文档进行迁移变更。 <code>jobmanager.heap.size</code> 和 <code>jobmanager.heap.mb</code> 配置参数已经过期了，如果这些过期的选项还继续使用的话，为了维持向后兼容性，它们将被解释为以下新选项之一：<ul><li>jobmanager.memory.heap.size：JVM Heap，为了 Standalone 和 Mesos 部署</li><li>jobmanager.memory.process.size：进程总内存，为了容器部署（Kubernetes 和 YARN）</li></ul></li></ul><p>   下面两个选项已经删除了并且不再起作用了：</p><ul><li>containerized.heap-cutoff-ratio</li><li>containerized.heap-cutoff-min</li></ul><p>   JVM 参数，JobManager JVM 进程的 direct 和 metaspace 内存现在通过下面两个参数进行配置：</p><ul><li>jobmanager.memory.off-heap.size</li><li><p>jobmanager.memory.jvm-metaspace.size</p><p>如果没有正确配置或存在相应的内存泄漏，这些新的限制可能会产生相应的 OutOfMemoryError 异常，可以参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/ops/memory/mem_trouble.html#outofmemoryerror-direct-buffer-memory">OutOfMemoryError</a> 文档进行解决。</p></li></ul><ul><li><strong>移除过期的</strong><code>mesos.resourcemanager.tasks.mem</code><strong>参数</strong></li></ul><h3 id="Table-API-SQL"><a href="#Table-API-SQL" class="headerlink" title="Table API/SQL"></a>Table API/SQL</h3><ul><li><strong>Blink planner 成为默认的 planner</strong></li><li><p><strong>改变了 Table API 的包结构</strong>：由于包 <code>org.apache.flink.table.api.scala/java</code> 中的各种问题，这些包下的所有类都已迁移。 此外，如 Flink 1.9 中所述，scala 表达式已移至 <code>org.apache.flink.table.api</code> 。</p><p> 如果你之前使用了下面的类：</p><ul><li><code>org.apache.flink.table.api.java.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.scala.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.java.BatchTableEnvironment</code> </li><li><code>org.apache.flink.table.api.scala.BatchTableEnvironment</code> </li></ul></li></ul><p>   如果你不需要转换成 DataStream 或者从 DataStream 转换，那么你可以使用：</p><ul><li><code>org.apache.flink.table.api.TableEnvironment</code> </li></ul><p>   如果你需要转换成 DataStream/DataSet，或者从 DataStream/DataSet 转换，那么你需要将依赖 imports 改成：</p><ul><li><code>org.apache.flink.table.api.bridge.java.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.scala.StreamTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.java.BatchTableEnvironment</code> </li><li><code>org.apache.flink.table.api.bridge.scala.BatchTableEnvironment</code> </li></ul><p>   对于 Scala 表达式，使用下面的 import：</p><ul><li><code>org.apache.flink.table.api._ instead of org.apache.flink.table.api.bridge.scala._</code> </li></ul><p>   如果你使用 Scala 隐式转换成 DataStream/DataSet，或者从 DataStream/DataSet 转换，那么该导入</p><ul><li><code>org.apache.flink.table.api.bridge.scala._</code> </li></ul><ul><li><strong>移除 StreamTableSink 接口中的 emitDataStream 方法</strong>：该接口的 emitDataStream 方法将移除</li><li><strong>移除 BatchTableSink 中的 emitDataSet 方法</strong>：将该接口的 emitDataSet 方法重命名为 consumeDataSet 并且返回 DataSink</li><li><strong>纠正</strong> <code>TableEnvironment.execute()</code><strong>和</strong> <code>StreamTableEnvironment.execute()</code> <strong>的执行行为</strong>：在早期的版本， <code>TableEnvironment.execute()</code> 和 <code>StreamExecutionEnvironment.execute()</code> 都可以触发 Table 程序和 DataStream 程序。从 Flink 1.11.0 开始，Table 程序只能由 <code>TableEnvironment.execute()</code> 触发。将 Table 程序转换为 DataStream 程序（通过 <code>toAppendStream()</code> 或 <code>toRetractStream()</code> 方法）后，只能由 <code>StreamExecutionEnvironment.execute()</code> 触发它。</li><li><strong>纠正</strong> <code>ExecutionEnvironment.execute()</code>  <strong>和</strong> <code>BatchTableEnvironment.execute()</code> <strong>的执行行为</strong>：在早期的版本中， <code>BatchTableEnvironment.execute()</code> 和 <code>ExecutionEnvironment.execute()</code> 都可以触发 Table 和 DataSet 应用程序（针对老的 planner）。 从 Flink 1.11.0 开始，批处理 Table 程序只能由 <code>BatchEnvironment.execute()</code> 触发。将 Table 程序转换为DataSet 程序（通过 toDataSet() 方法）后，只能由 <code>ExecutionEnvironment.execute()</code> 触发它。</li><li><strong>在 Row 类型中添加了更改标志</strong>：在 Row 类型中添加了一个更改标志 RowKind</li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><strong>重命名</strong> <code>log4j-yarn-session.properties</code> <strong>和</strong> <code>logback-yarn.xml</code> <strong>配置文件</strong>：日志配置文件 <code>log4j-yarn-session.properties</code> 和 <code>logback-yarn.xml</code> 被重命名为 <code>log4j-session.properties</code> 和 <code>logback-session.xml</code> 而且， <code>yarn-session.sh</code> 和 <code>kubernet -session.sh</code> 使用这些日志配置文件。</li></ul><h3 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h3><ul><li><strong>删除已弃用的后台清理开关</strong>： <code>StateTtlConfig#cleanupInBackground</code> 已经被删除，因为在 1.10 中该方法已被弃用，并且默认启用了后台 TTL。</li><li><p><strong>删除禁用 TTL 压缩过滤器的的选项</strong>：默认情况下，RocksDB 中的 TTL 压缩过滤器在 1.10 中是启用的，在 1.11+ 中总是启用的。因此，在 1.11 中删除了以下选项和方法：</p><ul><li>state.backend.rocksdb.ttl.compaction.filter.enabled</li><li>StateTtlConfig#cleanupInRocksdbCompactFilter()</li><li>RocksDBStateBackend#isTtlCompactionFilterEnabled</li><li>RocksDBStateBackend#enableTtlCompactionFilter</li><li>RocksDBStateBackend#disableTtlCompactionFilter</li><li>(state_backend.py) is_ttl_compaction_filter_enabled</li><li>(state_backend.py) enable_ttl_compaction_filter</li><li>(state_backend.py) disable_ttl_compaction_filter</li></ul></li><li><p><strong>改变</strong> <code>StateBackendFactory#createFromConfig</code> <strong>的参数类型</strong>：从 Flink 1.11 开始， <code>StateBackendFactory</code> 接口中的 <code>createFromConfig</code>方法中的参数变为 ReadableConfig 而不是 Configuration。Configuration 类是 ReadableConfig 接口的实现类，因为它实现了 ReadableConfig 接口，所以自定义 StateBackend 也应该做相应的调整。</p></li><li><strong>删除过期的</strong> <code>OptionsFactory</code> <strong>和</strong> <code>ConfigurableOptionsFactory</code> <strong>类</strong>：过期的 OptionsFactory 和 ConfigurableOptionsFactory 类已被删除。请改用 RocksDBOptionsFactory 和 ConfigurableRocksDBOptionsFactory。如果任何类扩展了DefaultConfigurableOptionsFactory，也请重新编译你的应用程序代码。</li><li><strong>默认情况下启用</strong> setTotalOrderSeek：从 Flink 1.11 开始，默认情况下，RocksDB 的 ReadOptions 将启用 setTotalOrderSeek 选项。这是为了防止用户忘记使用 optimizeForPointLookup。为了向后兼容，我们支持通过 RocksDBOptionsFactory 自定义 ReadOptions。如果观察到性能下降，请将 setTotalOrderSeek 设置为 false（根据我们的测试，这种情况不应该发生）。</li><li><strong>增加</strong> <code>state.backend.fs.memory-threshold</code> <strong>的默认值</strong>： <code>state.backend.fs.memory-threshold</code> 的默认值已从 1K 增加到20K，以防止在远程 FS 上为小状态创建太多小文件。对于那些 source 处配置很多并行度或者有状态的算子的作业可能会因此变更而出现 <code>JM OOM</code> 或 <code>RPC message exceeding maximum frame size</code> 的问题。如果遇到此类问题，请手动将配置设置回 1K。</li></ul><h3 id="PyFlink"><a href="#PyFlink" class="headerlink" title="PyFlink"></a>PyFlink</h3><ul><li><strong>对于不支持的数据类型将抛出异常</strong>：可以使用一些参数（例如，精度）来配置数据类型。但是，在以前的版本中，用户提供的精度没有任何效果，会使用该精度的默认值。为了避免混淆，从 Flink 1.11 开始，如果不支持该数据类型，则将引发异常。 更改包括：<ul><li><code>TimeType</code> 精度只能为 <code>0</code></li><li><code>VarBinaryType</code>/<code>VarCharType</code> 的长度是 <code>0x7fffffff</code></li><li><code>DecimalType</code> 可选值是 <code>38</code>/<code>18</code></li><li><code>TimestampType</code>/<code>LocalZonedTimestampType</code> 的精度只能是 <code>3</code></li><li><code>DayTimeIntervalType</code> 的单位是 <code>SECOND</code> ，<code>fractionalPrecision</code> 精度只能为 <code>3</code></li><li><code>YearMonthIntervalType</code> 的单位是 <code>MONTH</code> ，<code>yearPrecision</code> 精度只能为 <code>2</code></li><li><code>CharType</code>/<code>BinaryType</code>/<code>ZonedTimestampType</code> 不支持</li></ul></li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li><strong>将所有的 MetricReporters 转换为 plugins</strong>：Flink 的所有 MetricReporters 都已经转换为 plugins，它们不再存放在 lib 目录下（这样做可能会导致依赖冲突），而应该放到 <code>/plugins/&lt;some_directory&gt;</code> 目录下。</li><li><strong>改变 DataDog 的 metrics reporter Counter Metrics</strong>：现在 DataDog metrics reporter 程序将 Counter 指标上报为报告时间间隔内的事件数，而不是总数，将 Counter 语义与 DataDog 文档保持一致。</li><li><strong>切换 Log4j2 为默认的</strong>：Flink 现在默认使用 Log4j2，希望恢复到 Log4j1 的用户可以在日志文档中找到操作说明</li><li><strong>更改 JobManager API 的日志请求行为</strong>：从 JobManager 服务端请求一个不可用的 log 或者 stdout 文件现在会返回 404 状态码，在之前的版本中，会返回 <code>file unavailable</code> 。</li><li><strong>移除 lastCheckpointAlignmentBuffered metric</strong>：现在 lastCheckpointAlignmentBuffered metric 已经被移除了，因为在发出 Checkpoint barrier 之后，上游的任务不会发送任何数据，直到下游侧完成对齐为止，WebUI 仍然会显示该值，但现在始终为 0。</li></ul><h3 id="Connectors"><a href="#Connectors" class="headerlink" title="Connectors"></a>Connectors</h3><ul><li><strong>移除 Kafka 0.8/0.9 Connector</strong></li><li><strong>移除 ElasticSearch 2.x Connector</strong></li><li><strong>移除</strong> KafkaPartitioner</li><li><strong>改进的 fallback 文件系统，以只处理特定的文件系统</strong></li><li><strong>将</strong> <code>FileSystem#getKind</code> <strong>方法设置过期的</strong></li></ul><h3 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h3><ul><li><strong>流作业在 Checkpoint 同步部分失败时会立即失败</strong>：无论配置什么参数，Checkpoint 同步部分中的失败（如算子抛出异常）都将立即使其任务（和作业）失败，从 Flink 1.5 版本开始，可以通过设置 <code>setTolerableCheckpointFailureNumber(...)</code> 或 <code>setFailTaskOnCheckpointError(...)</code> 参数来忽略此类的失败，现在这两个参数只影响异步的失败。</li><li><strong>Checkpoint 超时不再被</strong> <code>CheckpointConfig#setTolerableCheckpointFailureNumber</code> <strong>忽略</strong>：现在将 Checkpoint 超时视为正常的 Checkpoint 故障，并根据 <code>CheckpointConfig＃setTolerableCheckpointFailureNumber</code> 配置的值进行检查。</li></ul><h3 id="各种接口变更"><a href="#各种接口变更" class="headerlink" title="各种接口变更"></a>各种接口变更</h3><ul><li><strong>移除过期的</strong> <code>StreamTask#getCheckpointLock()</code> ：在方法在 Flink 1.10 中已经设置过期了，目前不再提供该方法。用户可以使用 MailboxExecutor 来执行需要与任务线程安全的操作。</li><li><strong>flink-streaming-java 模块不再依赖 flink-client 模块</strong>：从 Flink 1.11.0 开始，flink-streaming-java 模块不再依赖 flink-client 模块，如果你项目依赖于 flink-client 模块，需要显示的添加其为依赖项。</li><li><strong>AsyncWaitOperator 是可链接的</strong>：默认情况下，将允许 AsyncWaitOperator 与所有算子链接在一起，但带有 SourceFunction 的任务除外。</li><li><strong>更改了</strong> <code>ShuffleEnvironment</code> <strong>接口的</strong> <code>createInputGates</code> <strong>和</strong> <code>createResultPartitionWriters</code> <strong>方法的参数类型</strong>。</li><li><code>CompositeTypeSerializerSnapshot#isOuterSnapshotCompatible</code> 方法标示过期了。</li><li><strong>移除了过期的 TimestampExtractor</strong>：可以使用 TimestampAssigner 和 WatermarkStrategies。</li><li><strong>将</strong> <code>ListCheckpointed</code> <strong>标示为过期的</strong>：可以使用 CheckpointedFunction 作为代替</li><li><strong>移除了过期的 state 连接方法</strong>：移除了 <code>RuntimeContext#getFoldingState()</code> 、 <code>OperatorStateStore#getSerializableListState()</code> 和 <code>OperatorStateStore#getOperatorState()</code> 连接状态的方法，这意味着在 1.10 运行成功的代码在 1.11 上是运行不了的。</li></ul><p>详情参考 <a href="https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.11.html">https://ci.apache.org/projects/flink/flink-docs-master/release-notes/flink-1.11.html</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.11 快要发布了，这里提前解读一下 Release 文档&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink 1.10 TaskManager 内存管理优化</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/</id>
    <published>2020-05-15T16:00:00.000Z</published>
    <updated>2020-05-16T03:34:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flink 1.10 对 TaskManager 的内存模型和 Flink 应用程序的配置选项进行了重大变更。这些最近引入的更改做到了对内存消耗提供了严格的控制，使得 Flink 在各种部署环境（例如 Kubernetes，Yarn，Mesos）更具有适应能力，</p><a id="more"></a><p>在本文中，我们将介绍 Flink 1.10 中的内存模型、如何设置和管理 Flink 应用程序的内存消耗以及社区在最新的 Apache Flink Release 版本中的变化。</p><h3 id="Flink-内存模型的介绍"><a href="#Flink-内存模型的介绍" class="headerlink" title="Flink 内存模型的介绍"></a>Flink 内存模型的介绍</h3><p>对 Apache Flink 的内存模型有清晰的了解，可以使您更有效地管理各种情况下的资源使用情况。 下图描述了 Flink 中的主要内存组件：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-05-16-032601.png" alt="Flink: Total Process Memory"></p><p>TaskManager 进程是一个 JVM 进程，从较高的角度来看，它的内存由 JVM Heap 和 Off-Heap 组成。这些类型的内存由 Flink 直接使用，或由 JVM 用于其特定目的（比如元空间 metaspace）。</p><p>Flink 中有两个主要的内存使用者：</p><ul><li>用户代码中的作业 task 算子</li><li>Flink 框架本身的内部数据结构、网络缓冲区 (Network Buffers)等</li></ul><p>请注意，用户代码可以直接访问所有的内存类型：JVM 堆、Direct 和 Native 内存。因此，Flink 不能真正控制其分配和使用。但是，有两种供作业 Task 使用并由 Flink 严格控制的 Off-Heap 内存，它们分别是：</p><ul><li>Managed Memory (Off-Heap)</li><li>网络缓冲区 (Network Buffers)</li></ul><p>网络缓冲区 (Network Buffers) 是 JVM Direct 内存的一部分，分配在算子和算子之间用于进行用户数据的交换。</p><h3 id="怎么去配置-Flink-的内存"><a href="#怎么去配置-Flink-的内存" class="headerlink" title="怎么去配置 Flink 的内存"></a>怎么去配置 Flink 的内存</h3><p>在最新 Flink 1.10 版本中，为了提供更好的用户体验，框架提供了内存组件的高级和细粒度调优。在 TaskManager 中设置内存基本上有三种选择。</p><p>前两个（也是最简单的）选择是需要你配置以下两个选项之一，以供 TaskManager 的 JVM 进程使用的总内存：</p><ul><li>Total Process Memory：Flink Java 应用程序（包括用户代码）和 JVM 运行整个进程所消耗的总内存。</li><li>Total Flink Memory：仅 Flink Java 应用程序消耗的内存，包括用户代码，但不包括 JVM 为其运行而分配的内存。</li></ul><p>如果是以 standalone 模式部署，则建议配置 Total Flink Memory，在这种情况下，显式声明为 Flink 分配多少内存是一种常见的做法，而外部 JVM 开销却很少。</p><p>对于在容器化环境（例如 Kubernetes，Yarn 或 Mesos）中部署 Flink 的情况，建议配置 Total Process Memory，因为它表示所请求容器的总内存大小，容器化环境通常严格执行此内存限制。</p><p>其余的内存组件将根据其默认值或其他已配置的参数自动进行调整。Flink 还会检查整体一致性。你可以在相应的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_detail.html">文档</a>中找到有关不同内存组件的更多信息。 此外，你可以使用 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-49%3A+Unified+Memory+Configuration+for+TaskExecutors">FLIP-49</a> 的配置电子表格尝试不同的配置选项，并根据你的情况检查相应的结果。</p><p>如果要从 1.10 之前的 Flink 版本进行迁移，我们建议你遵循 Flink 文档的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_migration.html">迁移指南</a>中的步骤。</p><h3 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h3><p>在配置 Flink 的内存时，可以使用相应选项的值固定不同内存组件的大小，也可以使用多个选项进行调整。下面我们提供有关内存设置的更多信息。</p><h4 id="按比例细分-Total-Flink-Memory"><a href="#按比例细分-Total-Flink-Memory" class="headerlink" title="按比例细分 Total Flink Memory"></a>按比例细分 Total Flink Memory</h4><p>此方法允许按比例细分 Total Flink Memory，其中 Managed Memory（如果未明确设置）和网络缓冲区可以占用一部分。然后，将剩余的内存分配给 Task Heap（如果未明确设置）和其他固定的 JVM Heap 和 Off-Heap 组件。下图是这种设置的示例：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-05-16-032632.png" alt=""></p><p><strong>请注意</strong>：</p><p>Flink 会校验分配的 Network Memory 大小在其最小值和最大值之间，否则 Flink 的启动会失败，最大值和最小值的限制具有默认值，这些默认值是可以被相应的配置选项覆盖。</p><p>通常，Flink 将配置的占比分数视为提示。在某些情况下，真正分配的值可能与占比分数不匹配。例如，如果将 Total Flink Memory 和 Task Heap 配置为固定值，则 Managed Memory 将获得一定比例的内存，而 Network Memory 将获得可能与该比例不完全匹配的剩余内存。</p><h4 id="控制容器内存限制的更多提示"><a href="#控制容器内存限制的更多提示" class="headerlink" title="控制容器内存限制的更多提示"></a>控制容器内存限制的更多提示</h4><p>堆内存和 direct 内存的使用是由 JVM 管理的。在 Apache Flink 或其用户应用程序中，还有许多其他 native 内存消耗的可能来源，它们不是由 Flink 或 JVM 管理的。通常很难控制它们的限制大小，这会使调试潜在的内存泄漏变得复杂。</p><p>如果 Flink 的进程以不受管理的方式分配了过多的内存，则在容器化环境中通常可能导致 TaskManager 容器会被杀死。在这种情况下，可能很难理解哪种类型的内存消耗已超过其限制。 Flink 1.10 引入了一些特定的调整选项，以清楚地表示这些组件。 尽管 Flink 不能始终严格执行严格的限制和界限，但此处的想法是明确计划内存使用情况。 下面我们提供一些示例，说明内存设置如何防止容器超出其内存限制：</p><ul><li><p><strong>RocksDB 状态不能太大</strong>：RocksDB 状态后端的内存消耗是在 Managed Memory 中解决的。 RocksDB 默认情况下遵守其限制（仅自 Flink 1.10 起）。你可以增加 Managed Memory 的大小以提高 RocksDB 的性能，也可以减小 Managed Memory 的大小以节省资源。</p></li><li><p><strong>用户代码或其依赖项会消耗大量的 off-heap 内存</strong>：调整 Task Off-Heap 选项可以为用户代码或其任何依赖项分配额外的 direct 或 native 内存。Flink 无法控制 native 分配，但它设置了 JVM Direct 内存分配的限制。Direct 内存限制由 JVM 强制执行。</p></li><li><p><strong>JVM metaspace 需要额外的内存</strong>：如果遇到 <code>OutOfMemoryError：Metaspace</code>，Flink 提供了一个增加其限制的选项，并且 JVM 将确保不超过该限制。</p></li><li><p><strong>JVM 需要更多内部内存</strong>：无法直接控制某些类型的 JVM 进程分配，但是 Flink 提供了 JVM 开销选项。这些选项允许声明额外的内存量，这些内存是为这些分配所预期的，并且未被其他选项覆盖。</p></li></ul><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>最新的 Flink 版本（Flink 1.10）对 Flink 的内存配置进行了一些重大更改，从而可以比以前更好地管理应用程序内存和调试 Flink。未来 JobManager 的内存模型也会采取类似的更改，可以参考 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP+116%3A+Unified+Memory+Configuration+for+Job+Managers">FLIP-116</a>，因此请继续关注即将发布的新版本中新增的功能。如果你对社区有任何建议或问题，我们建议你注册 Apache Flink 邮件列表并参与其中的讨论。</p><blockquote><p>博客英文地址：<a href="https://flink.apache.org/news/2020/04/21/memory-management-improvements-flink-1.10.html">https://flink.apache.org/news/2020/04/21/memory-management-improvements-flink-1.10.html</a><br>作者: Andrey Zagrebin<br>本文翻译作者：zhisheng<br>翻译后首发地址：<a href="http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/">http://www.54tianzhisheng.cn/2020/05/16/flink-taskmanager-memory-model/</a></p></blockquote><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink 1.10 对 TaskManager 的内存模型和 Flink 应用程序的配置选项进行了重大变更。这些最近引入的更改做到了对内存消耗提供了严格的控制，使得 Flink 在各种部署环境（例如 Kubernetes，Yarn，Mesos）更具有适应能力，&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward 2020 PPT 下载</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/13/flink-forward-2020/</id>
    <published>2020-05-12T16:00:00.000Z</published>
    <updated>2020-05-13T15:04:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward 2020 是在线上举办的一次会议</p><a id="more"></a><p>1、《Keynote:Introducing Stateful Functions 2.0: Stream Processing meets Serverless Applications》<br>Stephan Ewen – Apache Flink PMC,Ververica Co-founder, CTO</p><p>讲解嘉宾：李钰（绝顶） – Apache Flink Committer，Apache Flink 1.10 Release Manager，阿里巴巴高级技术专家</p><p>2、《Keynote:Stream analytics made real with Pravega and Apache Flink》<br>  Srikanth Satya – VP of Engineering at DellEMC</p><p>讲解嘉宾：滕昱 – DellEMC 技术总监</p><p>3、《Keynote:Apache Flink – Completing Cloudera’s End to End Streaming Platform》<br>  Marton Balassi – Apache Flink PMC ，Senior Solutions Architect at Cloudera</p><p>Joe Witt – VP of Engineering at Cloudera</p><p>讲解嘉宾：杨克特（鲁尼） – Apache Member, Apache Flink PMC, 阿里巴巴高级技术专家</p><p>4、《Keynote:The Evolution of Data Infrastructure at Splunk》<br>Eric Sammer – Distinguished Engineer at Splunk</p><p>讲解嘉宾：王治江（淘江） – 阿里巴巴高级技术专家</p><p>5、《Flink SQL 之 2020：舍我其谁》<br>Fabian Hueske, &amp; Timo Walther</p><p>讲解嘉宾：伍翀（云邪），Apache Flink PMC，阿里巴巴技术专家</p><p>6、《微博基于 Flink 的机器学习实践》</p><p>分享嘉宾：</p><p>于茜，微博机器学习研发中心高级算法工程师。多年来致力于使用 Flink 构建实时数据处理和在线机器学习框架，有丰富的社交媒体应用推荐系统的开发经验。</p><p>曹富强，微博机器学习研发中心系统工程师。现负责微博机器学习平台数据计算模块。主要涉及实时计算 Flink，Storm，Spark Streaming，离线计算 Hive，Spark 等。目前专注于 Flink 在微博机器学习场景的应用。</p><p>于翔，微博机器学习研发中心算法架构工程师。</p><p>7、《Flink’s application at Didi》</p><p>分享嘉宾：薛康 – 现任滴滴技术专家，实时计算负责人</p><p>8、《Alink：提升基于 Flink 的机器学习平台易用性》</p><p>分享嘉宾：杨旭（品数） – 阿里巴巴资深技术专家。</p><p>9、《Google: 机器学习工作流的分布式处理》<br>Ahmet Altay &amp; Reza Rokni &amp; Robert Crowe</p><p>讲解嘉宾：秦江杰 – Apache Flink PMC，阿里巴巴高级技术专家</p><p>10、《Flink + AI Flow：让 AI 易如反掌》</p><p>分享嘉宾：秦江杰 – Apache Flink PMC，阿里巴巴高级技术专家</p><p>11、《终于等到你：PyFlink + Zeppelin》</p><p>分享嘉宾：</p><p>孙金城（金竹） – Apache Member，Apache Flink PMC，阿里巴巴高级技术专家</p><p>章剑锋（简锋） – Apache Member，Apache Zeppelin PMC，阿里巴巴高级技术专家</p><p>12、《Uber ：使用 Flink CEP 进行地理情形检测的实践》<br>Teng (Niel) Hu</p><p>讲解嘉宾：付典 – Apache Flink Committer，阿里巴巴技术专家</p><p>13、《AWS: 如何在全托管 Apache Flink 服务中提供应用高可用》</p><p>Ryan Nienhuis &amp; Tirtha Chatterjee</p><p>讲解嘉宾：章剑锋（简锋） – Apache Member，Apache Zeppelin PMC，阿里巴巴高级技术专家</p><p>14、《Production-Ready Flink and Hive Integration – what story you can tell now?》</p><p>Bowen Li</p><p>讲解嘉宾：李锐（天离） – Apache Hive PMC，阿里巴巴技术专家</p><p>15、《Data Warehouse, Data Lakes, What’s Next?》<br>Xiaowei Jiang</p><p>讲解嘉宾：金晓军（仙隐） – 阿里巴巴高级技术专家</p><p>16、《Netflix 的 Flink 自动扩缩容》</p><p>Abhay Amin</p><p>讲解嘉宾：吕文龙（龙三），阿里巴巴技术专家</p><p>17、《Apache Flink 误用之痛》</p><p>Konstantin Knauf</p><p>讲解嘉宾：孙金城（金竹） – Apache Member，Apache Flink PMC，阿里巴巴高级技术专家</p><p>18、《A deep dive into Flink SQL》</p><p>分享嘉宾：伍翀（云邪），Apache Flink PMC，阿里巴巴技术专家</p><p>19、《Lyft: 基于Flink的准实时海量数据分析平台》</p><p>Ying Xu &amp; Kailash Hassan Dayanand</p><p>讲解嘉宾：王阳（亦祺），阿里巴巴技术专家</p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以扫描下面二维码，关注微信公众号：zhisheng，然后在里面回复关键字: <strong>ff2020</strong> 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2019-12-28-144329.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward 2020 是在线上举办的一次会议&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>如何实时监控 Flink 集群和作业？</title>
    <link href="http://www.54tianzhisheng.cn/2020/05/07/flink-job-monitor/"/>
    <id>http://www.54tianzhisheng.cn/2020/05/07/flink-job-monitor/</id>
    <published>2020-05-06T16:00:00.000Z</published>
    <updated>2020-05-07T13:03:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。</p><a id="more"></a><h2 id="实时监控-Flink-及其作业"><a href="#实时监控-Flink-及其作业" class="headerlink" title="实时监控 Flink 及其作业"></a>实时监控 Flink 及其作业</h2><p>当将 Flink JobManager、TaskManager 都运行起来了，并且也部署了不少 Flink Job，那么它到底是否还在运行、运行的状态如何、资源 TaskManager 和 Slot 的个数是否足够、Job 内部是否出现异常、计算速度是否跟得上数据生产的速度 等这些问题其实对我们来说是比较关注的，所以就很迫切的需要一个监控系统帮我们把整个 Flink 集群的运行状态给展示出来。通过监控系统我们能够很好的知道 Flink 内部的整个运行状态，然后才能够根据项目生产环境遇到的问题 ‘对症下药’。下面分别来讲下 JobManager、TaskManager、Flink Job 的监控以及最关心的一些监控指标。</p><h3 id="监控-JobManager"><a href="#监控-JobManager" class="headerlink" title="监控 JobManager"></a>监控 JobManager</h3><p>我们知道 JobManager 是 Flink 集群的中控节点，类似于 Apache Storm 的 Nimbus 以及 Apache Spark 的 Driver 的角色。它负责作业的调度、作业 Jar 包的管理、Checkpoint 的协调和发起、与 TaskManager 之间的心跳检查等工作。如果 JobManager 出现问题的话，就会导致作业 UI 信息查看不了，TaskManager 和所有运行的作业都会受到一定的影响，所以这也是为啥在 7.1 节中强调 JobManager 的高可用问题。 </p><p>在 Flink 自带的 UI 上 JobManager 那个 Tab 展示的其实并没有显示其对应的 Metrics，那么对于 JobManager 来说常见比较关心的监控指标有哪些呢？</p><h4 id="基础指标"><a href="#基础指标" class="headerlink" title="基础指标"></a>基础指标</h4><p>因为 Flink JobManager 其实也是一个 Java 的应用程序，那么它自然也会有 Java 应用程序的指标，比如内存、CPU、GC、类加载、线程信息等。</p><ul><li>内存：内存又分堆内存和非堆内存，在 Flink 中还有 Direct 内存，每种内存又有初始值、使用值、最大值等指标，因为在 JobManager 中的工作其实相当于 TaskManager 来说比较少，也不存储事件数据，所以通常 JobManager 占用的内存不会很多，在 Flink JobManager 中自带的内存 Metrics 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">jobmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">jobmanager_Status_JVM_Memory_NonHeap_Used</span><br></pre></td></tr></table></figure><ul><li>CPU：JobManager 分配的 CPU 使用情况，如果使用类似 K8S 等资源调度系统，则需要对每个容器进行设置资源，比如 CPU 限制不能超过多少，在 Flink JobManager 中自带的 CPU 指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_CPU_Load</span><br><span class="line">jobmanager_Status_JVM_CPU_Time</span><br></pre></td></tr></table></figure><ul><li>GC：GC 信息对于 Java 应用来说是避免不了的，每种 GC 都有时间和次数的指标可以供参考，提供的指标有：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_MarkSweep_Time</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Count</span><br><span class="line">jobmanager_Status_JVM_GarbageCollector_PS_Scavenge_Time</span><br></pre></td></tr></table></figure><h4 id="Checkpoint-指标"><a href="#Checkpoint-指标" class="headerlink" title="Checkpoint 指标"></a>Checkpoint 指标</h4><p>因为 JobManager 负责了作业的 Checkpoint 的协调和发起功能，所以 Checkpoint 相关的指标就有表示 Checkpoint 执行的时间、Checkpoint 的时间长短、完成的 Checkpoint 的次数、Checkpoint 失败的次数、Checkpoint 正在执行 Checkpoint 的个数等，其对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_lastCheckpointAlignmentBuffered</span><br><span class="line">jobmanager_job_lastCheckpointDuration</span><br><span class="line">jobmanager_job_lastCheckpointExternalPath</span><br><span class="line">jobmanager_job_lastCheckpointRestoreTimestamp</span><br><span class="line">jobmanager_job_lastCheckpointSize</span><br><span class="line">jobmanager_job_numberOfCompletedCheckpoints</span><br><span class="line">jobmanager_job_numberOfFailedCheckpoints</span><br><span class="line">jobmanager_job_numberOfInProgressCheckpoints</span><br><span class="line">jobmanager_job_totalNumberOfCheckpoints</span><br></pre></td></tr></table></figure><h4 id="重要的指标"><a href="#重要的指标" class="headerlink" title="重要的指标"></a>重要的指标</h4><p>另外还有比较重要的指标就是 Flink UI 上也提供的，类似于 Slot 总共个数、Slot 可使用的个数、TaskManager 的个数（通过查看该值可以知道是否有 TaskManager 发生异常重启）、正在运行的作业数量、作业运行的时间和完成的时间、作业的重启次数，对应的指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">jobmanager_job_uptime</span><br><span class="line">jobmanager_numRegisteredTaskManagers</span><br><span class="line">jobmanager_numRunningJobs</span><br><span class="line">jobmanager_taskSlotsAvailable</span><br><span class="line">jobmanager_taskSlotsTotal</span><br><span class="line">jobmanager_job_downtime</span><br><span class="line">jobmanager_job_fullRestarts</span><br><span class="line">jobmanager_job_restartingTime</span><br></pre></td></tr></table></figure><h3 id="监控-TaskManager"><a href="#监控-TaskManager" class="headerlink" title="监控 TaskManager"></a>监控 TaskManager</h3><p>TaskManager 在 Flink 集群中也是一个个的进程实例，它的数量代表着能够运行作业个数的能力，所有的 Flink 作业最终其实是会在 TaskManager 上运行的，TaskManager 管理着运行在它上面的所有作业的 Task 的整个生命周期，包括了 Task 的启动销毁、内存管理、磁盘 IO、网络传输管理等。</p><p>因为所有的 Task 都是运行运行在 TaskManager 上的，有的 Task 可能会做比较复杂的操作或者会存储很多数据在内存中，那么就会消耗很大的资源，所以通常来说 TaskManager 要比 JobManager 消耗的资源要多，但是这个资源具体多少其实也不好预估，所以可能会出现由于分配资源的不合理，导致 TaskManager 出现 OOM 等问题。一旦 TaskManager 因为各种问题导致崩溃重启的话，运行在它上面的 Task 也都会失败，JobManager 与它的通信也会丢失。因为作业出现 failover，所以在重启这段时间它是不会去消费数据的，所以必然就会出现数据消费延迟的问题。对于这种情况那么必然就很需要 TaskManager 的监控信息，这样才能够对整个集群的 TaskManager 做一个提前预警。</p><p>那么在 Flink 中自带的 TaskManager Metrics 有哪些呢？主要也是 CPU、类加载、GC、内存、网络等。其实这些信息在 Flink UI 上也是有，如下图所示，不知道读者有没有细心观察过。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-030513.png" alt=""></p><p>在这个 TaskManager 的 Metrics 监控页面通常比较关心的指标有内存相关的，还有就是 GC 的指标，通常一个 TaskManager 出现 OOM 之前会不断的进行 GC，在这个 Metrics 页面它展示了年轻代和老年代的 GC 信息（时间和次数），如下图所示，大家可以细心观察下是否 TaskManager OOM 前老年代和新生代的 GC 次数比较、时间比较长。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-030954.png" alt=""></p><p>在 Flink Reporter 中提供的 TaskManager Metrics 指标如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_Status_JVM_CPU_Load</span><br><span class="line">taskmanager_Status_JVM_CPU_Time</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesLoaded</span><br><span class="line">taskmanager_Status_JVM_ClassLoader_ClassesUnloaded</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Old_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Count</span><br><span class="line">taskmanager_Status_JVM_GarbageCollector_G1_Young_Generation_Time</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Direct_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_Heap_Used</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_Count</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_MemoryUsed</span><br><span class="line">taskmanager_Status_JVM_Memory_Mapped_TotalCapacity</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Committed</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Max</span><br><span class="line">taskmanager_Status_JVM_Memory_NonHeap_Used</span><br><span class="line">taskmanager_Status_JVM_Threads_Count</span><br><span class="line">taskmanager_Status_Network_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Network_TotalMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_AvailableMemorySegments</span><br><span class="line">taskmanager_Status_Shuffle_Netty_TotalMemorySegments</span><br></pre></td></tr></table></figure><h3 id="监控-Flink-作业"><a href="#监控-Flink-作业" class="headerlink" title="监控 Flink 作业"></a>监控 Flink 作业</h3><p>对于运行的作业来说，其实我们会更关心其运行状态，如果没有其对应的一些监控信息，那么对于我们来说这个 Job 就是一个黑盒，完全不知道是否在运行，Job 运行状态是什么、Task 运行状态是什么、是否在消费数据、消费数据是咋样（细分到每个 Task）、消费速度能否跟上生产数据的速度、处理数据的过程中是否有遇到什么错误日志、处理数据是否有出现反压问题等等。</p><p>上面列举的这些问题通常来说是比较关心的，那么在 Flink UI 上也是有提供的查看对应的信息的，点开对应的作业就可以查看到作业的执行图，每个 Task 的信息都是会展示出来的，包含了状态、Bytes Received（接收到记录的容量大小）、Records Received（接收到记录的条数）、Bytes Sent（发出去的记录的容量大小）、Records Sent（发出去记录的条数）、异常信息、timeline（作业运行状态的时间线）、Checkpoint 信息，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-042958.png" alt=""></p><p>这些指标也可以通过 Flink 的 Reporter 进行上报存储到第三方的时序数据库，然后通过类似 Grafana 展示出来，如下图所示。通过这些信息大概就可以清楚的知道一个 Job 的整个运行状态，然后根据这些运行状态去分析作业是否有问题。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-070124.png" alt=""></p><p>在流作业中最关键的指标无非是作业的实时性，那么延迟就是衡量作业的是否实时的一个基本参数，但是对于现有的这些信息其实还不知道作业的消费是否有延迟，通常来说可以结合 Kafka 的监控去查看对应消费的 Topic 的 Group 的 Lag 信息，如果 Lag 很大就表明有数据堆积了，另外还有一个办法就是需要自己在作业中自定义 Metrics 做埋点，将算子在处理数据的系统时间与数据自身的 Event Time 做一个差值，求得值就可以知道算子消费的数据是什么时候的了。比如在 1571457964000（2019-10-19 12:06:04）Map 算子消费的数据的事件时间是 1571457604000（2019-10-19 12:00:04），相差了 6 分钟，那么就表明消费延迟了 6 分钟，然后通过 Metrics Reporter 将埋点的 Metrics 信息上传，这样最终就可以获取到作业在每个算子处的消费延迟的时间。</p><p>上面的是针对于作业延迟的判断方法，另外像类似于作业反压的情况，在 Flink 的 UI 也会有展示，具体怎么去分析和处理这种问题在 9.1 节中有详细讲解。</p><p>根据这些监控信息不仅可以做到提前预警，做好资源的扩容（比如增加容器的数量／内存／CPU／并行度／Slot 个数），也还可以找出作业配置的资源是否有浪费。通常来说一个作业的上线可能是会经过资源的预估，然后才会去申请这个作业要配置多少资源，比如算子要使用多少并行度，最后上线后可以通过完整的运行监控信息查看该作业配置的并行度是否有过多或者配置的内存比较大。比如出现下面这些情况的时候可能就是资源出现浪费了：</p><ul><li>作业消费从未发生过延迟，即使在数据流量高峰的时候，也未发生过消费延迟</li><li>作业运行所在的 TaskManager 堆内存使用率异常的低</li><li>作业运行所在的 TaskManager 的 GC 时间和次数非常规律，没有出现异常的现象，如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-064123.png" alt=""></p><p>在 Flink Metrics Reporter 上传的指标中大概有下面这些：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Input_Buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_Buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocal</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemote</span><br><span class="line">taskmanager_job_task_Shuffle_Netty_Output_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_buffers_inPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_inputExclusiveBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputFloatingBuffersUsage</span><br><span class="line">taskmanager_job_task_buffers_inputQueueLength</span><br><span class="line">taskmanager_job_task_buffers_outPoolUsage</span><br><span class="line">taskmanager_job_task_buffers_outputQueueLength</span><br><span class="line">taskmanager_job_task_checkpointAlignmentTime</span><br><span class="line">taskmanager_job_task_currentInputWatermark</span><br><span class="line">taskmanager_job_task_numBuffersInLocal</span><br><span class="line">taskmanager_job_task_numBuffersInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBuffersInRemote</span><br><span class="line">taskmanager_job_task_numBuffersInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBuffersOut</span><br><span class="line">taskmanager_job_task_numBuffersOutPerSecond</span><br><span class="line">taskmanager_job_task_numBytesIn</span><br><span class="line">taskmanager_job_task_numBytesInLocal</span><br><span class="line">taskmanager_job_task_numBytesInLocalPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInPerSecond</span><br><span class="line">taskmanager_job_task_numBytesInRemote</span><br><span class="line">taskmanager_job_task_numBytesInRemotePerSecond</span><br><span class="line">taskmanager_job_task_numBytesOut</span><br><span class="line">taskmanager_job_task_numBytesOutPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsIn</span><br><span class="line">taskmanager_job_task_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_numRecordsOut</span><br><span class="line">taskmanager_job_task_numRecordsOutPerSecond</span><br><span class="line">taskmanager_job_task_operator_currentInputWatermark</span><br><span class="line">taskmanager_job_task_operator_currentOutputWatermark</span><br><span class="line">taskmanager_job_task_operator_numLateRecordsDropped</span><br><span class="line">taskmanager_job_task_operator_numRecordsIn</span><br><span class="line">taskmanager_job_task_operator_numRecordsInPerSecond</span><br><span class="line">taskmanager_job_task_operator_numRecordsOut</span><br><span class="line">taskmanager_job_task_operator_numRecordsOutPerSecond</span><br></pre></td></tr></table></figure><h3 id="最关心的性能指标"><a href="#最关心的性能指标" class="headerlink" title="最关心的性能指标"></a>最关心的性能指标</h3><p>上面已经提及到 Flink 的 JobManager、TaskManager 和运行的 Flink Job 的监控以及常用的监控信息，这些指标有的是可以直接在 Flink 的 UI 上观察到的，另外 Flink 提供了 Metrics Reporter 进行上报存储到监控系统中去，然后通过可视化的图表进行展示，在 8.2 节中将教大家如何构建一个完整的监控系统。那么有了这么多监控指标，其实哪些是比较重要的呢，比如说这些指标出现异常的时候可以发出告警及时进行通知，这样可以做到预警作用，另外还可以根据这些信息进行作业资源的评估。下面列举一些笔者觉得比较重要的指标：</p><h4 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h4><p>在 JobManager 中有着该集群中所有的 TaskManager 的个数、Slot 的总个数、Slot 的可用个数、运行的时间、作业的 Checkpoint 情况，笔者觉得这几个指标可以重点关注。</p><ul><li>TaskManager 个数：如果出现 TaskManager 突然减少，可能是因为有 TaskManager 挂掉重启，一旦该 TaskManager 之前运行了很多作业，那么重启带来的影响必然是巨大的。</li><li>Slot 个数：取决于 TaskManager 的个数，决定了能运行作业的最大并行度，如果资源不够，及时扩容。</li><li>作业运行时间：根据作业的运行时间来判断作业是否存活，中途是否掉线过。</li><li>Checkpoint 情况：Checkpoint 是 JobManager 发起的，并且关乎到作业的状态是否可以完整的保存。</li></ul><h4 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h4><p>因为所有的作业最终都是运行在 TaskManager 上，所以 TaskManager 的监控指标也是异常的监控，并且作业的复杂度也会影响 TaskManager 的资源使用情况，所以 TaskManager 的基础监控指标比如内存、GC 如果出现异常或者超出设置的阈值则需要立马进行告警通知，防止后面导致大批量的作业出现故障重启。</p><ul><li>内存使用率：部分作业的算子会将所有的 State 数据存储在内存中，这样就会导致 TaskManager 的内存使用率会上升，还有就是可以根据该指标看作业的利用率，从而最后来重新划分资源的配置。</li><li>GC 情况：分时间和次数，一旦 TaskManager 的内存率很高的时候，必定伴随着频繁的 GC，如果在 GC 的时候没有得到及时的预警，那么将面临 OOM 风险。</li></ul><h4 id="Flink-Job"><a href="#Flink-Job" class="headerlink" title="Flink Job"></a>Flink Job</h4><p>作业的稳定性和及时性其实就是大家最关心的，常见的指标有：作业的状态、Task 的状态、作业算子的消费速度、作业出现的异常日志。</p><ul><li>作业的状态：在 UI 上是可以看到作业的状态信息，常见的状态变更信息如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-080858.png" alt=""></p><ul><li>Task 的状态：其实导致作业的状态发生变化的原因通常是由于 Task 的运行状态出现导致，所以也需要对 Task 的运行状态进行监控，Task 的运行状态如下图所示。</li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-19-081049.png" alt=""></p><ul><li><p>作业异常日志：导致 Task 出现状态异常的根因通常是作业中的代码出现各种各样的异常日志，最后可能还会导致作业无限重启，所以作业的异常日志也是需要及时关注。</p></li><li><p>作业重启次数：当 Task 状态和作业的状态发生变化的时候，如果作业中配置了重启策略或者开启了 Checkpoint 则会进行作业重启的，重启作业的带来的影响也会很多，并且会伴随着一些不确定的因素，最终导致作业一直重启，这样既不能解决问题，还一直在占用着资源的消耗。</p></li><li><p>算子的消费速度：代表了作业的消费能力，还可以知道作业是否发生延迟，可以包含算子接收的数据量和发出去数据量，从而可以知道在算子处是否有发生数据的丢失。</p></li></ul><h3 id="小结与反思"><a href="#小结与反思" class="headerlink" title="小结与反思"></a>小结与反思</h3><p>本节讲了 Flink 中常见的监控对象，比如 JobManager、TaskManager 和 Flink Job，对于这几个分别介绍了其内部大概有的监控指标，以及在真实生产环境关心的指标，你是否还有其他的监控指标需要补充呢？ </p><p>本节涉及的监控指标对应的含义可以参考官网链接：<a href="https://ci.apache.org/projects/flink/flink-docs-stable/monitoring/metrics.html#system-metrics">metrics</a></p><p>本节涉及的监控指标列表地址：<a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-monitor/flink_monitor_measurements.md">flink_monitor_measurements</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 相关的组件和作业的稳定性通常是比较关键的，所以得需要对它们进行监控，如果有异常，则需要及时告警通知。本章先会教会教会大家如何利用现有 Flink UI 上面的信息去发现和排查问题，会指明一些比较重要和我们非常关心的指标，通过这些指标我们能够立马定位到问题的根本原因。接着笔者会教大家如何去利用现有的 Metrics Reporter 去构建一个 Flink 的监控系统，它可以收集到所有作业的监控指标，并会存储这些监控指标数据，最后还会有一个监控大盘做数据可视化，通过这个大盘可以方便排查问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的实时 Error 日志告警</title>
    <link href="http://www.54tianzhisheng.cn/2020/04/15/flink-error-log-alert/"/>
    <id>http://www.54tianzhisheng.cn/2020/04/15/flink-error-log-alert/</id>
    <published>2020-04-14T16:00:00.000Z</published>
    <updated>2020-05-07T13:03:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。</p><a id="more"></a><h3 id="日志处理方案的演进"><a href="#日志处理方案的演进" class="headerlink" title="日志处理方案的演进"></a>日志处理方案的演进</h3><p>日志处理的方案也是有一个演进的过程，要想弄清楚整个过程，我们先来看下日志的介绍。</p><h4 id="什么是日志？"><a href="#什么是日志？" class="headerlink" title="什么是日志？"></a>什么是日志？</h4><p>日志是带时间戳的基于时间序列的数据，它可以反映系统的运行状态，包括了一些标识信息（应用所在服务器集群名、集群机器 IP、机器设备系统信息、应用名、应用 ID、应用所属项目等）</p><h4 id="日志处理方案演进"><a href="#日志处理方案演进" class="headerlink" title="日志处理方案演进"></a>日志处理方案演进</h4><p>日志处理方案的演进过程：</p><ul><li>日志处理 v1.0: 应用日志分布在很多机器上，需要人肉手动去机器查看日志信息。</li><li>日志处理 v2.0: 利用离线计算引擎统一的将日志收集，形成一个日志搜索分析平台，提供搜索让用户根据关键字进行搜索和分析，缺点就是及时性比较差。</li><li>日志处理 v3.0: 利用 Agent 实时的采集部署在每台机器上的日志，然后统一发到日志收集平台做汇总，并提供实时日志分析和搜索的功能，这样从日志产生到搜索分析出结果只有简短的延迟（在用户容忍时间范围之内），优点是快，但是日志数据量大的情况下带来的挑战也大。</li></ul><h3 id="日志采集工具对比"><a href="#日志采集工具对比" class="headerlink" title="日志采集工具对比"></a>日志采集工具对比</h3><p>上面提到的日志采集，其实现在已经有很多开源的组件支持去采集日志，比如 Logstash、Filebeat、Fluentd、Logagent 等，这里简单做个对比。</p><h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><p>Logstash 是一个开源数据收集引擎，具有实时管道功能。Logstash 可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。如下图所示，Logstash 将采集到的数据用作分析、监控、告警等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-025214.jpg" alt=""></p><p><strong>优势</strong>：Logstash 主要的优点就是它的灵活性，它提供很多插件，详细的文档以及直白的配置格式让它可以在多种场景下应用。而且现在 ELK 整个技术栈在很多公司应用的比较多，所以基本上可以在往上找到很多相关的学习资源。</p><p><strong>劣势</strong>：Logstash 致命的问题是它的性能以及资源消耗(默认的堆大小是 1GB)。尽管它的性能在近几年已经有很大提升，与它的替代者们相比还是要慢很多的，它在大数据量的情况下会是个问题。另一个问题是它目前不支持缓存，目前的典型替代方案是将 Redis 或 Kafka 作为中心缓冲池：</p><h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><p>作为 Beats 家族的一员，Filebeat 是一个轻量级的日志传输工具，它的存在正弥补了 Logstash 的缺点，Filebeat 作为一个轻量级的日志传输工具可以将日志推送到 Kafka、Logstash、ElasticSearch、Redis。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-030138.jpg" alt=""></p><p><strong>优势</strong>：Filebeat 只是一个二进制文件没有任何依赖。它占用资源极少，尽管它还十分年轻，正式因为它简单，所以几乎没有什么可以出错的地方，所以它的可靠性还是很高的。它也为我们提供了很多可以调节的点，例如：它以何种方式搜索新的文件，以及当文件有一段时间没有发生变化时，何时选择关闭文件句柄。</p><p><strong>劣势</strong>：Filebeat 的应用范围十分有限，所以在某些场景下我们会碰到问题。例如，如果使用 Logstash 作为下游管道，我们同样会遇到性能问题。正因为如此，Filebeat 的范围在扩大。开始时，它只能将日志发送到 Logstash 和 Elasticsearch，而现在它可以将日志发送给 Kafka 和 Redis，在 5.x 版本中，它还具备过滤的能力。</p><h4 id="Fluentd"><a href="#Fluentd" class="headerlink" title="Fluentd"></a>Fluentd</h4><p>Fluentd 创建的初衷主要是尽可能的使用 JSON 作为日志输出，所以传输工具及其下游的传输线不需要猜测子字符串里面各个字段的类型。这样它为几乎所有的语言都提供库，这也意味着可以将它插入到自定义的程序中。它的处理流程如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-031337.png" alt=""></p><p><strong>优势</strong>：和多数 Logstash 插件一样，Fluentd 插件是用 Ruby 语言开发的非常易于编写维护。所以它数量很多，几乎所有的源和目标存储都有插件(各个插件的成熟度也不太一样)。这也意味这可以用 Fluentd 来串联所有的东西。</p><p><strong>劣势</strong>：因为在多数应用场景下得到 Fluentd 结构化的数据，它的灵活性并不好。但是仍然可以通过正则表达式来解析非结构化的数据。尽管性能在大多数场景下都很好，但它并不是最好的，它的缓冲只存在与输出端，单线程核心以及 Ruby GIL 实现的插件意味着它大的节点下性能是受限的。</p><h4 id="Logagent"><a href="#Logagent" class="headerlink" title="Logagent"></a>Logagent</h4><p>Logagent 是 Sematext 提供的传输工具，它用来将日志传输到 Logsene(一个基于 SaaS 平台的 Elasticsearch API)，因为 Logsene 会暴露 Elasticsearch API，所以 Logagent 可以很容易将数据推送到 Elasticsearch 。</p><p><strong>优势</strong>：可以获取 /var/log 下的所有信息，解析各种格式的日志，可以掩盖敏感的数据信息。它还可以基于 IP 做 GeoIP 丰富地理位置信息。同样，它轻量又快速，可以将其置入任何日志块中。Logagent 有本地缓冲，所以在数据传输目的地不可用时不会丢失日志。</p><p><strong>劣势</strong>：没有 Logstash 灵活。</p><h3 id="日志结构设计"><a href="#日志结构设计" class="headerlink" title="日志结构设计"></a>日志结构设计</h3><p>前面介绍了日志和对比了常用日志采集工具的优势和劣势，通常在不同环境，不同机器上都会部署日志采集工具，然后采集工具会实时的将新的日志采集发送到下游，因为日志数据量毕竟大，所以建议发到 MQ 中，比如 Kafka，这样再想怎么处理这些日志就会比较灵活。假设我们忽略底层采集具体是哪种，但是规定采集好的日志结构化数据如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEvent</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String type;<span class="comment">//日志的类型(应用、容器、...)</span></span><br><span class="line">    <span class="keyword">private</span> Long timestamp;<span class="comment">//日志的时间戳</span></span><br><span class="line">    <span class="keyword">private</span> String level;<span class="comment">//日志的级别(debug/info/warn/error)</span></span><br><span class="line">    <span class="keyword">private</span> String message;<span class="comment">//日志内容</span></span><br><span class="line">    <span class="comment">//日志的标识(应用 ID、应用名、容器 ID、机器 IP、集群名、...)</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; tags = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后上面这种 LogEvent 的数据（假设采集发上来的是这种结构数据的 JSON 串，所以需要在 Flink 中做一个反序列化解析）就会往 Kafka 不断的发送数据，样例数据如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="attr">"type"</span>: <span class="string">"app"</span>,</span><br><span class="line"><span class="attr">"timestamp"</span>: <span class="number">1570941591229</span>,</span><br><span class="line"><span class="attr">"level"</span>: <span class="string">"error"</span>,</span><br><span class="line"><span class="attr">"message"</span>: <span class="string">"Exception in thread \"main\" java.lang.NoClassDefFoundError: org/apache/flink/api/common/ExecutionConfig$GlobalJobParameters"</span>,</span><br><span class="line"><span class="attr">"tags"</span>: &#123;</span><br><span class="line"><span class="attr">"cluster_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"app_name"</span>: <span class="string">"zhisheng"</span>,</span><br><span class="line"><span class="attr">"host_ip"</span>: <span class="string">"127.0.0.1"</span>,</span><br><span class="line"><span class="attr">"app_id"</span>: <span class="string">"21"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么在 Flink 中如何将应用异常或者错误的日志做实时告警呢？</p><h3 id="异常日志实时告警项目架构"><a href="#异常日志实时告警项目架构" class="headerlink" title="异常日志实时告警项目架构"></a>异常日志实时告警项目架构</h3><p>整个异常日志实时告警项目的架构如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-035811.png" alt=""></p><p>应用日志散列在不同的机器，然后每台机器都有部署采集日志的 Agent（可以是上面的 Filebeat、Logstash 等），这些 Agent 会实时的将分散在不同机器、不同环境的应用日志统一的采集发到 Kafka 集群中，然后告警这边是有一个 Flink 作业去实时的消费 Kafka 数据做一个异常告警计算处理。如果还想做日志的搜索分析，可以起另外一个作业去实时的将 Kafka 的日志数据写入进 ElasticSearch，再通过 Kibana 页面做搜索和分析。</p><h3 id="日志数据发送到-Kafka"><a href="#日志数据发送到-Kafka" class="headerlink" title="日志数据发送到 Kafka"></a>日志数据发送到 Kafka</h3><p>上面已经讲了日志数据 LogEvent 的结构和样例数据，因为要在服务器部署采集工具去采集应用日志数据对于本地测试来说可能稍微复杂，所以在这里就只通过代码模拟构造数据发到 Kafka 去，然后在 Flink 作业中去实时消费 Kafka 中的数据，下面演示构造日志数据发到 Kafka 的工具类，这个工具类主要分两块，构造 LogEvent 数据和发送到 Kafka。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BuildLogEventDataUtil</span> </span>&#123;</span><br><span class="line">    <span class="comment">//Kafka broker 和 topic 信息</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BROKER_LIST = <span class="string">"localhost:9092"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LOG_TOPIC = <span class="string">"zhisheng_log"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeDataToKafka</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, BROKER_LIST);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        KafkaProducer producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//模拟构造 LogEvent 对象</span></span><br><span class="line">            LogEvent logEvent = <span class="keyword">new</span> LogEvent().builder()</span><br><span class="line">                    .type(<span class="string">"app"</span>)</span><br><span class="line">                    .timestamp(System.currentTimeMillis())</span><br><span class="line">                    .level(logLevel())</span><br><span class="line">                    .message(message(i + <span class="number">1</span>))</span><br><span class="line">                    .tags(mapData())</span><br><span class="line">                    .build();</span><br><span class="line"><span class="comment">//            System.out.println(logEvent);</span></span><br><span class="line">            ProducerRecord record = <span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(LOG_TOPIC, <span class="keyword">null</span>, <span class="keyword">null</span>, GsonUtil.toJson(logEvent));</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        writeDataToKafka();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">message</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"这是第 "</span> + i + <span class="string">" 行日志！"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">logLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"debug"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"warn"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"error"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"info"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">hostIp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> number = random.nextInt(<span class="number">4</span>);</span><br><span class="line">        <span class="keyword">switch</span> (number) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.11"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.12"</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="number">3</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.13"</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="string">"121.12.17.10"</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Map&lt;String, String&gt; <span class="title">mapData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        map.put(<span class="string">"app_id"</span>, <span class="string">"11"</span>);</span><br><span class="line">        map.put(<span class="string">"app_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"cluster_name"</span>, <span class="string">"zhisheng"</span>);</span><br><span class="line">        map.put(<span class="string">"host_ip"</span>, hostIp());</span><br><span class="line">        map.put(<span class="string">"class"</span>, <span class="string">"BuildLogEventDataUtil"</span>);</span><br><span class="line">        map.put(<span class="string">"method"</span>, <span class="string">"main"</span>);</span><br><span class="line">        map.put(<span class="string">"line"</span>, String.valueOf(<span class="keyword">new</span> Random().nextInt(<span class="number">100</span>)));</span><br><span class="line">        <span class="comment">//add more tag</span></span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果之前 Kafka 中没有 zhisheng_log 这个 topic，运行这个工具类之后也会自动创建这个 topic 了。</p><h3 id="Flink-实时处理日志数据"><a href="#Flink-实时处理日志数据" class="headerlink" title="Flink 实时处理日志数据"></a>Flink 实时处理日志数据</h3><p>在 3.7 章中已经讲过如何使用 Flink Kafka connector 了，接下来就直接写代码去消费 Kafka 中的日志数据，作业代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogEventAlert</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ParameterTool parameterTool = ExecutionEnvUtil.createParameterTool(args);</span><br><span class="line">        StreamExecutionEnvironment env = ExecutionEnvUtil.prepare(parameterTool);</span><br><span class="line">        Properties properties = KafkaConfigUtil.buildKafkaProps(parameterTool);</span><br><span class="line">        FlinkKafkaConsumer011&lt;LogEvent&gt; consumer = <span class="keyword">new</span> FlinkKafkaConsumer011&lt;&gt;(</span><br><span class="line">                parameterTool.get(<span class="string">"log.topic"</span>),</span><br><span class="line">                <span class="keyword">new</span> LogSchema(),</span><br><span class="line">                properties);</span><br><span class="line">        env.addSource(consumer)</span><br><span class="line">                .print();</span><br><span class="line">        env.execute(<span class="string">"log event alert"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为 Kafka 的日志数据是 JSON 的，所以在消费的时候需要额外定义 Schema 来反序列化数据，定义的 LogSchema 如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogSchema</span> <span class="keyword">implements</span> <span class="title">DeserializationSchema</span>&lt;<span class="title">LogEvent</span>&gt;, <span class="title">SerializationSchema</span>&lt;<span class="title">LogEvent</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Gson gson = <span class="keyword">new</span> Gson();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> LogEvent <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> gson.fromJson(<span class="keyword">new</span> String(bytes), LogEvent.class);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEndOfStream</span><span class="params">(LogEvent logEvent)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(LogEvent logEvent) &#123;</span><br><span class="line">        <span class="keyword">return</span> gson.toJson(logEvent).getBytes(Charset.forName(<span class="string">"UTF-8"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> TypeInformation&lt;LogEvent&gt; <span class="title">getProducedType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> TypeInformation.of(LogEvent.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置文件中设置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka.brokers=localhost:9092</span><br><span class="line">kafka.group.id=zhisheng</span><br><span class="line">log.topic=zhisheng_log</span><br></pre></td></tr></table></figure><p>接下来先启动 Kafka，然后运行 BuildLogEventDataUtil 工具类，往 Kafka 中发送模拟的日志数据，接下来运行 LogEventAlert 类，去消费将 Kafka 中的数据做一个验证，运行结果如下图所示，可以发现有日志数据打印出来了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-072350.png" alt=""></p><h3 id="处理应用异常日志"><a href="#处理应用异常日志" class="headerlink" title="处理应用异常日志"></a>处理应用异常日志</h3><p>上面已经能够处理这些日志数据了，但是需求是要将应用的异常日志做告警，所以在消费到所有的数据后需要过滤出异常的日志，比如可以使用 filter 算子进行过滤。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.filter(logEvent -&gt; <span class="string">"error"</span>.equals(logEvent.getLevel()))</span><br></pre></td></tr></table></figure><p>过滤后只有 error 的日志数据打印出来了，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-073245.png" alt=""></p><p>再将作业打包通过 UI 提交到集群运行的结果如下：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-10-13-080120.png" alt=""></p><p>再获取到这些 Error 类型的数据后，就可以根据这个数据构造成一个新的 Event，组装成告警消息，然后在 Sink 处调用下游的通知策略进行告警通知，当然这些告警通知策略可能会很多，然后还有收敛策略。具体的通知策略和收敛策略在这节不做细讲，最后发出的应用异常日志告警消息中会携带一个链接，点击该链接可以跳转到对应的应用异常页面，这样就可以查看应用堆栈的详细日志，更加好定位问题。</p><h3 id="小结与反思"><a href="#小结与反思" class="headerlink" title="小结与反思"></a>小结与反思</h3><p>本节开始讲了日志处理方案的演进，接着分析最新日志方案的实现架构，包含它的日志结构设计和异常日志实时告警的方案，然后通过模拟日志数据发送到 Kafka，Flink 实时去处理这种日志的数据进行告警。</p><p>本节涉及的代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-monitor/flink-learning-monitor-alert">flink-learning-monitor-alert</a></p><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据时代，随着公司业务不断的增长，数据量自然也会跟着不断的增长，那么业务应用和集群服务器的的规模也会逐渐扩大，几百台服务器在一般的公司已经是很常见的了。那么将应用服务部署在如此多的服务器上，对开发和运维人员来说都是一个挑战。一个优秀的系统运维平台是需要将部署在这么多服务器上的应用监控信息汇总成一个统一的数据展示平台，方便运维人员做日常的监测、提升运维效率，还可以及时反馈应用的运行状态给应用开发人员。举个例子，应用的运行日志需要按照时间排序做一个展示，并且提供日志下载和日志搜索等服务，这样如果应用出现问题开发人员首先可以根据应用日志的错误信息进行问题的排查。那么该如何实时的将应用的 Error 日志推送给应用开发人员呢，接下来我们将讲解日志的处理方案。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 能否动态更改 Checkpoint 配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/29/flink-nacos-checkpoint/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-03-01T01:35:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。</p><a id="more"></a><p>不过今天的话题不是在于去讨论 Checkpoint 的机制，因为前面两个问题都涉及到了动态的去配置 Checkpoint 的参数（是否开启和 Checkpoint 的时间间隔），而 zhisheng 我在前面通过两个视频讲解了 <a href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/">Flink 如何与 Apollo 和 Nacos 整合去动态的更改作业配置</a>，所以私底下就有同学找我咨询是否可以动态的更改 Checkpoint 配置，我当时因为知道其实有些参数是一旦初始化了之后是改不了的，但是具体什么参数我也不难全部列举，所以只好回答那位同学说：以自己实测的结果为准哈。</p><p>所以这里我就给大家演示一下到底是否可以动态的更改 Checkpoint 配置，请看我在 B 站的视频：</p><p><a href="https://www.bilibili.com/video/av92655075/">https://www.bilibili.com/video/av92655075/</a></p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=92655075&cid=158192037&page=1" allowfullscreen="true"> </iframe><p>通过这个视频，虽然我是使用 Flink 和 Nacos 整合的，作业监听到了 Checkpoint 的配置做了修改，但是可以发现其实 Checkpoint 更改后其实是不生效的。</p><p>这里仅从个人的思考来解释一下：因为 Flink 是 Lazy Evaluation（延迟执行），当程序的 main 方法执行时，我们创建的 env 会依次进行属性的初始化配置，但是数据源加载数据和数据转换等算子不会立马执行，这些算子操作会被创建并添加到程序的执行计划中去，只有当执行环境 env 的 execute 方法被显示地触发执行时，整个程序才开始执行实际的操作（StreamGraph -&gt; JobGraph -&gt; ExecutionGraph），所以在程序执行 execute 方法后再修改 env 的配置其实就不起作用了。</p><p>另外给大家来看下邱从贤(负责 Flink State 相关)对能否动态配置 Checkpoint 的回答：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-03-01-011804.png" alt=""></p><p>相关的测试代码在: <a href="https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/blob/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前段时间在社区邮件中看到有人提问是否可以动态开启 Checkpoint，昨天在钉钉群中又看到有个同学在问能够动态调整 Checkpoint 的时间，其实不仅仅是这些，在社区邮件和群里经常看到有问这块内容的问题，所以可以发现在 Flink 中其实关于 Checkpoint 相关的东西还是非常重要且解决起来比较麻烦，估计应该也困扰了不少人。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Apollo，动态更新 Flink 作业配置</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/23/flink-apollo/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-26T00:39:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>在上一篇讲解 <a href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/">Flink 与 Nacos 整合的视频</a> 中，讲过了常见的几种更新配置的方法，最常使用的可能就是通过广播流的方式，相信看完上个视频的，估计对整合 Nacos 做动态更新配置应该问题不大，zhisheng 我也觉得稍微简单，尤其 Nacos 搭建安装也比较简单。不知道大家公司有没有使用 Nacos 呢？我知道有的公司使用 Apollo 居多，所以后面就有读者问我能不能出个整合 Apollo 的视频，所以我趁着周末大晚上的时间就开始折腾了一番，本篇文章将给大家讲解与 Apollo 整合，动态的更新 Flink 配置。</p><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p><p>因为它的自身架构原因，导致安装可能会比较复杂，需要安装好多个组件，个人觉得比 Nacos 复杂，幸好的是官方的文档比较详细，跟着安装步骤来说还是没有问题的。zhisheng 我是只在自己 Mac 电脑上面安装了一个单机版的，仅为测试使用。</p><p>快速上手的请参考该链接 <a href="https://github.com/nobodyiam/apollo-build-scripts">https://github.com/nobodyiam/apollo-build-scripts</a>，这样你就能够在几分钟内在本地环境部署、启动 Apollo 配置中心。另外还提供了 Quick Start 的 Docker 版本，如果你对 Docker 比较熟悉的话，那更方便了。</p><p>主要演示流程（安装 Apollo 和整合 Flink），本人录了个视频，更方便大家去实战操作，欢迎观看：</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=91742999&cid=156618259&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-apollo</a></p><p>注意引入 Apollo 的依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.ctrip.framework.apollo<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>apollo-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Apollo，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Apollo" scheme="http://www.54tianzhisheng.cn/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>Flink 整合 Nacos，让 Flink 作业配置动态更新不再是难事</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-nacos/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-25T16:06:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！</p><a id="more"></a><p>我们知道 Flink 作业的配置一般都是通过在作业启动的时候通过参数传递的，或者通过读取配置文件的参数，在作业启动后初始化了之后如果再想更新作业的配置一般有两种解决方法：</p><ul><li><p>改变启动参数或者改变配置文件，重启作业，让作业能够读取到修改后的配置</p></li><li><p>通过读取配置流（需要自定义 Source 读取配置），然后流和流连接起来</p></li></ul><p>这两种解决方法一般是使用的比较多，对于第一种方法，zhisheng 我本人其实是不太建议的，重启作业会带来很多影响，Flink 作业完整的重启流程应该是：当作业停掉的时候需要去做一次 Savepoint（相当于把作业的状态做一次完整的快照），启动的时候又需要将作业从 Savepoint 启动，整个流程如果状态比较大的话，做一次 Savepoint 和从 Savepoint 初始化的时间会比较久，然而流处理的场景下通常数据量都是比较大的，那么在这段时间内，可能会造成不少的数据堆积（可能分钟内就上千万或者更多），当作业启动后再去追这千万量级的数据，对作业来说压力自然会增大。</p><p>对于第二种方法也是一种用的很多的方式，自己也比较推荐，之前自己在社区直播的时候也有讲过类似的方案，但是今天我准备讲解另一种方法 —— 整合配置中心，没看见有人这么用过，我也算是第一个吃螃蟹的人了！说到配置中心，目前国内有 Apollo 和 Nacos，这里先来讲下和 Nacos 的整合，下面的实战操作请看我录制的视频。</p><iframe height=900 width=1150 src="//player.bilibili.com/player.html?aid=90742627&cid=154955963&page=1" allowfullscreen="true"> </iframe><p>代码地址：<a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-configration-center/flink-learning-configration-center-nacos</a></p><p>我本人安装的 Nacos 依赖是阿里的，因为自己本地编译了一份源码，所以可能会有这些依赖在自己本地的 .m2 目录中：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.nacos<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>nacos-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.1.4<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>但是有些同学反馈说上面的依赖引入不上，一直下载不了，比如 nacos-core，这里建议去 <a href="https://mvnrepository.com/search?q=nacos-core">https://mvnrepository.com/search?q=nacos-core</a> 看一下第一个，然后引用试试。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人自己录的视频，讲解 Flink 整和 Nacos，动态更新作业配置，无需重启作业！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink 1.10 新特性研究</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/22/flink-1.10-release/</id>
    <published>2020-02-21T16:00:00.000Z</published>
    <updated>2020-02-22T13:34:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。</p><a id="more"></a><h3 id="集群和部署"><a href="#集群和部署" class="headerlink" title="集群和部署"></a>集群和部署</h3><ul><li><p>文件系统需要通过插件的方式加载</p></li><li><p>Flink 客户端根据配置的类加载策略加载，parent-first 和 child-first 两种方式</p></li><li><p>允许在所有的 TaskManager 上均匀地分布任务，需要在 <code>flink-conf.yaml</code> 配置文件中配置 <code>cluster.evenly-spread-out-slots: true</code> 参数</p></li><li><p>高可用存储目录做了修改，在 <code>HA_STORAGE_DIR/HA_CLUSTER_ID</code> 下，<code>HA_STORAGE_DIR</code> 路径通过 <code>high-availability.storageDir</code> 参数配置，<code>HA_CLUSTER_ID</code> 路径通过 <code>high-availability.cluster-id</code> 参数配置</p></li><li><p>当使用 <code>-yarnship</code> 命令参数时，资源目录和 jar 文件会被添加到 classpath 中</p></li><li><p>移除了 <code>--yn/--yarncontainer</code> 命令参数</p></li><li><p>移除了 <code>--yst/--yarnstreaming</code> 命令参数</p></li><li><p>Flink Mesos 会拒绝掉所有的过期请求</p></li><li><p>重构了 Flink 的调度程序，其目标是使调度策略在未来可以定制</p></li><li><p>支持 Java 11，当使用 Java 11 启动 Flink 时，会有些 WARNING 的日志提醒，注意：Cassandra、Hive、HBase 等 connector 没有使用 Java 11 测试过</p></li></ul><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><ul><li>全新的 Task Executor 内存模型，会影响 standalone、YARN、Mesos、K8S 的部署，JobManager 的内存模型没有修改。如果你在没有调整的情况下，重用以前的 Flink 配置，则新的内存模型可能会导致 JVM 的计算内存参数不同，从而导致性能的变化。</li></ul><p>以下选项已经删除，不再起作用：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074438.png" alt=""></p><p>以下选项已经替换成其他的选项：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-02-21-074623.png" alt=""></p><ul><li><p>RocksDB State Backend 内存可以控制，用户可以调整 RocksDB 的写/读内存比率 <code>state.backend.rocksdb.memory.write-buffer-ratio</code>（默认情况下 0.5）和为索引/过滤器保留的内存部分 <code>state.backend.rocksdb.memory.high-prio-pool-ratio</code>（默认情况下0.1）</p></li><li><p>细粒度的算子（Operator）资源管理，配置选项 <code>table.exec.resource.external-buffer-memory</code>，<code>table.exec.resource.hash-agg.memory</code>，<code>table.exec.resource.hash-join.memory</code>，和 <code>table.exec.resource.sort.memory</code> 已被弃用</p></li></ul><h3 id="Table-API-和-SQL"><a href="#Table-API-和-SQL" class="headerlink" title="Table API 和 SQL"></a>Table API 和 SQL</h3><ul><li><p>将 ANY 类型重命名为 RAW 类型，该标识符 raw 现在是保留关键字，在用作 SQL 字段或函数名称时必须转义</p></li><li><p>重命名 Table Connector 属性，以便编写 DDL 语句时提供更好的用户体验，比如 Kafka Connector 属性 <code>connector.properties</code> 和 <code>connector.specific-offsets</code>、Elasticsearch Connector 属性 <code>connector.hosts</code></p></li><li><p>之前与临时表和视图进行交互的方法已经被弃用，目前使用 createTemporaryView()</p></li><li><p>移除了 ExternalCatalog API（ExternalCatalog、SchematicDescriptor、MetadataDescriptor、StatisticsDescriptor），建议使用新的 Catalog API</p></li></ul><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><ul><li><p>ConfigOptions 如果无法将配置的值解析成所需要的类型，则会抛出 IllegalArgumentException 异常，之前是会返回默认值</p></li><li><p>增加默认的重启策略延迟时间（fixed-delay 和 failure-rate 已经默认是 1s，之前是 0）</p></li><li><p>简化集群级别的重启策略配置，现在集群级别的重启策略仅由 restart-strategy 配置和是否开启 Checkpoint 确定</p></li><li><p>默认情况下禁用内存映射的 BoundedBlockingSubpartition</p></li><li><p>移除基于未认证的网络流量控制</p></li><li><p>移除 HighAvailabilityOptions 中的 HA_JOB_DELAY 配置</p></li></ul><h3 id="状态（State）"><a href="#状态（State）" class="headerlink" title="状态（State）"></a>状态（State）</h3><ul><li><p>默认开启 TTL 的状态后台清理</p></li><li><p>弃用 <code>StateTtlConfig#Builder#cleanupInBackground()</code></p></li><li><p>使用 RocksDBStateBackend 时，默认将计时器存储在 RocksDB 中，之前是存储在堆内存（Heap）中</p></li><li><p><code>StateTtlConfig#TimeCharacteristic</code> 已经被移除，目前使用 <code>StateTtlConfig#TtlTimeCharacteristic</code></p></li><li><p>新增 <code>MapState#isEmpty()</code> 方法来检查 MapState 是否为空，该方法比使用 <code>mapState.keys().iterator().hasNext()</code> 的速度快 40%</p></li><li><p>RocksDB 升级，发布了自己的 FRocksDB（基于 RocksDB 5.17.2 版本），主要是因为高版本的 RocksDB 在某些情况下性能会下降</p></li><li><p>默认禁用 RocksDB 日志记录，需要启用的话需要利用 RocksDBOptionsFactory 创建 DBOptions 实例，并通过 setInfoLogLevel 方法设置 INFO_LEVEL</p></li><li><p>优化从 RocksDB Savepoint 恢复的机制，以前如果从包含大型 KV 对的 RocksDB Savepoint 恢复时，用户可能会遇到 OOM。现在引入了可配置的内存限制，RocksDBWriteBatchWrapper 默认值为 2MB。RocksDB的WriteBatch 将在达到内存限制之前刷新。可以在 <code>flink-conf.yml</code> 中修改 <code>state.backend.rocksdb.write-batch-size</code> 配置</p></li></ul><h3 id="PyFlink"><a href="#PyFlink" class="headerlink" title="PyFlink"></a>PyFlink</h3><ul><li>不再支持 Python2</li></ul><h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><ul><li>InfluxdbReporter 会跳过 Inf 和 NaN（InfluxDB 不支持的类型，比如 <code>Double.POSITIVE_INFINITY</code>, <code>Double.NEGATIVE_INFINITY</code>, <code>Double.NaN</code>）</li></ul><h3 id="连接器（Connectors）"><a href="#连接器（Connectors）" class="headerlink" title="连接器（Connectors）"></a>连接器（Connectors）</h3><ul><li>改变 Kinesis 连接器的 License</li></ul><h3 id="接口更改"><a href="#接口更改" class="headerlink" title="接口更改"></a>接口更改</h3><ul><li><p><code>ExecutionConfig＃getGlobalJobParameters()</code> 不再返回 null</p></li><li><p>MasterTriggerRestoreHook 中的 triggerCheckpoint 方法必须时非阻塞的</p></li><li><p>HA 服务的客户端/服务器端分离，HighAvailabilityServices 已分离成客户端 ClientHighAvailabilityServices 和集群端 HighAvailabilityServices</p></li><li><p><code>HighAvailabilityServices#getWebMonitorLeaderElectionService()</code> 标记过期</p></li><li><p>LeaderElectionService 接口做了更改</p></li><li><p>弃用 Checkpoint 锁</p></li><li><p>弃用 OptionsFactory 和 ConfigurableOptionsFactory 接口</p></li></ul><p>参考：<a href="https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md">https://github.com/apache/flink/blob/master/docs/release-notes/flink-1.10.zh.md</a></p><hr><p>看了下官方的这份新版本的介绍，感觉还缺少很多新功能的介绍，比如：</p><ul><li>在 1.10 版本中把 Blink 版本的哪些功能整合过来了</li><li>竟然没有写 Flink 对原生 Kubernetes 的集成</li><li>PyFlink 的介绍是认真的吗？</li><li>对 Hive 的生产级别集成，完全没有提及呀</li><li>Table API/SQL 优化点讲得不太多</li></ul><p>可能因为篇幅的问题，还有很多特性都没有讲解出来，得我们自己去找源码学习！</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink 1.10 release 文档描述了一些比较重要的点，比如配置、操作、依赖、1.9 版本和 1.10 版本之间的区别，如果你准备将 Flink 升级到 1.10 版本，建议仔细看完下面的内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="Nacos" scheme="http://www.54tianzhisheng.cn/tags/Nacos/"/>
    
  </entry>
  
  <entry>
    <title>Flink Checkpoint 问题排查实用指南</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/20/flink-checkpoint/</id>
    <published>2020-02-19T16:00:00.000Z</published>
    <updated>2020-02-20T01:36:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。</p><a id="more"></a><p>作者：邱从贤（山智）<br>转载自：<a href="">https://www.jianshu.com/p/fc100f85a0fb</a></p><p>在实际情况中，我们可能会遇到 Checkpoint 失败，或者 Checkpoint 慢的情况，本文会统一聊一聊 Flink 中 Checkpoint 异常的情况（包括失败和慢），以及可能的原因和排查思路。</p><h3 id="1-Checkpoint-流程简介"><a href="#1-Checkpoint-流程简介" class="headerlink" title="1. Checkpoint 流程简介"></a>1. Checkpoint 流程简介</h3><p>首先我们需要了解 Flink 中 Checkpoint 的整个流程是怎样的，在了解整个流程之后，我们才能在出问题的时候，更好的进行定位分析。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012549.jpg" alt=""></p><p>从上图我们可以知道，Flink 的 Checkpoint 包括如下几个部分：</p><ul><li>JM trigger checkpoint</li><li>Source 收到 trigger checkpoint 的 PRC，自己开始做 snapshot，并往下游发送 barrier</li><li>下游接收 barrier（需要 barrier 都到齐才会开始做 checkpoint）</li><li>Task 开始同步阶段 snapshot</li><li>Task 开始异步阶段 snapshot</li><li>Task snapshot 完成，汇报给 JM</li></ul><p>上面的任何一个步骤不成功，整个 checkpoint 都会失败。</p><h3 id="2-Checkpoint-异常情况排查"><a href="#2-Checkpoint-异常情况排查" class="headerlink" title="2 Checkpoint 异常情况排查"></a>2 Checkpoint 异常情况排查</h3><h4 id="2-1-Checkpoint-失败"><a href="#2-1-Checkpoint-失败" class="headerlink" title="2.1 Checkpoint 失败"></a>2.1 Checkpoint 失败</h4><p>可以在 Checkpoint 界面看到如下图所示，下图中 Checkpoint 10423 失败了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012649.jpg" alt=""></p><p>点击 Checkpoint 10423 的详情，我们可以看到类系下图所示的表格（下图中将 operator 名字截取掉了）。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-012705.jpg" alt=""></p><p>上图中我们看到三行，表示三个 operator，其中每一列的含义分别如下：</p><ul><li>其中 Acknowledged 一列表示有多少个 subtask 对这个 Checkpoint 进行了 ack，从图中我们可以知道第三个 operator 总共有 5 个 subtask，但是只有 4 个进行了 ack；</li><li>第二列 Latest Acknowledgement 表示该 operator 的所有 subtask 最后 ack 的时间；</li><li>End to End Duration 表示整个 operator 的所有 subtask 中完成 snapshot 的最长时间；</li><li>State Size 表示当前 Checkpoint 的 state 大小 – 主要这里如果是增量 checkpoint 的话，则表示增量大小；</li><li>Buffered During Alignment 表示在 barrier 对齐阶段积攒了多少数据，如果这个数据过大也间接表示对齐比较慢）；</li></ul><p>Checkpoint 失败大致分为两种情况：Checkpoint Decline 和 Checkpoint Expire。</p><h5 id="2-1-1-Checkpoint-Decline"><a href="#2-1-1-Checkpoint-Decline" class="headerlink" title="2.1.1 Checkpoint Decline"></a>2.1.1 Checkpoint Decline</h5><p>我们能从 jobmanager.log 中看到类似下面的日志</p><p>Decline checkpoint 10423 by task 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178. 其中<br>10423 是 checkpointID，0b60f08bf8984085b59f8d9bc74ce2e1 是 execution id，85d268e6fbc19411185f7e4868a44178 是 job id，我们可以在 jobmanager.log 中查找 execution id，找到被调度到哪个 taskmanager 上，类似如下所示：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - XXXXXXXXXXX (100/289) (87b751b1fd90e32af55f02bb2f9a9892) switched from SCHEDULED to DEPLOYING.</span><br><span class="line">2019-09-02 16:26:20,972 INFO  [jobmanager-future-thread-61] org.apache.flink.runtime.executiongraph.ExecutionGraph        - Deploying XXXXXXXXXXX (100/289) (attempt #0) to slot container_e24_1566836790522_8088_04_013155_1 on hostnameABCDE</span><br></pre></td></tr></table></figure><p>从上面的日志我们知道该 execution 被调度到 hostnameABCDE 的 container_e24_1566836790522_8088_04_013155_1 slot 上，接下来我们就可以到 container container_e24_1566836790522_8088_04_013155 的 taskmanager.log 中查找 Checkpoint 失败的具体原因了。</p><p>另外对于 Checkpoint Decline 的情况，有一种情况我们在这里单独抽取出来进行介绍：Checkpoint Cancel。</p><p>当前 Flink 中如果较小的 Checkpoint 还没有对齐的情况下，收到了更大的 Checkpoint，则会把较小的 Checkpoint 给取消掉。我们可以看到类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$taskNameWithSubTaskAndID: Received checkpoint barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>这个日志表示，当前 Checkpoint 19 还在对齐阶段，我们收到了 Checkpoint 20 的 barrier。然后会逐级通知到下游的 task checkpoint 19 被取消了，同时也会通知 JM 当前 Checkpoint 被 decline 掉了。</p><p>在下游 task 收到被 cancelBarrier 的时候，会打印类似如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, aborting alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">DEBUG</span><br><span class="line">$taskNameWithSubTaskAndID: Checkpoint 19 canceled, skipping alignment.</span><br><span class="line"></span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">WARN</span><br><span class="line">$taskNameWithSubTaskAndID: Received cancellation barrier for checkpoint 20 before completing current checkpoint 19. Skipping current checkpoint.</span><br></pre></td></tr></table></figure><p>上面三种日志都表示当前 task 接收到上游发送过来的 barrierCancel 消息，从而取消了对应的 Checkpoint。</p><h5 id="2-1-2-Checkpoint-Expire"><a href="#2-1-2-Checkpoint-Expire" class="headerlink" title="2.1.2 Checkpoint Expire"></a>2.1.2 Checkpoint Expire</h5><p>如果 Checkpoint 做的非常慢，超过了 timeout 还没有完成，则整个 Checkpoint 也会失败。当一个 Checkpoint 由于超时而失败是，会在 jobmanager.log 中看到如下的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Checkpoint 1 of job 85d268e6fbc19411185f7e4868a44178  expired before completing.</span><br></pre></td></tr></table></figure><p>表示 Chekpoint 1 由于超时而失败，这个时候可以可以看这个日志后面是否有类似下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Received late message for now expired checkpoint attempt 1 from 0b60f08bf8984085b59f8d9bc74ce2e1 of job 85d268e6fbc19411185f7e4868a44178.</span><br></pre></td></tr></table></figure><p>可以按照 2.1.1 中的方法找到对应的 taskmanager.log 查看具体信息。</p><blockquote><p>下面的日志如果是 DEBUG 的话，我们会在开始处标记 DEBUG</p></blockquote><p>我们按照下面的日志把 TM 端的 snapshot 分为三个阶段，开始做 snapshot 前，同步阶段，异步阶段：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>这个日志表示 TM 端 barrier 对齐后，准备开始做 Checkpoint。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">2019-08-06 13:43:02,613 DEBUG org.apache.flink.runtime.state.AbstractSnapshotStrategy       - DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@70442baf, checkpointDirectory=xxxxxxxx, sharedStateDirectory=xxxxxxxx, taskOwnedStateDirectory=xxxxxx, metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, synchronous part) in thread Thread[Async calls on Source: xxxxxx</span><br><span class="line">_source -&gt; Filter (27/70),5,Flink Task Threads] took 0 ms.</span><br></pre></td></tr></table></figure><p>上面的日志表示当前这个 backend 的同步阶段完成，共使用了 0 ms。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">DefaultOperatorStateBackend snapshot (FsCheckpointStorageLocation &#123;fileSystem=org.apache.flink.core.fs.SafetyNetWrapperFileSystem@7908affe, checkpointDirectory=xxxxxx, sharedStateDirectory=xxxxx, taskOwnedStateDirectory=xxxxx,  metadataFilePath=xxxxxx, reference=(default), fileStateSizeThreshold=1024&#125;, asynchronous part) in thread Thread[pool-48-thread-14,5,Flink Task Threads] took 369 ms</span><br></pre></td></tr></table></figure><p>上面的日志表示异步阶段完成，异步阶段使用了 369 ms</p><p>在现有的日志情况下，我们通过上面三个日志，定位 snapshot 是开始晚，同步阶段做的慢，还是异步阶段做的慢。然后再按照情况继续进一步排查问题。</p><h4 id="2-2-Checkpoint-慢"><a href="#2-2-Checkpoint-慢" class="headerlink" title="2.2 Checkpoint 慢"></a>2.2 Checkpoint 慢</h4><p>在 2.1 节中，我们介绍了 Checkpoint 失败的排查思路，本节会分情况介绍 Checkpoint 慢的情况。</p><p>Checkpoint 慢的情况如下：比如 Checkpoint interval 1 分钟，超时 10 分钟，Checkpoint 经常需要做 9 分钟（我们希望 1 分钟左右就能够做完），而且我们预期 state size 不是非常大。</p><p>对于 Checkpoint 慢的情况，我们可以按照下面的顺序逐一检查。</p><h5 id="2-2-0-Source-Trigger-Checkpoint-慢"><a href="#2-2-0-Source-Trigger-Checkpoint-慢" class="headerlink" title="2.2.0 Source Trigger Checkpoint 慢"></a>2.2.0 Source Trigger Checkpoint 慢</h5><p>这个一般发生较少，但是也有可能，因为 source 做 snapshot 并往下游发送 barrier 的时候，需要抢锁（这个现在社区正在进行用 mailBox 的方式替代当前抢锁的方式，详情参考[1])。如果一直抢不到锁的话，则可能导致 Checkpoint 一直得不到机会进行。如果在 Source 所在的 taskmanager.log 中找不到开始做 Checkpoint 的 log，则可以考虑是否属于这种情况，可以通过 jstack 进行进一步确认锁的持有情况。</p><h5 id="2-2-1-使用增量-Checkpoint"><a href="#2-2-1-使用增量-Checkpoint" class="headerlink" title="2.2.1 使用增量 Checkpoint"></a>2.2.1 使用增量 Checkpoint</h5><p>现在 Flink 中 Checkpoint 有两种模式，全量 Checkpoint 和 增量 Checkpoint，其中全量 Checkpoint 会把当前的 state 全部备份一次到持久化存储，而增量 Checkpoint，则只备份上一次 Checkpoint 中不存在的 state，因此增量 Checkpoint 每次上传的内容会相对更好，在速度上会有更大的优势。</p><p>现在 Flink 中仅在 RocksDBStateBackend 中支持增量 Checkpoint，如果你已经使用 RocksDBStateBackend，可以通过开启增量 Checkpoint 来加速，具体的可以参考 [2]。</p><h5 id="2-2-2-作业存在反压或者数据倾斜"><a href="#2-2-2-作业存在反压或者数据倾斜" class="headerlink" title="2.2.2 作业存在反压或者数据倾斜"></a>2.2.2 作业存在反压或者数据倾斜</h5><p>我们知道 task 仅在接受到所有的 barrier 之后才会进行 snapshot，如果作业存在反压，或者有数据倾斜，则会导致全部的 channel 或者某些 channel 的 barrier 发送慢，从而整体影响 Checkpoint 的时间，这两个可以通过如下的页面进行检查：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013106.jpg" alt=""></p><p>上图中我们选择了一个 task，查看所有 subtask 的反压情况，发现都是 high，表示反压情况严重，这种情况下会导致下游接收 barrier 比较晚。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-20-013126.jpg" alt=""></p><p>上图中我们选择其中一个 operator，点击所有的 subtask，然后按照 Records Received/Bytes Received/TPS 从大到小进行排序，能看到前面几个 subtask 会比其他的 subtask 要处理的数据多。</p><p>如果存在反压或者数据倾斜的情况，我们需要首先解决反压或者数据倾斜问题之后，再查看 Checkpoint 的时间是否符合预期。</p><h5 id="2-2-2-Barrier-对齐慢"><a href="#2-2-2-Barrier-对齐慢" class="headerlink" title="2.2.2 Barrier 对齐慢"></a>2.2.2 Barrier 对齐慢</h5><p>从前面我们知道 Checkpoint 在 task 端分为 barrier 对齐（收齐所有上游发送过来的 barrier），然后开始同步阶段，再做异步阶段。如果 barrier 一直对不齐的话，就不会开始做 snapshot。</p><p>barrier 对齐之后会有如下日志打印：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Starting checkpoint (6751) CHECKPOINT on task taskNameWithSubtasks (4/4)</span><br></pre></td></tr></table></figure><p>如果 taskmanager.log 中没有这个日志，则表示 barrier 一直没有对齐，接下来我们需要了解哪些上游的 barrier 没有发送下来，如果你使用 At Least Once 的话，可以观察下面的日志：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEBUG</span><br><span class="line">Received barrier for checkpoint 96508 from channel 5</span><br></pre></td></tr></table></figure><p>表示该 task 收到了 channel 5 来的 barrier，然后看对应 Checkpoint，再查看还剩哪些上游的 barrier 没有接受到，对于 ExactlyOnce 暂时没有类似的日志，可以考虑自己添加，或者 jmap 查看。</p><h5 id="2-2-3-主线程太忙，导致没机会做-snapshot"><a href="#2-2-3-主线程太忙，导致没机会做-snapshot" class="headerlink" title="2.2.3 主线程太忙，导致没机会做 snapshot"></a>2.2.3 主线程太忙，导致没机会做 snapshot</h5><p>在 task 端，所有的处理都是单线程的，数据处理和 barrier 处理都由主线程处理，如果主线程在处理太慢（比如使用 RocksDBBackend，state 操作慢导致整体处理慢），导致 barrier 处理的慢，也会影响整体 Checkpoint 的进度，在这一步我们需要能够查看某个 PID 对应 hotmethod，这里推荐两个方法：</p><ul><li>多次连续 jstack，查看一直处于 RUNNABLE 状态的线程有哪些；</li><li>使用工具 AsyncProfile dump 一份火焰图，查看占用 CPU 最多的栈；</li></ul><p>如果有其他更方便的方法当然更好，也欢迎推荐。</p><h5 id="2-2-4-同步阶段做的慢"><a href="#2-2-4-同步阶段做的慢" class="headerlink" title="2.2.4 同步阶段做的慢"></a>2.2.4 同步阶段做的慢</h5><p>同步阶段一般不会太慢，但是如果我们通过日志发现同步阶段比较慢的话，对于非 RocksDBBackend 我们可以考虑查看是否开启了异步 snapshot，如果开启了异步 snapshot 还是慢，需要看整个 JVM 在干嘛，也可以使用前一节中的工具。对于 RocksDBBackend 来说，我们可以用 iostate 查看磁盘的压力如何，另外可以查看 tm 端 RocksDB 的 log 的日志如何，查看其中 SNAPSHOT 的时间总共开销多少。</p><p>RocksDB 开始 snapshot 的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:55.734684 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:83] Started the snapshot process -- creating snapshot in directory /tmp/flink-io-87c360ce-0b98-48f4-9629-2cf0528d5d53/XXXXXXXXXXX/chk-92729</span><br></pre></td></tr></table></figure><p>snapshot 结束的日志如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019/09/10-14:22:56.001275 7fef66ffd700 [utilities/checkpoint/checkpoint_impl.cc:145] Snapshot DONE. All is good</span><br></pre></td></tr></table></figure><p>#####2.2.6 异步阶段做的慢</p><p>对于异步阶段来说，tm 端主要将 state 备份到持久化存储上，对于非 RocksDBBackend 来说，主要瓶颈来自于网络，这个阶段可以考虑观察网络的 metric，或者对应机器上能够观察到网络流量的情况（比如 iftop)。</p><p>对于 RocksDB 来说，则需要从本地读取文件，写入到远程的持久化存储上，所以不仅需要考虑网络的瓶颈，还需要考虑本地磁盘的性能。另外对于 RocksDBBackend 来说，如果觉得网络流量不是瓶颈，但是上传比较慢的话，还可以尝试考虑开启多线程上传功能[3]。</p><h3 id="3-总结"><a href="#3-总结" class="headerlink" title="3 总结"></a>3 总结</h3><p>在第二部分内容中，我们介绍了官方编译的包的情况下排查一些 Checkpoint 异常情况的主要场景，以及相应的排查方法，如果排查了上面所有的情况，还是没有发现瓶颈所在，则可以考虑添加更详细的日志，逐步将范围缩小，然后最终定位原因。</p><p>上文提到的一些 DEBUG 日志，如果 flink dist 包是自己编译的话，则建议将 Checkpoint 整个步骤内的一些 DEBUG 改为 INFO，能够通过日志了解整个 Checkpoint 的整体阶段，什么时候完成了什么阶段，也在 Checkpoint 异常的时候，快速知道每个阶段都消耗了多少时间。</p><h3 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h3><p>[1]、<a href="https://issues.apache.org/jira/browse/FLINK-12477">Change threading-model in StreamTask to a mailbox-based approach</a><br>[2]、<a href="https://mp.weixin.qq.com/s/rIgrAscMIJLPpfKytmp4Mw">增量 checkpoint 原理介绍</a><br>[3]、<a href="https://issues.apache.org/jira/browse/FLINK-11008">RocksDBStateBackend 多线程上传 State</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在 Flink 中，状态可靠性保证由 Checkpoint 支持，当作业出现 failover 的情况下，Flink 会从最近成功的 Checkpoint 恢复。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Apache Flink 1.10.0 重磅发布，新特性解读</title>
    <link href="http://www.54tianzhisheng.cn/2020/02/11/flink-1.10/"/>
    <id>http://www.54tianzhisheng.cn/2020/02/11/flink-1.10/</id>
    <published>2020-02-10T16:00:00.000Z</published>
    <updated>2020-02-15T14:10:12.000Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Flink 社区迎来了激动人心的两位数位版本号，Flink 1.10.0 正式宣告发布！</p><a id="more"></a><p>作为 Flink 社区迄今为止规模最大的一次版本升级，Flink 1.10 容纳了超过 200 位贡献者对超过 1200 个 issue 的开发实现，包含对 Flink 作业的整体性能及稳定性的显著优化、对原生 Kubernetes 的初步集成以及对 Python 支持（PyFlink）的重大优化。</p><p>Flink 1.10 同时还标志着对 Blink 的整合宣告完成，随着对 Hive 的生产级别集成及对 TPC-DS 的全面覆盖，Flink 在增强流式 SQL 处理能力的同时也具备了成熟的批处理能力。本篇博客将对此次版本升级中的主要新特性及优化、值得注意的重要变化以及使用新版本的预期效果逐一进行介绍。</p><p>新版本的二进制发布包和源码包已经可以在最新的 Flink 官网<a href="https://flink.apache.org/downloads.html">下载页面</a>找到。更多细节请参考完整的版本<a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&amp;version=12345845">更新日志</a>以及最新的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/">用户文档</a>。</p><h2 id="新特性及优化"><a href="#新特性及优化" class="headerlink" title="新特性及优化"></a>新特性及优化</h2><h3 id="内存管理及配置优化"><a href="#内存管理及配置优化" class="headerlink" title="内存管理及配置优化"></a>内存管理及配置优化</h3><p>Flink 目前的 TaskExecutor 内存模型存在着一些缺陷，导致优化资源利用率比较困难，例如：</p><ul><li>流和批处理内存占用的配置模型不同；</li><li>流处理中的 RocksDB state backend 需要依赖用户进行复杂的配置。</li></ul><p>为了让内存配置变的对于用户更加清晰、直观，Flink 1.10 对 TaskExecutor 的内存模型和配置逻辑进行了较大的改动 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-49%3A+Unified+Memory+Configuration+for+TaskExecutors">FLIP-49</a>。这些改动使得 Flink 能够更好地适配所有部署环境（例如 Kubernetes, Yarn, Mesos），让用户能够更加严格的控制其内存开销。</p><h4 id="Managed-内存扩展"><a href="#Managed-内存扩展" class="headerlink" title="Managed 内存扩展"></a>Managed 内存扩展</h4><p>Managed 内存的范围有所扩展，还涵盖了 RocksDB state backend 使用的内存。尽管批处理作业既可以使用堆内内存也可以使用堆外内存，使用 RocksDB state backend 的流处理作业却只能利用堆外内存。因此为了让用户执行流和批处理作业时无需更改集群的配置，我们规定从现在起 managed 内存只能在堆外。</p><h4 id="简化-RocksDB-配置"><a href="#简化-RocksDB-配置" class="headerlink" title="简化 RocksDB 配置"></a>简化 RocksDB 配置</h4><p>此前，配置像 RocksDB 这样的堆外 state backend 需要进行大量的手动调试，例如减小 JVM 堆空间、设置 Flink 使用堆外内存等。现在，Flink 的开箱配置即可支持这一切，且只需要简单地改变 managed 内存的大小即可调整 RocksDB state backend 的内存预算。 </p><p>另一个重要的优化是，Flink 现在可以限制 RocksDB 的 native 内存占用（<a href="https://issues.apache.org/jira/browse/FLINK-7289">FLINK-7289</a>），以避免超过总的内存预算——这对于 Kubernetes 等容器化部署环境尤为重要。关于如何开启、调试该特性，请参考 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/state/large_state_tuning.html#tuning-rocksdb">RocksDB 调试</a>。</p><blockquote><p>注：FLIP-49 改变了集群的资源配置过程，因此从以前的 Flink 版本升级时可能需要对集群配置进行调整。详细的变更日志及调试指南请<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/memory/mem_setup.html">参考文档</a></p></blockquote><h3 id="统一的作业提交逻辑"><a href="#统一的作业提交逻辑" class="headerlink" title="统一的作业提交逻辑"></a>统一的作业提交逻辑</h3><p>在此之前，提交作业是由执行环境负责的，且与不同的部署目标（例如 Yarn, Kubernetes, Mesos）紧密相关。这导致用户需要针对不同环境保留多套配置，增加了管理的成本。</p><p>在 Flink 1.10 中，作业提交逻辑被抽象到了通用的 Executor 接口（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-73%3A+Introducing+Executors+for+job+submission">FLIP-73</a>）。新增加的 ExecutorCLI （<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=133631524">FLIP-81</a>）引入了为任意<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/cli.html#deployment-targets">执行目标</a>指定配置参数的统一方法。此外，随着引入 JobClient（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-74%3A+Flink+JobClient+API">FLINK-74</a>）负责获取 JobExecutionResult，获取作业执行结果的逻辑也得以与作业提交解耦。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-15-120628.jpg" alt=""></p><p>上述改变向用户提供了统一的 Flink 入口，使得在 Apache Beam 或 Zeppelin notebooks 等下游框架中以编程方式使用 Flink 变的更加容易。对于需要在多种不同环境使用 Flink 的用户而言，新的基于配置的执行过程同样显著降低了冗余代码量以及维护开销。</p><h3 id="原生-Kubernetes-集成（Beta）"><a href="#原生-Kubernetes-集成（Beta）" class="headerlink" title="原生 Kubernetes 集成（Beta）"></a>原生 Kubernetes 集成（Beta）</h3><p>对于想要在容器化环境中尝试 Flink 的用户来说，想要在 Kubernetes 上部署和管理一个 Flink standalone 集群，首先需要对容器、算子及像 kubectl 这样的环境工具有所了解。</p><p>在 Flink 1.10 中，我们推出了初步的支持 session 模式的主动 Kubernetes 集成（<a href="https://jira.apache.org/jira/browse/FLINK-9953">FLINK-9953</a>）。其中，“主动”指 Flink ResourceManager (K8sResMngr) 原生地与 Kubernetes 通信，像 Flink 在 Yarn 和 Mesos 上一样按需申请 pod。用户可以利用 namespace，在多租户环境中以较少的资源开销启动 Flink。这需要用户提前配置好 RBAC 角色和有足够权限的服务账号。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-02-15-120748.jpg" alt=""></p><p>正如在统一的作业提交逻辑一节中提到的，Flink 1.10 将命令行参数映射到了统一的配置。因此，用户可以参阅 Kubernetes 配置选项，在命令行中使用以下命令向 Kubernetes 提交 Flink 作业。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run -d -e kubernetes-session -Dkubernetes.cluster-id=&lt;ClusterId&gt; examples/streaming/WindowJoin.jar</span><br></pre></td></tr></table></figure><p>如果你希望第一时间尝试这一特性，欢迎参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/deployment/native_kubernetes.html">相关文档</a>、试用并与社区分享你的反馈意见。</p><h3 id="Table-API-SQL-生产可用的-Hive-集成"><a href="#Table-API-SQL-生产可用的-Hive-集成" class="headerlink" title="Table API/SQL: 生产可用的 Hive 集成"></a>Table API/SQL: 生产可用的 Hive 集成</h3><p>Flink 1.9 推出了预览版的 Hive 集成。该版本允许用户使用 SQL DDL 将 Flink 特有的元数据持久化到 Hive Metastore、调用 Hive 中定义的 UDF 以及读、写 Hive 中的表。Flink 1.10 进一步开发和完善了这一特性，带来了全面兼容 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/hive/#supported-hive-versions">Hive 主要版本</a>的生产可用的 Hive 集成。</p><h4 id="Batch-SQL-原生分区支持"><a href="#Batch-SQL-原生分区支持" class="headerlink" title="Batch SQL 原生分区支持"></a>Batch SQL 原生分区支持</h4><p>此前，Flink 只支持写入未分区的 Hive 表。在 Flink 1.10 中，Flink SQL 扩展支持了 INSERT OVERWRITE 和 PARTITION 的语法（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-63%3A+Rework+table+partition+support">FLIP-63</a>），允许用户写入 Hive 中的静态和动态分区。</p><ul><li>写入静态分区</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT &#123; INTO | OVERWRITE &#125; TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement;</span><br></pre></td></tr></table></figure><ul><li>写入动态分区</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT &#123; INTO | OVERWRITE &#125; TABLE tablename1 select_statement1 FROM from_statement;</span><br></pre></td></tr></table></figure><p>对分区表的全面支持，使得用户在读取数据时能够受益于分区剪枝，减少了需要扫描的数据量，从而大幅提升了这些操作的性能。</p><h4 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h4><p>除了分区剪枝，Flink 1.10 的 Hive 集成还引入了许多<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/hive/read_write_hive.html#optimizations">数据读取</a>方面的优化，例如：</p><ul><li>投影下推：Flink 采用了投影下推技术，通过在扫描表时忽略不必要的域，最小化 Flink 和 Hive 表之间的数据传输量。这一优化在表的列数较多时尤为有效。</li><li>LIMIT 下推：对于包含 LIMIT 语句的查询，Flink 在所有可能的地方限制返回的数据条数，以降低通过网络传输的数据量。</li><li>读取数据时的 ORC 向量化： 为了提高读取 ORC 文件的性能，对于 Hive 2.0.0 及以上版本以及非复合数据类型的列，Flink 现在默认使用原生的 ORC 向量化读取器。</li></ul><h4 id="将可插拔模块作为-Flink-内置对象（Beta）"><a href="#将可插拔模块作为-Flink-内置对象（Beta）" class="headerlink" title="将可插拔模块作为 Flink 内置对象（Beta）"></a>将可插拔模块作为 Flink 内置对象（Beta）</h4><p>Flink 1.10 在 Flink table 核心引入了通用的可插拔模块机制，目前主要应用于系统内置函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-68%3A+Extend+Core+Table+System+with+Pluggable+Modules">FLIP-68</a>）。通过模块，用户可以扩展 Flink 的系统对象，例如像使用 Flink 系统函数一样使用 Hive 内置函数。新版本中包含一个预先实现好的 HiveModule，能够支持多个 Hive 版本，当然用户也可以选择编写自己的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/modules.html">可插拔模块</a>。</p><h3 id="其他-Table-API-SQL-优化"><a href="#其他-Table-API-SQL-优化" class="headerlink" title="其他 Table API/SQL 优化"></a>其他 Table API/SQL 优化</h3><h4 id="SQL-DDL-中的-watermark-和计算列"><a href="#SQL-DDL-中的-watermark-和计算列" class="headerlink" title="SQL DDL 中的 watermark 和计算列"></a>SQL DDL 中的 watermark 和计算列</h4><p>Flink 1.10 在 SQL DDL 中增加了针对流处理定义时间属性及产生 watermark 的语法扩展（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-66%3A+Support+Time+Attribute+in+SQL+DDL">FLIP-66</a>）。这使得用户可以在用 DDL 语句创建的表上进行基于时间的操作（例如窗口）以及<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/create.html#create-table">定义 watermark 策略</a>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table_name (</span><br><span class="line"></span><br><span class="line">WATERMARK FOR columnName AS &lt;watermark_strategy_expression&gt;</span><br><span class="line"></span><br><span class="line">) WITH (</span><br><span class="line">...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="其他-SQL-DDL-扩展"><a href="#其他-SQL-DDL-扩展" class="headerlink" title="其他 SQL DDL 扩展"></a>其他 SQL DDL 扩展</h4><p>Flink 现在严格区分临时/持久、系统/目录函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-57%3A+Rework+FunctionCatalog">FLIP-57</a>）。这不仅消除了函数引用中的歧义，还带来了确定的函数解析顺序（例如，当存在命名冲突时，比起目录函数、持久函数 Flink 会优先使用系统函数、临时函数）。</p><p>在 FLIP-57 的基础上，我们扩展了 SQL DDL 的语法，支持创建目录函数、临时函数以及临时系统函数（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-79+Flink+Function+DDL+Support">FLIP-79</a>）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE [TEMPORARY|TEMPORARY SYSTEM] FUNCTION</span><br><span class="line"></span><br><span class="line">[IF NOT EXISTS] [catalog_name.][db_name.]function_name</span><br><span class="line"></span><br><span class="line">AS identifier [LANGUAGE JAVA|SCALA]</span><br></pre></td></tr></table></figure><p>关于目前完整的 Flink SQL DDL 支持，请参考<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/">最新的文档</a>。</p><blockquote><p>注：为了今后正确地处理和保证元对象（表、视图、函数）上的行为一致性，Flink 废弃了 Table API 中的部分对象申明方法，以使留下的方法更加接近标准的 SQL DDL（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-64%3A+Support+for+Temporary+Objects+in+Table+module">FLIP-64</a>）。</p></blockquote><h4 id="批处理完整的-TPC-DS-覆盖"><a href="#批处理完整的-TPC-DS-覆盖" class="headerlink" title="批处理完整的 TPC-DS 覆盖"></a>批处理完整的 TPC-DS 覆盖</h4><p>TPC-DS 是广泛使用的业界标准决策支持 benchmark，用于衡量基于 SQL 的数据处理引擎性能。Flink 1.10 端到端地支持所有 TPC-DS 查询（<a href="https://issues.apache.org/jira/browse/FLINK-11491">FLINK-11491</a>），标志着 Flink SQL 引擎已经具备满足现代数据仓库及其他类似的处理需求的能力。</p><h3 id="PyFlink-支持原生用户自定义函数（UDF）"><a href="#PyFlink-支持原生用户自定义函数（UDF）" class="headerlink" title="PyFlink: 支持原生用户自定义函数（UDF）"></a>PyFlink: 支持原生用户自定义函数（UDF）</h3><p>作为 Flink 全面支持 Python 的第一步，在之前版本中我们发布了预览版的 PyFlink。在新版本中，我们专注于让用户在 Table API/SQL 中注册并使用自定义函数（UDF，另 UDTF / UDAF 规划中）（<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-58%3A+Flink+Python+User-Defined+Stateless+Function+for+Table">FLIP-58</a>）。</p><p><img src="https://flink.apache.org/img/blog/2020-02-11-release-1.10.0/flink_1.10_pyflink.gif" alt=""></p><p>如果你对这一特性的底层实现（基于 Apache Beam 的可移植框架）感兴趣，请参考 FLIP-58 的 Architecture 章节以及 <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-78%3A+Flink+Python+UDF+Environment+and+Dependency+Management">FLIP-78</a>。这些数据结构为支持 Pandas 以及今后将 PyFlink 引入到 DataStream API 奠定了基础。</p><p>从 Flink 1.10 开始，用户只要执行以下命令就可以轻松地通过 pip 安装 PyFlink：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install apache-flink</span><br></pre></td></tr></table></figure><h2 id="重要变更"><a href="#重要变更" class="headerlink" title="重要变更"></a>重要变更</h2><ul><li>FLINK-10725：Flink 现在可以使用 Java 11 编译和运行。</li><li>FLINK-15495：SQL 客户端现在默认使用 Blink planner，向用户提供最新的特性及优化。Table API 同样计划在下个版本中从旧的 planner 切换到 Blink planner，我们建议用户现在就开始尝试和熟悉 Blink planner。</li><li>FLINK-13025：新的 <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/connectors/elasticsearch.html#elasticsearch-connector">Elasticsearch sink connector</a> 全面支持 Elasticsearch 7.x 版本。</li><li>FLINK-15115：Kafka 0.8 和 0.9 的 connector 已被标记为废弃并不再主动支持。如果你还在使用这些版本或有其他相关问题，请通过 @dev 邮件列表联系我们。</li><li>FLINK-14516：非基于信用的网络流控制已被移除，同时移除的还有配置项“taskmanager.network.credit.model”。今后，Flink 将总是使用基于信用的网络流控制。</li><li>FLINK-12122：在 Flink 1.5.0 中，<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077">FLIP-6</a> 改变了 slot 在 TaskManager 之间的分布方式。要想使用此前的调度策略，既尽可能将负载分散到所有当前可用的 TaskManager，用户可以在 flink-conf.yaml 中设置 “cluster.evenly-spread-out-slots: true”。</li><li>FLINK-11956：s3-hadoop 和 s3-presto 文件系统不再使用类重定位加载方式，而是使用插件方式加载，同时无缝集成所有认证提供者。我们强烈建议其他文件系统也只使用插件加载方式，并将陆续移除重定位加载方式。</li><li>Flink 1.9 推出了新的 Web UI，同时保留了原来的 Web UI 以备不时之需。截至目前，我们没有收到关于新的 UI 存在问题的反馈，因此社区投票决定在 Flink 1.10 中移除旧的 Web UI。</li></ul><h3 id="关注我"><a href="#关注我" class="headerlink" title="关注我"></a>关注我</h3><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客</p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Flink 社区迎来了激动人心的两位数位版本号，Flink 1.10.0 正式宣告发布！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="实时计算" scheme="http://www.54tianzhisheng.cn/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink 视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/</id>
    <published>2019-12-30T16:00:00.000Z</published>
    <updated>2020-02-15T05:25:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><a id="more"></a><h3 id="Flink-专栏"><a href="#Flink-专栏" class="headerlink" title="Flink 专栏"></a>Flink 专栏</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><p>专栏大纲：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-055430.jpg" alt=""></p><h2 id="Flink-学习项目代码"><a href="#Flink-学习项目代码" class="headerlink" title="Flink 学习项目代码"></a>Flink 学习项目代码</h2><p><a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>麻烦路过的各位亲给这个项目点个 star，太不易了，写了这么多，算是对我坚持下来的一种鼓励吧！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-05-25-124027.jpg" alt=""></p><h2 id="本项目结构"><a href="#本项目结构" class="headerlink" title="本项目结构"></a>本项目结构</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-125710.jpg" alt=""></p><h2 id="How-to-build"><a href="#How-to-build" class="headerlink" title="How to build"></a>How to build</h2><p>Maybe your Maven conf file <code>settings.xml</code> mirrors can add aliyun central mirror :</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>alimaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>aliyun maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven.aliyun.com/repository/central<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure><p>then you can run the following command :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -Dmaven.test.skip=true</span><br></pre></td></tr></table></figure><p>you can see following result if build success.</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-27-121923.jpg" alt=""></p><h2 id="Change"><a href="#Change" class="headerlink" title="Change"></a>Change</h2><p>2019/09/06 将该项目的 Flink 版本升级到 1.9.0，有一些变动，Flink 1.8.0 版本的代码经群里讨论保存在分支 <a href="https://github.com/zhisheng17/flink-learning/tree/feature/flink-1.8.0">feature/flink-1.8.0</a> 以便部分同学需要。</p><p>2019/06/08 新增 Flink 四本电子书籍的 PDF，在 books 目录下：</p><ul><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Introduction_to_Apache_Flink_book.pdf">Introduction_to_Apache_Flink_book.pdf</a>    这本书比较薄，处于介绍阶段，国内有这本的翻译书籍</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Learning_Apache_Flink.pdf">Learning Apache Flink.pdf</a>    这本书比较基础，初学的话可以多看看</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Stream_Processing_with_Apache_Flink.pdf">Stream Processing with Apache Flink.pdf</a>    这本书是 Flink PMC 写的</p></li><li><p><a href="https://github.com/zhisheng17/flink-learning/blob/master/books/Streaming_System.pdf">Streaming System.pdf</a>  这本书评价不是一般的高</p></li></ul><p>2019/06/09 新增流处理引擎相关的 Paper，在 paper 目录下：</p><ul><li><a href="https://github.com/zhisheng17/flink-learning/blob/master/paper/paper.md">流处理引擎相关的 Paper</a></li></ul><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="https://t.zsxq.com/uniY7mm">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><h3 id="Flink-源码项目结构"><a href="#Flink-源码项目结构" class="headerlink" title="Flink 源码项目结构"></a>Flink 源码项目结构</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-125756.jpg" alt=""></p><h2 id="学习资料"><a href="#学习资料" class="headerlink" title="学习资料"></a>学习资料</h2><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号了。<br>你可以加我的微信：<strong>yuanblog_tzs</strong>，然后回复关键字：<strong>Flink</strong> 即可无条件获取到，转载请联系本人获取授权，违者必究。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-23-124320.jpg" alt=""></p><p>有人要问知识星球里面更新什么内容？值得加入吗？</p><p>目前知识星球内已更新的系列文章：</p><h3 id="大数据重磅炸弹"><a href="#大数据重磅炸弹" class="headerlink" title="大数据重磅炸弹"></a>大数据重磅炸弹</h3><p>1、<a href="https://t.zsxq.com/fqfuVRR​">《大数据重磅炸弹——实时计算引擎 Flink》开篇词</a></p><p>2、、<a href="https://t.zsxq.com/emMBaQN​">你公司到底需不需要引入实时计算引擎？</a></p><p>3、<a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a> ​</p><p>4、<a href="https://t.zsxq.com/eAyRz7Y">别再傻傻的分不清大数据框架Flink、Blink、Spark Streaming、Structured Streaming和Storm之间的区别了</a>​</p><p>5、<a href="https://t.zsxq.com/iaMJAe6​">Flink 环境准备看这一篇就够了</a>  </p><p>6、<a href="https://t.zsxq.com/iaMJAe6​">一文讲解从 Flink 环境安装到源码编译运行</a></p><p>7、<a href="https://t.zsxq.com/eaIIiAm">通过 WordCount 程序教你快速入门上手 Flink</a>  ​</p><p>8、<a href="https://t.zsxq.com/Vnq72jY​">Flink 如何处理 Socket 数据及分析实现过程</a>  </p><p>9、<a href="https://t.zsxq.com/BiyvFUZ​">Flink job 如何在 Standalone、YARN、Mesos、K8S 上部署运行？</a></p><p>10、<a href="https://t.zsxq.com/fufUBiA">Flink 数据转换必须熟悉的算子（Operator）</a></p><p>11、<a href="https://t.zsxq.com/r7aYB2V">Flink 中 Processing Time、Event Time、Ingestion Time 对比及其使用场景分析</a> </p><p>12、<a href="https://t.zsxq.com/byZbyrb">如何使用 Flink Window 及 Window 基本概念与实现原理</a></p><p>13、<a href="https://t.zsxq.com/VzNBi2r">如何使用 DataStream API 来处理数据？</a></p><p>14、<a href="https://t.zsxq.com/Iub6IQf">Flink WaterMark 详解及结合 WaterMark 处理延迟数据</a></p><h3 id="源码系列"><a href="#源码系列" class="headerlink" title="源码系列"></a>源码系列</h3><p>1、<a href="https://t.zsxq.com/UZfaYfE">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="https://t.zsxq.com/zZZjaYf">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="https://t.zsxq.com/QZVRZJA">Flink 源码解析 —— standalonesession 模式启动流程</a></p><p>5、<a href="https://t.zsxq.com/u3fayvf">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="https://t.zsxq.com/MnQRByb">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="https://t.zsxq.com/YJ2Zrfi">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="https://t.zsxq.com/qnMFEUJ">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="https://t.zsxq.com/naaMf6y">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="https://t.zsxq.com/qRFIm6I">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="https://t.zsxq.com/2VRrbuf">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="https://t.zsxq.com/RZbu7yN">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="https://t.zsxq.com/zV7MnuJ">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="https://t.zsxq.com/ynQNbeM">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="https://t.zsxq.com/JaQfeMf">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="https://t.zsxq.com/zjQvjeM">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="https://t.zsxq.com/f6eAu3J">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>除了《从1到100深入学习Flink》源码学习这个系列文章，《从0到1学习Flink》的案例文章也会优先在知识星球更新，让大家先通过一些 demo 学习 Flink，再去深入源码学习！</p><p>如果学习 Flink 的过程中，遇到什么问题，可以在里面提问，我会优先解答，这里做个抱歉，自己平时工作也挺忙，微信的问题不能做全部做一些解答，<br>但肯定会优先回复给知识星球的付费用户的，庆幸的是现在星球里的活跃氛围还是可以的，有不少问题通过提问和解答的方式沉淀了下来。</p><p>1、<a href="https://t.zsxq.com/62rZV7q">为何我使用 ValueState 保存状态 Job 恢复是状态没恢复？</a></p><p>2、<a href="https://t.zsxq.com/yF2rjmY">flink中watermark究竟是如何生成的，生成的规则是什么，怎么用来处理乱序数据</a></p><p>3、<a href="https://t.zsxq.com/uzFIeiq">消费kafka数据的时候，如果遇到了脏数据，或者是不符合规则的数据等等怎么处理呢？</a></p><p>4、<a href="https://t.zsxq.com/Nz7QZBY">在Kafka 集群中怎么指定读取/写入数据到指定broker或从指定broker的offset开始消费？</a></p><p>5、<a href="https://t.zsxq.com/7UVBeMj">Flink能通过oozie或者azkaban提交吗？</a></p><p>6、<a href="https://t.zsxq.com/mUzRbY7">jobmanager挂掉后，提交的job怎么不经过手动重新提交执行？</a></p><p>7、<a href="https://t.zsxq.com/Nju7EuV">使用flink-web-ui提交作业并执行 但是/opt/flink/log目录下没有日志文件 请问关于flink的日志（包括jobmanager、taskmanager、每个job自己的日志默认分别存在哪个目录 ）需要怎么配置？</a></p><p>8、<a href="https://t.zsxq.com/6muRz3j">通过flink 仪表盘提交的jar 是存储在哪个目录下？</a></p><p>9、<a href="https://t.zsxq.com/uvFQvFu">从Kafka消费数据进行etl清洗，把结果写入hdfs映射成hive表，压缩格式、hive直接能够读取flink写出的文件、按照文件大小或者时间滚动生成文件</a></p><p>10、<a href="https://t.zsxq.com/ubIY33f">flink jar包上传至集群上运行，挂掉后，挂掉期间kafka中未被消费的数据，在重新启动程序后，是自动从checkpoint获取挂掉之前的kafka offset位置，自动消费之前的数据进行处理，还是需要某些手动的操作呢？</a></p><p>11、<a href="https://t.zsxq.com/UfA2rBy">flink 启动时不自动创建 上传jar的路径，能指定一个创建好的目录吗</a></p><p>12、<a href="https://t.zsxq.com/zBMnIA6">Flink sink to es 集群上报 slot 不够，单机跑是好的，为什么？</a></p><p>13、<a href="https://t.zsxq.com/qrZBAQJ">Fllink to elasticsearch如何创建索引文档期时间戳？</a></p><p>14、<a href="https://t.zsxq.com/J2JiIMv">blink有没有api文档或者demo，是否建议blink用于生产环境。</a></p><p>15、<a href="https://t.zsxq.com/ZVVrjuv">flink的Python api怎样？bug多吗？</a></p><p>16、<a href="https://t.zsxq.com/zbybQNf">Flink VS Spark Streaming VS Storm VS Kafka Stream </a></p><p>17、<a href="https://t.zsxq.com/Zf6meAm">你们做实时大屏的技术架构是什么样子的？flume→kafka→flink→redis，然后后端去redis里面捞数据，酱紫可行吗？</a></p><p>18、<a href="https://t.zsxq.com/YniI2JQ">做一个统计指标的时候，需要在Flink的计算过程中多次读写redis，感觉好怪，星主有没有好的方案？</a></p><p>19、<a href="https://t.zsxq.com/fYZZfYf">Flink 使用场景大分析，列举了很多的常用场景，可以好好参考一下</a></p><p>20、<a href="https://t.zsxq.com/I6eEqR7">将kafka中数据sink到mysql时，metadata的数据为空，导入mysql数据不成功？？？</a></p><p>21、<a href="https://t.zsxq.com/62rZV7q">使用了ValueState来保存中间状态，在运行时中间状态保存正常，但是在手动停止后，再重新运行，发现中间状态值没有了，之前出现的键值是从0开始计数的，这是为什么？是需要实现CheckpointedFunction吗？</a></p><p>22、<a href="https://t.zsxq.com/mQ7YbQJ">flink on yarn jobmanager的HA需要怎么配置。还是说yarn给管理了</a></p><p>23、<a href="https://t.zsxq.com/q3VvB6U">有两个数据流就行connect，其中一个是实时数据流（kafka 读取)，另一个是配置流。由于配置流是从关系型数据库中读取，速度较慢，导致实时数据流流入数据的时候，配置信息还未发送，这样会导致有些实时数据读取不到配置信息。目前采取的措施是在connect方法后的flatmap的实现的在open 方法中，提前加载一次配置信息，感觉这种实现方式不友好，请问还有其他的实现方式吗？</a></p><p>24、<a href="https://t.zsxq.com/7UVBeMj">Flink能通过oozie或者azkaban提交吗？</a></p><p>25、<a href="https://t.zsxq.com/mUzRbY7">不采用yarm部署flink，还有其他的方案吗？ 主要想解决服务器重启后，flink服务怎么自动拉起？ jobmanager挂掉后，提交的job怎么不经过手动重新提交执行？</a></p><p>26、<a href="https://t.zsxq.com/bYnimQv">在一个 Job 里将同份数据昨晚清洗操作后，sink 到后端多个地方（看业务需求），如何保持一致性？（一个sink出错，另外的也保证不能插入）</a></p><p>27、<a href="https://t.zsxq.com/YvBAyrV">flink sql任务在某个特定阶段会发生tm和jm丢失心跳，是不是由于gc时间过长呢，</a></p><p>28、<a href="https://t.zsxq.com/fayf2Vv">有这样一个需求，统计用户近两周进入产品详情页的来源（1首页大搜索，2产品频道搜索，3其他），为php后端提供数据支持，该信息在端上报事件中，php直接获取有点困难。 我现在的解决方案 通过flink滚动窗口（半小时），统计用户半小时内3个来源pv，然后按照日期序列化，直接写mysql。php从数据库中解析出来，再去统计近两周占比。 问题1，这个需求适合用flink去做吗？ 问题2，我的方案总感觉怪怪的，有没有好的方案？</a></p><p>29、<a href="https://t.zsxq.com/ZFiY3VZ">一个task slot  只能同时运行一个任务还是多个任务呢？如果task  slot运行的任务比较大，会出现OOM的情况吗？</a></p><p>30、<a href="https://t.zsxq.com/Yn2JqB6">你们怎么对线上flink做监控的，如果整个程序失败了怎么自动重启等等</a></p><p>31、<a href="https://t.zsxq.com/YFMFeaA">flink cep规则动态解析有接触吗？有没有成型的框架？</a></p><p>32、<a href="https://t.zsxq.com/VZvRrjm">每一个Window都有一个watermark吗？window是怎么根据watermark进行触发或者销毁的？</a></p><p>33、<a href="https://t.zsxq.com/R3ZZJUF"> CheckPoint与SavePoint的区别是什么？</a></p><p>34、<a href="https://t.zsxq.com/Aa62Bim">flink可以在算子中共享状态吗？或者大佬你有什么方法可以共享状态的呢？</a></p><p>35、<a href="https://t.zsxq.com/ayFmmMF">运行几分钟就报了，看taskmager日志，报的是 failed elasticsearch bulk request null，可是我代码里面已经做过空值判断了呀 而且也过滤掉了，flink版本1.7.2 es版本6.3.1</a></p><p>36、<a href="https://t.zsxq.com/Yzzzb2b">这种情况，我们调并行度 还是配置参数好</a></p><p>37、<a href="https://t.zsxq.com/AqBUR3f">大家都用jdbc写，各种数据库增删查改拼sql有没有觉得很累，ps.set代码一大堆，还要计算每个参数的位置</a></p><p>38、<a href="https://t.zsxq.com/AqBUR3f">关于datasource的配置，每个taskmanager对应一个datasource?还是每个slot? 实际运行下来，每个slot中datasorce线程池只要设置1就行了，多了也用不到?</a></p><p>39、<a href="https://t.zsxq.com/AqBUR3f">kafka现在每天出现数据丢失，现在小批量数据，一天200W左右, kafka版本为 1.0.0，集群总共7个节点，TOPIC有十六个分区，单条报文1.5k左右</a></p><p>40、<a href="https://t.zsxq.com/AqBUR3f">根据key.hash的绝对值 对并发度求模，进行分组，假设10各并发度，实际只有8个分区有处理数据，有2个始终不处理，还有一个分区处理的数据是其他的三倍，如截图</a></p><p>41、<a href="https://t.zsxq.com/AqBUR3f">flink每7小时不知道在处理什么， CPU 负载 每7小时，有一次高峰，5分钟内平均负载超过0.8，如截图</a></p><p>42、<a href="https://t.zsxq.com/M3fIMbu">有没有Flink写的项目推荐？我想看到用Flink写的整体项目是怎么组织的，不单单是一个单例子</a></p><p>43、<a href="https://t.zsxq.com/yv7EQFA">Flink 源码的结构图</a></p><p>44、<a href="https://t.zsxq.com/vBAYNJq">我想根据不同业务表（case when）进行不同的redis sink（hash ，set），我要如何操作？</a></p><p>45、<a href="https://t.zsxq.com/b2zbUJa">这个需要清理什么数据呀，我把hdfs里面的已经清理了 启动还是报这个</a></p><p>46、<a href="https://t.zsxq.com/QjQFmQr">  在流处理系统，在机器发生故障恢复之后，什么情况消息最多会被处理一次？什么情况消息最少会被处理一次呢？</a></p><p>47、<a href="https://t.zsxq.com/zbQNfuJ">我检查点都调到5分钟了，这是什么问题</a></p><p>48、<a href="https://t.zsxq.com/ZrjEauN">reduce方法后 那个交易时间 怎么不是最新的，是第一次进入的那个时间，</a></p><p>49、<a href="https://t.zsxq.com/VJyr3bM">Flink  on Yarn 模式，用yarn session脚本启动的时候，我在后台没有看到到Jobmanager，TaskManager，ApplicationMaster这几个进程，想请问一下这是什么原因呢？因为之前看官网的时候，说Jobmanager就是一个jvm进程，Taskmanage也是一个JVM进程</a></p><p>50、<a href="https://t.zsxq.com/VJyr3bM">Flink  on Yarn的时候得指定 多少个TaskManager和每个TaskManager slot去运行任务，这样做感觉不太合理，因为用户也不知道需要多少个TaskManager适合，Flink 有动态启动TaskManager的机制吗。</a></p><p>51、<a href="https://t.zsxq.com/UBmUJMv">参考这个例子，Flink 零基础实战教程：如何计算实时热门商品 | Jark’s Blog， 窗口聚合的时候，用keywindow，用的是timeWindowAll，然后在aggregate的时候用aggregate(new CustomAggregateFunction(), new CustomWindowFunction())，打印结果后，发现窗口中一直使用的重复的数据，统计的结果也不变，去掉CustomWindowFunction()就正常了 ？ 非常奇怪</a></p><p>52、<a href="https://t.zsxq.com/naQb6aI">用户进入产品预定页面（端埋点上报），并填写了一些信息（端埋点上报），但半小时内并没有产生任何订单，然后给该类用户发送一个push。 1. 这种需求适合用flink去做吗？2. 如果适合，说下大概的思路</a></p><p>53、<a href="https://t.zsxq.com/AUf2VNz">业务场景是实时获取数据存redis，请问我要如何按天、按周、按月分别存入redis里？（比方说过了一天自动换一个位置存redis）</a></p><p>54、<a href="https://t.zsxq.com/UJ6Y7m2">有人 AggregatingState 的例子吗, 感觉官方的例子和 官网的不太一样?</a></p><p>55、<a href="https://t.zsxq.com/r3BaAY3">flink-jdbc这个jar有吗？怎么没找到啊？1.8.0的没找到，1.6.2的有</a></p><p>56、<a href="https://t.zsxq.com/jiybIee">现有个关于savepoint的问题，操作流程为，取消任务时设置保存点，更新任务，从保存点启动任务；现在遇到个问题，假设我中间某个算子重写，原先通过state编写，有用定时器，现在更改后，采用窗口，反正就是实现方式完全不一样；从保存点启动就会一直报错，重启，原先的保存点不能还原，此时就会有很多数据重复等各种问题，如何才能保证数据不丢失，不重复等，恢复到停止的时候，现在想到的是记下kafka的偏移量，再做处理，貌似也不是很好弄，有什么解决办法吗</a></p><p>57、<a href="https://t.zsxq.com/eMJmiQz">需要在flink计算app页面访问时长，消费Kafka计算后输出到Kafka。第一条log需要等待第二条log的时间戳计算访问时长。我想问的是，flink是分布式的，那么它能否保证执行的顺序性？后来的数据有没有可能先被执行？</a></p><p>58、<a href="https://t.zsxq.com/Y7e6aIu">我公司想做实时大屏，现有技术是将业务所需指标实时用spark拉到redis里存着，然后再用一条spark streaming流计算简单乘除运算，指标包含了各月份的比较。请问我该如何用flink简化上述流程？</a></p><p>59、<a href="https://t.zsxq.com/QbIayJ6">flink on yarn 方式，这样理解不知道对不对，yarn-session这个脚本其实就是准备yarn环境的，执行run任务的时候，根据yarn-session初始化的yarnDescription 把 flink 任务的jobGraph提交到yarn上去执行</a></p><p>60、<a href="https://t.zsxq.com/VFMRbYN">同样的代码逻辑写在单独的main函数中就可以成功的消费kafka ，写在一个spring boot的程序中，接受外部请求，然后执行相同的逻辑就不能消费kafka。你遇到过吗？能给一些查问题的建议，或者在哪里打个断点，能看到为什么消费不到kafka的消息呢？</a></p><p>61、<a href="https://t.zsxq.com/QNvjI6Q">请问下flink可以实现一个流中同时存在订单表和订单商品表的数据 两者是一对多的关系  能实现得到 以订单表为主 一个订单多个商品 这种需求嘛</a></p><p>62、<a href="https://t.zsxq.com/6ie66EE">在用中间状态的时候，如果中间一些信息保存在state中，有没有必要在redis中再保存一份，来做第三方的存储。</a></p><p>63、<a href="https://t.zsxq.com/bm6mYjI">能否出一期flink state的文章。什么场景下用什么样的state？如，最简单的，实时累加update到state。</a></p><p>64、<a href="https://t.zsxq.com/II6AEe2">flink的双流join博主有使用的经验吗？会有什么常见的问题吗</a></p><p>65、<a href="https://t.zsxq.com/V7EmUZR">窗口触发的条件问题</a></p><p>66、<a href="https://t.zsxq.com/JY3NJam">flink 定时任务怎么做？有相关的demo么？</a></p><p>67、<a href="https://t.zsxq.com/7YZ3Fuz">流式处理过程中数据的一致性如何保证或者如何检测</a></p><p>68、<a href="https://t.zsxq.com/nEEQvzR">重启flink单机集群，还报job not found 异常。</a></p><p>69、<a href="https://t.zsxq.com/qJyvzNj">kafka的数据是用 org.apache.kafka.common.serialization.ByteArraySerialize序列化的，flink这边消费的时候怎么通过FlinkKafkaConsumer创建DataStream<String>？</a></p><p>70、<a href="https://t.zsxq.com/byvnaEi">现在公司有一个需求，一些用户的支付日志，通过sls收集，要把这些日志处理后，结果写入到MySQL，关键这些日志可能连着来好几条才是一个用户的，因为发起请求，响应等每个环节都有相应的日志，这几条日志综合处理才能得到最终的结果，请问博主有什么好的方法没有？</a></p><p>71、<a href="https://t.zsxq.com/qfie6qR">flink 支持hadoop 主备么？ hadoop主节点挂了 flink 会切换到hadoop 备用节点？</a></p><p>72、<a href="https://t.zsxq.com/ZVZzZv7">请教大家: 实际 flink 开发中用 scala 多还是 java多些？ 刚入手 flink 大数据 scala 需要深入学习么？</a></p><p>73、<a href="https://t.zsxq.com/Qzbi6yn">我使用的是flink是1.7.2最近用了split的方式分流，但是底层的SplitStream上却标注为Deprecated，请问是官方不推荐使用分流的方式吗？</a></p><p>74、<a href="https://t.zsxq.com/Auf2NVR">KeyBy 的正确理解，和数据倾斜问题的解释</a></p><p>75、<a href="https://t.zsxq.com/3vnIm62">用flink时，遇到个问题 checkpoint大概有2G左右， 有背压时，flink会重启有遇到过这个问题吗</a></p><p>76、<a href="https://t.zsxq.com/URzVBIm">flink使用yarn-session方式部署，如何保证yarn-session的稳定性，如果yarn-session挂了，需要重新部署一个yarn-session，如何恢复之前yarn-session上的job呢，之前的checkpoint还能使用吗？</a></p><p>77、<a href="https://t.zsxq.com/MjyN7Uf">我想请教一下关于sink的问题。我现在的需求是从Kafka消费Json数据，这个Json数据字段可能会增加，然后将拿到的json数据以parquet的格式存入hdfs。现在我可以拿到json数据的schema，但是在保存parquet文件的时候不知道怎么处理。一是flink没有专门的format parquet，二是对于可变字段的Json怎么处理成parquet比较合适？</a></p><p>78、<a href="https://t.zsxq.com/6qBqVvZ">flink如何在较大的数据量中做去重计算。</a></p><p>79、<a href="https://t.zsxq.com/Eqjyju7">flink能在没有数据的时候也定时执行算子吗？</a></p><p>80、<a href="https://t.zsxq.com/i2zVfIi">使用rocksdb状态后端，自定义pojo怎么实现序列化和反序列化的，有相关demo么？</a></p><p>81、<a href="https://t.zsxq.com/vRJujAi">check point 老是失败，是不是自定义的pojo问题？到本地可以，到hdfs就不行，网上也有很多类似的问题 都没有一个很好的解释和解决方案</a></p><p>82、<a href="https://t.zsxq.com/MVFmuB6">cep规则如图，当start事件进入时，时间00:00:15，而后进入end事件，时间00:00:40。我发现规则无法命中。请问within 是从start事件开始计时？还是跟window一样根据系统时间划分的？如果是后者，请问怎么配置才能从start开始计时？</a></p><p>83、<a href="https://t.zsxq.com/EybM3vR">Flink聚合结果直接写Mysql的幂等性设计问题</a></p><p>84、<a href="https://t.zsxq.com/62VzNRF">Flink job打开了checkpoint，用的rocksdb，通过观察hdfs上checkpoint目录，为啥算副本总量会暴增爆减</a></p><p>85、<a href="">Flink 提交任务的 jar包可以指定路径为 HDFS 上的吗</a></p><p>86、<a href="https://t.zsxq.com/VfimieI">在flink web Ui上提交的任务，设置的并行度为2，flink是stand alone部署的。两个任务都正常的运行了几天了，今天有个地方逻辑需要修改，于是将任务cancel掉(在命令行cancel也试了)，结果taskmanger挂掉了一个节点。后来用其他任务试了，也同样会导致节点挂掉</a></p><p>87、<a href="https://t.zsxq.com/nee6qRv">一个配置动态更新的问题折腾好久（配置用个静态的map变量存着，有个线程定时去数据库捞数据然后存在这个map里面更新一把），本地 idea 调试没问题，集群部署就一直报 空指针异常。下游的算子使用这个静态变量map去get key在集群模式下会出现这个空指针异常，估计就是拿不到 map</a></p><p>88、<a href="https://t.zsxq.com/3bEUZfQ">批量写入MySQL，完成HBase批量写入</a></p><p>89、<a href="https://t.zsxq.com/Zb6AM3V">用flink清洗数据，其中要访问redis，根据redis的结果来决定是否把数据传递到下流，这有可能实现吗？</a></p><p>90、<a href="https://t.zsxq.com/RbeYZvb">监控页面流处理的时候这个发送和接收字节为0。</a></p><p>91、<a href="https://t.zsxq.com/MN7iuZf">sink到MySQL，如果直接用idea的话可以运行，并且成功，大大的代码上面用的FlinkKafkaConsumer010，而我的Flink版本为1.7，kafka版本为2.12，所以当我用FlinkKafkaConsumer010就有问题，于是改为<br>    FlinkKafkaConsumer就可以直接在idea完成sink到MySQL，但是为何当我把该程序打成Jar包，去运行的时候，就是报FlinkKafkaConsumer找不到呢</a></p><p>92、<a href="https://t.zsxq.com/e2VNN7Y">SocketTextStreamWordCount中输入中文统计不出来，请问这个怎么解决，我猜测应该是需要修改一下代码，应该是这个例子默认统计英文</a></p><p>93、<a href="https://t.zsxq.com/RVRn6AE"> Flink 应用程序本地 ide 里面运行的时候并行度是怎么算的？</a></p><p>94、<a href="https://t.zsxq.com/rzbIQBi"> 请问下flink中对于窗口的全量聚合有apply和process两种 他们有啥区别呢</a></p><p>95、<a href="https://t.zsxq.com/UJIubub">不知道大大熟悉Hbase不，我想直接在Hbase中查询某一列数据，因为有重复数据，所以想使用distinct统计实际数据量，请问Hbase中有没有类似于sql的distinct关键字。如果没有，想实现这种可以不？</a></p><p>96、<a href="https://t.zsxq.com/VFaQn2j"> 来分析一下现在Flink,Kafka方面的就业形势，以及准备就业该如何准备的这方面内容呢？</a></p><p>97、<a href="https://t.zsxq.com/Zn2FEQZ"> 大佬知道flink的dataStream可以转换为dataSet吗？因为数据需要11分钟一个批次计算五六个指标，并且涉及好几步reduce，计算的指标之间有联系，用Stream卡住了。</a></p><p>98、<a href="https://t.zsxq.com/aIqjmQN">1.如何在同一窗口内实现多次的聚合，比如像spark中的这样2.多个实时流的jion可以用window来处理一批次的数据吗？</a></p><p>99、<a href="https://t.zsxq.com/ZNvb2FM">写的批处理的功能，现在本机跑是没问题的，就是在linux集群上出现了问题，就是不知道如果通过本地调用远程jar包然后传参数和拿到结果参数返回本机</a></p><p>100、<a href="https://t.zsxq.com/femmiqf">我用standalone开启一个flink集群，上传flink官方用例Socket Window WordCount做测试，开启两个parallelism能正常运行，但是开启4个parallelism后出现错误</a></p><p>101、<a href="https://t.zsxq.com/YZ3vbY3"> 有使用AssignerWithPunctuatedWatermarks 的案例Demo吗？网上找了都是AssignerWithPeriodicWatermarks的，不知道具体怎么使用？</a></p><p>102、<a href="https://t.zsxq.com/uzFyVJe"> 有一个datastream(从文件读取的)，然后我用flink sql进行计算，这个sql是一个加总的运算，然后通过retractStreamTableSink可以把文件做sql的结果输出到文件吗？这个输出到文件的接口是用什么呢？</a></p><p>103、<a href="https://t.zsxq.com/6QNNrZz"> 为啥split这个流设置为过期的</a></p><p>104、<a href="https://t.zsxq.com/Q7YNRBE"> 需要使用flink table的水印机制控制时间的乱序问题，这种场景下我就使用水印+窗口了，我现在写的demo遇到了问题，就是在把触发计算的窗口table（WindowedTable）转换成table进行sql操作时发现窗口中的数据还是乱序的，是不是flink table的WindowedTable不支持水印窗口转table-sql的功能</a></p><p>105、<a href="https://t.zsxq.com/Jmayrbi"> Flink 对 SQL 的重视性</a></p><p>106、<a href="https://t.zsxq.com/ZrZfa2Z"> flink job打开了checkpoint，任务跑了几个小时后就出现下面的错，截图是打出来的日志，有个OOM，又遇到过的没？</a></p><p>107、<a href="https://t.zsxq.com/emaAeyj"> 本地测试是有数据的，之前该任务放在集群也是有数据的，可能提交过多次，现在读不到数据了 group id 也换过了， 只能重启集群解决么？</a></p><p>108、<a href="https://t.zsxq.com/ayBa6am">使用flink清洗数据存到es中，直接在flatmap中对处理出来的数据用es自己的ClientInterface类直接将数据存入es当中，不走sink，这样的处理逻辑是不是会有问题。</a></p><p>108、<a href="https://t.zsxq.com/QNvbE62"> flink从kafka拿数据（即增量数据）与存量数据进行内存聚合的需求，现在有一个方案就是程序启动的时候先用flink table将存量数据加载到内存中创建table中，然后将stream的增量数据与table的数据进行关联聚合后输出结束，不知道这种方案可行么。目前个人认为有两个主要问题：1是增量数据stream转化成append table后不知道能与存量的table关联聚合不，2是聚合后输出的结果数据是否过于频繁造成网络传输压力过大</a></p><p>109、<a href="https://t.zsxq.com/yzjAQ7a"> 设置时间时间特性有什么区别呢,  分别在什么场景下使用呢?两种设置时间延迟有什么区别呢 , 分别在什么场景下使用</a></p><p>110、<a href="https://t.zsxq.com/qRrJEaa"> flink从rabbitmq中读取数据，设置了rabbitmq的CorrelationDataId和checkpoint为EXACTLY_ONCE；如果flink完成一次checkpoint后，在这次checkpoint之前消费的数据都会从mq中删除。如果某次flink停机更新，那就会出现mq中的一些数据消费但是处于Unacked状态。在flink又重新开启后这批数据又会重新消费。那这样是不是就不能保证EXACTLY_ONCE了</a></p><p>111、<a href="https://t.zsxq.com/mAqn2RF">1. 在Flink checkpoint 中, 像 operator的状态信息 是在设置了checkpoint 之后自动的进行快照吗 ?2. 上面这个和我们手动存储的 Keyed State 进行快照(这个应该是增量快照)</a></p><p>112、<a href="https://t.zsxq.com/E2BeQ3f">现在有个实时商品数，交易额这种统计需求，打算用 flink从kafka读取binglog日志进行计算，但binglog涉及到insert和update这种操作时 怎么处理才能统计准确，避免那种重复计算的问题？</a></p><p>113、<a href="https://t.zsxq.com/vjIeyFI">我这边用flink做实时监控，功能很简单，就是每条消息做keyby然后三分钟窗口，然后做些去重操作，触发阈值则报警，现在问题是同一个时间窗口同一个人的告警会触发两次，集群是三台机器，standalone cluster，初步结果是三个算子里有两个收到了同样的数据</a></p><p>114、<a href="https://t.zsxq.com/unq3FIa">在使用WaterMark的时候，默认是每200ms去设置一次watermark，那么每个taskmanager之间，由于得到的数据不同，所以往往产生的最大的watermark不同。 那么这个时候，是各个taskmanager广播这个watermark，得到全局的最大的watermark，还是说各个taskmanager都各自用自己的watermark。主要没看到广播watermark的源码。不知道是自己观察不仔细还是就是没有广播这个变量。</a></p><p>115、<a href="https://t.zsxq.com/AeUnAyN">现在遇到一个需求，需要在job内部定时去读取redis的信息，想请教flink能实现像普通程序那样的定时任务吗？</a></p><p>116、<a href="https://t.zsxq.com/z7uZbY3">有个触发事件开始聚合，等到数量足够，或者超时则sink推mq 环境 flink 1.6 用了mapState 记录触发事件 1 数据足够这个OK 2 超时state ttl 1.6支持，但是问题来了，如何在超时时候增加自定义处理？</a></p><p>117、<a href="https://t.zsxq.com/R7UjeUF">请问impala这种mpp架构的sql引擎，为什么稳定性比较差呢？</a></p><p>118、<a href="https://t.zsxq.com/q7myfAQ">watermark跟并行度相关不是，过于全局了，期望是keyby之后再针对每个keyed stream 打watermark，这个有什么好的实践呢？</a></p><p>119、<a href="https://t.zsxq.com/rB6yfeA">请问如果把一个文件的内容读取成datastream和dataset，有什么区别吗？？他们都是一条数据一条数据的被读取吗？</a></p><p>120、<a href="https://t.zsxq.com/j2j6EyJ">有没有kylin相关的资料，或者调优的经验？</a></p><p>121、<a href="https://t.zsxq.com/iMjmQVV">flink先从jdbc读取配置表到流中，另外从kafka中新增或者修改这个配置，这个场景怎么把两个流一份配置流？我用的connect,接着发不成广播变量，再和实体流合并，但在合并时报Exception in thread “main” java.lang.IllegalArgumentException</a></p><p>122、<a href="https://t.zsxq.com/RFQNFIa">Flink  exactly-once，kafka版本为0.11.0 ，sink基于FlinkKafkaProducer011 每五分钟一次checkpoint，但是checkpoint开始后系统直接卡死，at-lease-once 一分钟能完成的checkpoint， 现在十分钟无法完成没进度还是0， 不知道哪里卡住了</a></p><p>123、<a href="https://t.zsxq.com/NJq3rj2">flink的状态是默认存在于内存的(也可以设置为rocksdb或hdfs)，而checkpoint里面是定时存放某个时刻的状态信息，可以设置hdfs或rocksdb是这样理解的吗？</a></p><p>124、<a href="https://t.zsxq.com/NJq3rj2">Flink异步IO中，下图这两种有什么区别？为啥要加 CompletableFuture.supplyAsync，不太明白？</a></p><p>125、<a href="https://t.zsxq.com/NJq3rj2">flink的状态是默认存在于内存的(也可以设置为rocksdb或hdfs)，而checkpoint里面是定时存放某个时刻的状态信息，可以设置hdfs或rocksdb是这样理解的吗？</a></p><p>126、<a href="https://t.zsxq.com/rniUrjm">有个计算场景，从kafka消费两个数据源，两个数据结构都有时间段概念，计算需要做的是匹配两个时间段，匹配到了，就生成一条新的记录。请问使用哪个工具更合适，flink table还是cep？请大神指点一下 我这边之前的做法，将两个数据流转为table.两个table over window后join成新的表。结果job跑一会就oom.</a></p><p>127、<a href="https://t.zsxq.com/vRZ7qJ2">一个互联网公司，或者一个业务系统，如果想做一个全面的监控要怎么做？有什么成熟的方案可以参考交流吗？有什么有什么度量指标吗？</a></p><p>128、<a href="https://t.zsxq.com/3vfyJau">怎么深入学习flink,或者其他大数据组件，能为未来秋招找一份大数据相关（计算方向）的工作增加自己的竞争力？</a></p><p>129、<a href="https://t.zsxq.com/VBIunun">oppo的实时数仓，其中明细层和汇总层都在kafka中，他们的关系库的实时数据也抽取到kafka的ods，那么在构建数仓的，需要join 三四个大业务表，业务表会变化，那么是大的业务表是从kafka的ods读取吗？实时数仓，多个大表join可以吗</a></p><p>130、<a href="https://t.zsxq.com/vnaURzj">Tuple类型有什么方法转换成json字符串吗？现在的场景是，结果在存储到sink中时希望存的是json字符串，这样应用程序获取数据比较好转换一点。如果Tuple不好转换json字符串，那么应该以什么数据格式存储到sink中</a></p><p>140、<a href="https://t.zsxq.com/J6eAmYb">端到端的数据保证，是否意味着中间处理程序中断，也不会造成该批次处理失败的消息丢失，处理程序重新启动之后，会再次处理上次未处理的消息</a></p><p>141、<a href="https://t.zsxq.com/7qBMrBe">关于flink datastream window相关的。比如我现在使用滚动窗口，统计一周内去重用户指标，按照正常watermark触发计算，需要等到当前周的window到达window的endtime时，才会触发，这样指标一周后才能产出结果。我能不能实现一小时触发一次计算，每次统计截止到当前时间，window中所有到达元素的去重数量。</a></p><p>142、<a href="https://t.zsxq.com/uJqzBIe">FLIP-16 Loop Fault Tolerance 是讲现在的checkpoint机制无法在stream loop的时候容错吗？现在这个问题解决了没有呀？</a></p><p>143、<a href="https://t.zsxq.com/uZnmQzv">现在的需求是，统计各个key的今日累计值，一分钟输出一次。如，各个用户今日累计点击次数。这种需求用datastream还是table API方便点？</a></p><p>144、<a href="https://t.zsxq.com/BqnYRN7">本地idea可以跑的工程，放在standalone集群上，总报错，报错截图如下，大佬请问这是啥原因</a></p><p>145、<a href="https://t.zsxq.com/7MJujMb">比如现在用k8s起了一个flink集群，这时候数据源kafka或者hdfs会在同一个集群上吗，还是会单独再起一个hdfs/kafka集群</a></p><p>146、<a href="https://t.zsxq.com/6U7QFMj">flink kafka sink 的FlinkFixedPartitioner 分配策略，在并行度小于topic的partitions时，一个并行实例固定的写消息到固定的一个partition，那么就有一些partition没数据写进去？</a></p><p>147、<a href="https://t.zsxq.com/fmq3fYF">基于事件时间，每五分钟一个窗口，五秒钟滑动一次，同时watermark的时间同样是基于事件事件时间的，延迟设为1分钟，假如数据流从12：00开始，如果12：07-12：09期间没有产生任何一条数据，即在12：07-12：09这段间的数据流情况为···· （12：07:00，xxx）,(12:09:00,xxx)······，那么窗口[12:02:05-12:07:05]，[12:02:10-12:07:10]等几个窗口的计算是否意味着只有等到，12：09：00的数据到达之后才会触发</a></p><p>148、<a href="https://t.zsxq.com/MRvv3ZV">使用flink1.7，当消费到某条消息(protobuf格式)，报Caused by: org.apache.kafka.common.KafkaException: Record batch for partition Notify-18 at offset 1803009 is invalid, cause: Record is corrupt 这个异常。 如何设置跳过已损坏的消息继续消费下一条来保证业务不终断？ 我看了官网kafka connectors那里，说在DeserializationSchema.deserialize(…)方法中返回null，flink就会跳过这条消息，然而依旧报这个异常</a></p><p>149、<a href="https://t.zsxq.com/MRJeAuj">是否可以抽空总结一篇Flink 的 watermark 的原理案例？一直没搞明白基于事件时间处理时的数据乱序和数据迟到底咋回事</a></p><p>150、<a href="https://t.zsxq.com/2rJyNrF">flink中rpc通信的原理，与几个类的讲解，有没有系统详细的文章样，如有求分享，谢谢</a></p><p>151、<a href="https://t.zsxq.com/bM3ZZRf">Flink中如何使用基于事件时间处理，但是又不使用Watermarks? 我在会话窗口中使用遇到一些问题，图一是基于处理时间的，测试结果session是基于keyby(用户)的，图二是基于事件时间的，不知道是我用法不对还是怎么的，测试结果发现并不是基于keyby(用户的)，而是全局的session。不知道怎么修改？</a></p><p>152、<a href="https://t.zsxq.com/BMVzzzB">flink实时计算平台，yarn模式日志收集怎么做，为什么会checkpoint失败，报警处理，后需要做什么吗？job监控怎么做</a></p><p>153、<a href="https://t.zsxq.com/237EAay">有flink与jstorm的在不同应用场景下, 性能比较的数据吗? 从网络上能找大部分都是flink与storm的比较. 在jstorm官网上有一份比较的图表, 感觉参考意义不大, 应该是比较早的flink版本.</a></p><p>154、<a href="https://t.zsxq.com/J6eAmYb">为什么使用SessionWindows.withGap窗口的话，State存不了东西呀，每次加1 ，拿出来都是null, 我换成 TimeWindow就没问题。</a></p><p>155、<a href="https://t.zsxq.com/y3nYZrf">请问一下，flink datastream流处理怎么统计去重指标？  官方文档中只看到批处理有distinct概念。</a></p><p>156、<a href="https://t.zsxq.com/qRjqFY3">好全的一篇文章，对比分析 Flink，Spark Streaming，Storm 框架</a></p><p>157、<a href="https://t.zsxq.com/Eau7qNB">关于 structured_streaming 的 paper</a></p><p>158、<a href="https://t.zsxq.com/rFYbEeq">zookeeper集群切换领导了，flink集群项目重启了就没有数据的输入和输出了，这个该从哪方面入手解决？</a></p><p>159、<a href="https://t.zsxq.com/nEAaYNF">我想请教下datastream怎么和静态数据join呢</a></p><p>160、<a href="https://t.zsxq.com/IAAeiA6">时钟问题导致收到了明天的数据，这时候有什么比较好的处理方法？看到有人设置一个最大的跳跃阈值，如果当前数据时间 - 历史最大时间 超过阈值就不更新。如何合理的设计水印，有没有一些经验呢？</a></p><p>161、<a href="https://t.zsxq.com/EuJ2RRf">大佬们flink怎么定时查询数据库？</a></p><p>162、<a href="https://t.zsxq.com/vzZBmYB">现在我们公司有个想法，就是提供一个页面，在页面上选择source sink 填写上sql语句，然后后台生成一个flink的作业，然后提交到集群。功能有点类似于华为的数据中台，就是页面傻瓜式操作。后台能自动根据相应配置得到结果。请问拘你的了解，可以实现吗？如何实现？有什么好的思路。现在我无从下手</a></p><p>163、<a href="https://t.zsxq.com/VRFIMfy">请教一下 flink on yarn 的 ha机制</a></p><p>164、<a href="https://t.zsxq.com/FAiiEyr">在一般的流处理以及cep, 都可以对于eventtime设置watermark, 有时可能需要设置相对大一点的值, 这内存压力就比较大, 有没有办法不应用jvm中的内存, 而用堆外内存, 或者其他缓存, 最好有cache机制, 这样可以应对大流量的峰值.</a></p><p>165、<a href="https://t.zsxq.com/YnI2F66">请教一个flink sql的问题。我有两个聚合后的流表A和B，A和Bjoin得到C表。在设置state TTL 的时候是直接对C表设置还是，对A表和B表设置比较好？</a></p><p>166、<a href="https://t.zsxq.com/unyneEU">spark改写为flink，会不会很复杂，还有这两者在SQL方面的支持差别大吗？</a></p><p>167、<a href="https://t.zsxq.com/RfyZFUR">请问flink allowedLateness导致窗口被多次fire，最终数据重复消费，这种问题怎么处理，数据是写到es中</a></p><p>168、<a href="https://t.zsxq.com/bIAEyFe">设置taskmanager.numberOfTaskSlots: 4的时候没有问题，但是cpu没有压上去，只用了30%左右，于是设置了taskmanager.numberOfTaskSlots: 8，但是就报错误找不到其中一个自定义的类，然后kafka数据就不消费了。为什么？cpu到多少合适？slot是不是和cpu数量一致是最佳配置？kafka分区数多少合适，是不是和slot,parallesim一致最佳？</a></p><p>169、<a href="https://t.zsxq.com/BUNfYnY">需求是根据每条日志切分出需要9个字段，有五个指标再根据9个字段的不同组合去做计算。  第一个方法是：我目前做法是切分的9个字段开5分钟大小1分钟计算一次的滑动窗口窗口，进行一次reduce去重，然后再map取出需要的字段，然后过滤再开5分钟大小1分钟计算一次的滑动窗口窗口进行计算保存结果，这个思路遇到的问题是上一个滑动窗口会每一分钟会计算5分钟数据，到第二个窗口划定的5分钟范围的数据会有好多重复，这个思路会造成数据重复。 第二个方法是：切分的9个字段开5分钟大小1分钟计算一次的滑动窗口窗口，再pross方法里完成所有的过滤，聚合计算，但是再高峰期每分钟400万条数据，这个思路担心在高峰期flink计算不过来</a></p><p>170、<a href="https://t.zsxq.com/aAqBEY7">a,b,c三个表，a和c有eventtime，a和c直接join可以，a和b join后再和c join 就会报错，这是怎么回事呢</a></p><p>171、<a href="https://t.zsxq.com/zZNNRzr">自定义的source是这样的（图一所示） 使用的时候是这样的（图二所示），为什么无论 sum.print().setParallelism(2)（图2所示）的并行度设置成几最后结果都是这样的</a></p><p>172、<a href="https://t.zsxq.com/i6Mz7Yj">刚接触flink，如有问的不合适的地方，请见谅。 1、为什么说flink是有状态的计算？ 2、这个状态是什么？3、状态存在哪里</a></p><p>173、<a href="https://t.zsxq.com/vNjAIMN">这边用flink 1.8.1的版本，采用flink on yarn，hadoop版本2.6.0。代码是一个简单的滚动窗口统计函数，但启动的时候报错，如下图片。  （2）然后我把flink版本换成1.7.1，重新提交到2.6.0的yarn平台，就能正常运行了。 （3）我们测试集群hadoop版本是3.0，我用flink 1.8.1版本将这个程序再次打包，提交到3.0版本的yarn平台，也能正常运行。 貌似是flink 1.8.1版本与yarn 2.6.0版本不兼容造成的这个问题</a></p><p>174、<a href="https://t.zsxq.com/2rVbm6Y">StateBackend我使用的是MemoryStateBackend， State是怎么释放内存的，例如我在函数中用ValueState存储了历史状态信息。但是历史状态数据我没有手动释放，那么程序会自动释放么？还是一直驻留在内存中</a></p><p>175、<a href="https://t.zsxq.com/3bIEAyv">请问老师是否可以提供一些Apachebeam的学习资料 谢谢</a></p><p>176、<a href="https://t.zsxq.com/yFEyZVB">flink 的 DataSet或者DataStream支持索引查询以及删除吗，像spark rdd，如果不支持的话，该转换成什么</a></p><p>177、<a href="https://t.zsxq.com/VNrn6iI">关于flink的状态，能否把它当做数据库使用，类似于内存数据库，在处理过程中存业务数据。如果是数据库可以算是分布式数据库吗?是不是使用rocksdb这种存储方式才算是?支持的单库大小是不是只是跟本地机器的磁盘大小相关?如果使用硬盘存储会不会效率性能有影响</a></p><p>178、<a href="https://t.zsxq.com/yfmiUvf">我这边做了个http sink，想要批量发送数据，不过现在只能用数量控制发送，但最后的几个记录没法触发发送动作，想问下有没有什么办法</a></p><p>179、<a href="https://t.zsxq.com/vNvrfmE">请问下如何做定时去重计数，就是根据时间分窗口，窗口内根据id去重计数得出结果，多谢。试了不少办法，没有简单直接办法</a></p><p>180、<a href="https://t.zsxq.com/rzZbQFA">我有个job使用了elastic search sink. 设置了批量5000一写入，但是看es监控显示每秒只能插入500条。是不是bulkprocessor的currentrequest为0有关</a></p><p>181、<a href="https://t.zsxq.com/aIur7ai">有docker部署flink的资料吗</a></p><p>182、<a href="https://t.zsxq.com/VjQjqF6">在说明KeyBy的StreamGraph执行过程时，keyBy的ID为啥是6？  根据前面说，ID是一个静态变量，每取一次就递增1，我觉得应该是3啊，是我理解错了吗</a></p><p>183、<a href="https://t.zsxq.com/BEmAIQv">有没计划出Execution Graph的远码解析</a></p><p>184、<a href="https://t.zsxq.com/vVjiYJQ">可以分享下物理执行图怎样划分task，以及task如何执行，还有他们之间数据如何传递这块代码嘛？</a></p><p>185、<a href="https://t.zsxq.com/FyNJQbQ">Flink源码和这个学习项目的结构图</a></p><p>186、<a href="https://t.zsxq.com/qrjmmaU">请问flink1.8，如何做到动态加载外部udf-jar包呢？</a></p><p>187、<a href="https://t.zsxq.com/ZFQjQnm">同一个Task Manager中不同的Slot是怎么交互的，比如：source处理完要传递给map的时候，如果在不同的Slot中，他们的内存是相互隔离，是怎么交互的呢？  我猜是通过序列化和反序列化对象，并且通过网络来进行交互的</a></p><p>188、<a href="https://t.zsxq.com/YBQFufi">你们有没有这种业务场景。flink从kafka里面取数据，每一条数据里面有mongdb表A的id,这时我会在map的时候采用flink的异步IO连接A表，然后查询出A表的字段1，再根据该字段1又需要异步IO去B表查询字段2，然后又根据字段2去C表查询字段3…..像这样的业务场景，如果多来几种逻辑，我应该用什么方案最好呢</a></p><p>189、<a href="https://t.zsxq.com/vnufYFY">今天本地运行flink程序，消费socket中的数据，连续只能消费两条，第三条flink就消费不了了</a></p><p>190、<a href="https://t.zsxq.com/me6EmM3">源数据经过过滤后分成了两条流，然后再分别提取事件时间和水印，做时间窗口，我测试时一条流没有数据，另一条的数据看日志到了窗口操作那边就没走下去，貌似窗口一直没有等到触发</a></p><p>191、<a href="https://t.zsxq.com/fubQrvj">有做flink cep的吗，有资料没？</a></p><p>192、<a href="https://t.zsxq.com/fEQVjAe">麻烦问一下 BucketingSink跨集群写，如果任务运行在hadoop A集群，从kafka读取数据处理后写到Hadoo B集群，即使把core-site.xml和hdfs-site.xml拷贝到代码resources下，路径使用hdfs://hadoopB/xxx，会提示ava.lang.RuntimeException: Error while creating FileSystem when initializing the state of the BucketingSink.，跨集群写这个问题  flink不支持吗？</a></p><p>193、<a href="https://t.zsxq.com/fIMVJ2J">想咨询下，如何对flink中的datastream和dataset进行数据采样</a></p><p>194、<a href="https://t.zsxq.com/7MVjyzz">一个flink作业经常发生oom，可能是什么原因导致的。  处理流程只有15+字段的解析，redis数据读取等操作，TM配置10g。  业务会在夜间刷数据，qps能打到2500左右~</a></p><p>195、<a href="https://t.zsxq.com/jA2NVnU">我看到flink 1.8的状态过期仅支持Processing Time，那么如果我使用的是Event time那么状态就不会过期吗</a></p><p>196、<a href="https://t.zsxq.com/BQv33Rb">请问我想每隔一小时统计一个属性从当天零点到当前时间的平均值，这样的时间窗该如何定义？</a></p><p>197、<a href="https://t.zsxq.com/nEAiIea">flink任务里面反序列化一个类，报ClassNotFoundException，可是包里面是有这个类的，有遇到这种情况吗？</a></p><p>198、<a href="https://t.zsxq.com/RnayrVn">在构造StreamGraph，类似PartitionTransformmation 这种类型的 transform，为什么要添加成一个虚拟节点，而不是一个实际的物理节点呢？</a></p><p>199、<a href="https://t.zsxq.com/A2fYNFA">flink消费kafka的数据写入到hdfs中，我采用了BucketingSink 这个sink将operator出来的数据写入到hdfs文件上，并通过在hive中建外部表来查询这个。但现在有个问题，处于in-progress的文件，hive是无法识别出来该文件中的数据，可我想能在hive中实时查询进来的数据，且不想产生很多的小文件，这个该如何处理呢</a></p><p>200、<a href="https://t.zsxq.com/7AurJU3">采用Flink单机集群模式一个jobmanager和两个taskmanager，机器是单机是24核，现在做个简单的功能从kafka的一个topic转满足条件的消息到另一个topic，topic的分区是30，我设置了程序默认并发为30，现在每秒消费2w多数据，不够快，请问可以怎么提高job的性能呢？</a></p><p>201、<a href="https://t.zsxq.com/Mnm2nI6">Flink Metric 源码分析</a></p><p>202、<a href="https://t.zsxq.com/iAi6QRb">请问怎么理解官网的这段话？按官网的例子，难道只keyby之后才有keyed state，才能托管Flink存储状态么？source和map如果没有自定义operator state的话，状态是不会被保存的？</a></p><p>203、<a href="https://t.zsxq.com/3rbeuju">想用Flink做业务监控告警，并要能够支持动态添加CEP规则，问下可以直接使用Flink CEP还是siddhi CEP? 有没有相关的资料学习下？谢谢！</a></p><p>204、<a href="https://t.zsxq.com/eYJUbm6">请问一下，有没有关于水印，触发器的Java方面的demo啊</a></p><p>205、<a href="https://t.zsxq.com/QvbAqVB">老师，最近我们线上偶尔出现这种情况，就是40个并行度，其他有一个并行度CheckPoint一直失败，其他39个并行度都是毫秒级别就可以CheckPoint成功，这个怎么定位问题呢？还有个问题 CheckPoint的时间分为三部分 Checkpoint Duration (Async）和 Checkpoint Duration (Sync），还有个 end to end 减去同步和异步的时间，这三部分 分别指代哪块？如果发现这三者中的任意一个步骤时间长，该怎么去优化</a></p><p>206、<a href="https://t.zsxq.com/JaUZvbY">我这边有个场景很依赖消费出来的数据的顺序。在源头侧做了很多处理，将kafka修改成一个分区等等很多尝试，最后消费出来的还是乱序的。能不能在flink消费的时候做处理，来保证处理的数据的顺序。</a></p><p>207、<a href="https://t.zsxq.com/iQfaAeu">有一个类似于实时计算今天的pv，uv需求，采用source-&gt;keyby-&gt;window-&gt;trigger-&gt;process后，在process里采用ValueState计算uv  ,问题是 这个window内一天的所有数据是都会缓存到flink嘛？ 一天的数据量如果大点，这样实现就有问题了，  这个有其他的实现思路嘛？</a></p><p>208、<a href="https://t.zsxq.com/f6eAu3J">Flink 注解源码解析</a></p><p>209、<a href="https://t.zsxq.com/IuRJYne">如何监控 Flink 的 TaskManager 和 JobManager</a></p><p>210、<a href="https://t.zsxq.com/v7yfEIq">问下，在真实流计算过程中，并行度的设置，是与 kafka topic的partition数一样的吗？</a></p><p>211、<a href="https://t.zsxq.com/Zf2F6mM">Flink的日志 如果自己做平台封装在自己的界面中 请问job Manger 和 taskManger 还有用户自己的程序日志 怎么获取呢 有api还是自己需要利用flume 采集到ELK？</a></p><p>212、<a href="https://t.zsxq.com/72VzBEy">我想问下一般用Flink统计pv uv是怎么做的？uv存到redis? 每个uv都存到redis，会不会撑爆？</a></p><p>213、<a href="https://t.zsxq.com/zBmm2fq">Flink的Checkpoint 机制，在有多个source的时候，barrier n 的流将被暂时搁置，从其他流接收的记录将不会被处理，但是会放进一个输入缓存input buffer。如果被缓存的record大小超出了input buffer会怎么样？不可能一直缓存下去吧，如果其中某一条就一直没数据的话，整个过程岂不是卡死了？</a></p><p>214、<a href="https://t.zsxq.com/ZnIAi2j">公司想实时展示订单数据，汇总金额，并需要和前端交互，实时生成数据需要告诉前端，展示成折线图，这种场景的技术选型是如何呢？包括数据的存储，临时汇总数据的存储，何种形式告诉前端</a></p><p>215、<a href="https://t.zsxq.com/7EIeEyJ">请问下checkpoint中存储了哪些东西？</a></p><p>216、<a href="https://t.zsxq.com/euvFaYz">我这边有个需求是实时计算当前车辆与前车距离，用经纬度求距离。大概6000台车，10秒一条经纬度数据。gps流与自己join的地方在进行checkpoint的时候特别缓，每次要好几分钟。checkpoint 状态后端是rocksDB。有什么比较好的方案吗？自己实现一个类似last_value的函数取车辆最新的经纬再join，或者弄个10秒的滑动窗口输出车辆最新的经纬度再进行join，这样可行吗？</a></p><p>217、<a href="https://t.zsxq.com/YRnEUFe">flink在启动的时候能不能指定一个时间点从kafka里面恢复数据呢</a></p><p>218、<a href="https://t.zsxq.com/7QJEEyr">我们线上有个问题，很多业务都去读某个hive表，但是当这个hive表正在写数据的时候，偶尔出现过 读到表里数据为空的情况，这个问题怎么解决呢？</a></p><p>219、<a href="https://t.zsxq.com/yVnaYR7">使用 InfluxDB 和 Grafana 搭建监控 Flink 的平台</a></p><p>220、<a href="https://t.zsxq.com/uvFU7aY">flink消费kafka两个不同的topic,然后进行join操作，如果使用事件时间，两个topic都要设置watermaker吗，如果只设置了topic  A的watermaker,topic B的不设置会有什么影响吗？</a></p><p>221、<a href="https://t.zsxq.com/NNFYJMn">请教一个问题，我的Flink程序运行一段时间就会报这个错误，定位好多天都没有定位到。checkpoint 时间是5秒，20秒都不行。Caused by: java.io.IOException: Could not flush and close the file system output stream to hdfs://HDFSaaaa/flink/PointWideTable_OffTest_Test2/1eb66edcfccce6124c3b2d6ae402ec39/chk-355/1005127c-cee3-4099-8b61-aef819d72404 in order to obtain the stream state handle</a></p><p>222、<a href="https://t.zsxq.com/yvRNFEI">Flink的反压机制相比于Storm的反压机制有什么优势呢？问题2: Flink的某一个节点发生故障，是否会影响其他节点的正常工作？还是会通过Checkpoint容错机制吗把任务转移到其他节点去运行呢？</a></p><p>223、<a href="https://t.zsxq.com/ZJmiqZz">我在验证checkpoint的时候遇到给问题，不管是key state 还是operator state，默认和指定uid是可以的恢复state数据的，当指定uidHash时候无法恢复state数据，麻烦大家给解答一样。我操作state是实现了CheckpointedFunction接口，覆写snapshotState和initializeState，再这两个方法里操作的，然后让程序定时抛出异常，观察发现指定uidHash后snapshotState()方法里context.isRestored()为false，不太明白具体是什么原因</a></p><p>224、<a href="https://t.zsxq.com/mYV37qF">kafka 中的每条数据需要和 es 中的所有数据(动态增加)关联，关联之后会做一些额外的操作，这个有什么比较可行的方案？</a></p><p>225、<a href="https://t.zsxq.com/buFeyZr">flink消费kafka数据，设置1分钟checkpoint一次，假如第一次checkpoint完成以后，还没等到下一次checkpoint，程序就挂了，kafka offset还是第一次checkpoint记录的offset,那么下次重新启动程序，岂不是多消费数据了？那flink的 exactly one消费语义是怎么样的？</a></p><p>226、<a href="https://t.zsxq.com/Znyja62">程序频繁发生Heartbeat of TaskManager with id container_e36_1564049750010_5829_01_000024 timed out. 心跳超时，一天大概10次左右。是内存没给够吗？还是网络波动引起的</a></p><p>227、<a href="https://t.zsxq.com/AA6ma2Z">有没有性能优化方面的指导文章？</a></p><p>228、<a href="https://t.zsxq.com/a2N37a6">flink消费kafka是如何监控消费是否正常的，有啥好办法？</a></p><p>229、<a href="https://t.zsxq.com/m2FeeMf">我按照官方的wordcount案例写了一个例子，然后在main函数中起了一个线程，原本是准备定时去更新某些配置，准备测试一下是否可行，所以直接在线程函数中打印一条语句测试是否可行。现在测试的结果是不可行，貌似这个线程根本就没有执行，请问这是什么原因呢？   按照理解，JobClient中不是反射类执行main函数吗， 执行main函数的时候为什么没有执行这个线程的打印函数呢？</a></p><p>230、<a href="https://t.zsxq.com/EyFUb6m">请问我想保留最近多个完成的checkpoint数据，是通过设置 state.checkpoints.num-retained 吗？要怎么使用？</a></p><p>231、<a href="https://t.zsxq.com/rFeIAeA">有没有etl实时数仓相关案例么？比如二十张事实表流join</a></p><p>232、<a href="https://t.zsxq.com/n2RFmyN">为什么我扔到flink 的stream job，立刻就finished</a></p><p>233、<a href="https://t.zsxq.com/iqJiyvN">有没有在flink上机器学习算法的一些例子啊，除了官网提供的flink exampke里的和flink ml里已有的</a></p><p>234、<a href="https://t.zsxq.com/uB6aUzZ">如果我想扩展sql的关键词，比如添加一些数据支持，有什么思路，现在想的感觉都要改calcite（刚碰flink感觉难度太大了）</a></p><p>235、<a href="https://t.zsxq.com/2BEeu3Z">我想实现统计每5秒中每个类型的次数，这个现在不输出，问题出在哪儿啊</a></p><p>236、<a href="https://t.zsxq.com/VBA6IUR">我用flink往hbase里写数据，有那种直接批量写hfile的方式的demo没</a></p><p>237、<a href="https://t.zsxq.com/IieMFMB">请问怎么监控Kafka消费是否延迟，是否出现消息积压？你有demo吗？这种是用Springboot自己写一个监控，还是咋整啊？</a></p><p>238、<a href="https://t.zsxq.com/j2fM3BM">请问有计算pv uv的例子吗</a></p><p>239、<a href="https://t.zsxq.com/Rb2Z7uB">通过控制流动态修改window算子窗口类型和长度要怎么写</a></p><p>240、<a href="https://t.zsxq.com/UVbaQfM">flink的远程调试能出一版么？网上资料坑的多</a></p><p>241、<a href="https://t.zsxq.com/AYVjAuB">企业里，Flink开发，java用得多，还是scala用得多？</a></p><p>242、<a href="https://t.zsxq.com/j6QfMzf">flink的任务运行在yarn的环境上，在yarn的resourcemanager在进行主备切换时，所有的flink任务都失败了，而MR的任务可以正常运行。报错信息如下：AM is not registered for known application attempt: appattempt_1565306391442_89321_000001 or RM had restarted after AM registered . AM should re-register<br>     请问这是什么原因，该如何处理呢？</a></p><p>243、<a href="https://t.zsxq.com/IUVZjUv">请教一个分布式问题，比如在Flink的多个TaskManager上统计指标count，TM1有两条数据，TM2有一条数据，程序是怎么计算出来是3呢？原理是怎么样的</a></p><p>244、<a href="https://t.zsxq.com/7MFEQR3">现在公司部分sql查询oracle数据特别的慢，因为查询条件很多想问一下有什么方法，例如基于大数据组件可以加快查询速度的吗？</a></p><p>245、<a href="https://t.zsxq.com/Mfa6aQB">想咨询下有没有做过flink同步配置做自定义计算的系统？或者有没有什么好的建议？业务诉求是希望业务用户可以自助配置计算规则做流式计算</a></p><p>246、<a href="https://t.zsxq.com/z3bunyN">我这边有个实时同步数据的任务，白天运行的时候一直是正常的，一到凌晨2点多之后就没有数据sink进mysql。晚上会有一些离线任务和一些dataX任务同步数据到mysql。但是任务一切都是正常的，ck也很快20ms，数据也是正常消费。看了yarn上的日志，没有任何error。自定义的sink里面也设置了日志打印，但是log里没有。这种如何快速定位问题。</a></p><p>247、<a href="https://t.zsxq.com/Y3fe6Mn">有没有flink处理异常数据的案例资料</a></p><p>248、<a href="https://t.zsxq.com/I2Z7Ybm">flink中如何传递一个全局变量</a></p><p>249、<a href="https://t.zsxq.com/iIUZrju">台4核16G的Flink taskmanager配一个单独的Yarn需要一台啥样的服务器？其他功能都不需要就一个调度的东西？</a></p><p>250、<a href="https://t.zsxq.com/m6I2BEE">side-output 的分享</a></p><p>251、<a href="https://t.zsxq.com/amURFme">使用 InfluxDB + Grafana 监控flink能否配置告警。是不是prometheus更强大点？</a></p><p>252、<a href="https://t.zsxq.com/rZfyZvn">我们线上遇到一个问题，带状态的算子没有指定 uid，现在代码必须改，那个带状态的算子 不能正常恢复了，有解吗？通过某种方式能获取到系统之前自动生成的uid吗？</a></p><p>253、<a href="https://t.zsxq.com/uZz3Z7Q">tableEnv.registerDataStream(“Orders”, ds, “user, product, amount, proctime.proctime, rowtime.rowtime”);请问像这样把流注册成表的时候，这两个rowtime分别是什么意思</a></p><p>254、<a href="https://t.zsxq.com/yBiEyf2">我想问一下 flink on yarn session 模式下提交任务官网给的例子是 flink run -c xxx.MainClass job.jar 这里是怎么知道 yarn 上的哪个是 flink 的 appid 呢？</a></p><p>255、<a href="https://t.zsxq.com/yBeyfqv">Flink Netty Connector 这个有详细的使用例子？ 通过Netty建立的source能直接回复消息吗？还是只能被动接受消息？</a></p><p>256、<a href="https://t.zsxq.com/FIEia6M">请问flink sqlclient 提交的作业可以用于生产环境吗？</a></p><p>257、<a href="https://t.zsxq.com/ZBIaUvF">flink批处理写回mysql是否没法用tableEnv.sqlUpdate(“insert into t2 select * from t1”)？作为sink表的t2要如何注册？查跟jdbc相关的就两个TableSink，JDBCAppendTableSink用于BatchTableSink，JDBCUpertTablSink用于StreamTableSink。前者只接受insert into  values语法。所以我是先通过select from查询获取到DataSet再JDBCAppendTableSink.emitDataSet(ds)实现的，但这样达不到sql rule any目标</a></p><p>258、<a href="https://t.zsxq.com/aq3BIU7">请问在stream模式下，flink的计算结果在不落库的情况下，可以通过什么restful api获取计算结果吗</a></p><p>259、<a href="https://t.zsxq.com/NbYnAYF">现在我有场景，需要把一定的消息发送给kafka topic指定的partition，该怎么搞？</a></p><p>260、<a href="https://t.zsxq.com/YfmAMfm">请问我的job作业在idea上运行正常 提交到生产集群里提示Caused by: java.lang.NoSuchMethodError: org.apache.flink.api.java.ClosureCleaner.clean(Ljava/lang/Object;Z)V请问如何解决</a></p><p>261、<a href="https://t.zsxq.com/72n6MVb">遇到一个很奇怪的问题，在使用streamingSQL时，发现timestamp在datastream的时候还是正常的，在注册成表print出来的时候就少了八小时，大佬知道是什么原因么？</a></p><p>262、<a href="https://t.zsxq.com/RjQFmIQ">请问将flink的产生的一些记录日志异步到kafka中，需要如何配置，配置后必须要重启集群才会生效吗</a></p><p>263、<a href="https://t.zsxq.com/Q7u3vzR">星主你好，问下flink1.9对维表join的支持怎么样了？有文档吗</a></p><p>264、<a href="https://t.zsxq.com/aEEA66M">请问下 flink slq： SELECT city_name as city_name, count(1) as total, max(create_time) as create_time FROM * 。代码里面设置窗口为： retractStream.timeWindowAll(Time.minutes(5))一个global窗口，数据写入hdfs   结果数据重复 ，存在两条完全重复的数据如下 常州、2283、 1566230703）：请问这是为什么</a></p><p>265、<a href="https://t.zsxq.com/YNrfyrj">我用rocksdb存储checkpoint，线上运行一段时间发展checkpoint占用空间越来越大，我是直接存本地磁盘上的，怎么样能让它自动清理呢？</a></p><p>266、<a href="https://t.zsxq.com/aAaqFYn">flink应该在哪个用户下启动呢，是root的还是在其他的用户呢</a></p><p>267、<a href="https://t.zsxq.com/2nUBIAI">link可以读取lzo的文件吗</a></p><p>268、<a href="https://t.zsxq.com/beIY7mY">怎么快速从es里面便利数据？我们公司现在所有的数据都存在Es里面的;我发现每次从里面scan数据的时候特别慢;你那有没有什么好的办法？</a></p><p>269、<a href="https://t.zsxq.com/fYnYrR7">如果想让数据按照其中一个假如f0进行分区，然后每一个分区做处理的时候并行度都是1怎么设置呢</a></p><p>270、<a href="https://t.zsxq.com/nQFYrBm">近在写算子的过程中,使用scala语言写flink比较快,而且在process算子中实现ontime方式时,可以使用scala中的listbuff来输出一个top3的记录;那么到了java中,只能用ArrayList将flink中的ListState使用get()方法取出之后放在ArrayList吗?</a></p><p>271、<a href="https://t.zsxq.com/eyRRv7q">请问老师能否出一些1.9版本维表join的例子 包括async和维表缓存？</a></p><p>272、<a href="https://t.zsxq.com/aMRzjMb">flink kaka source设置为从组内消费，有个问题是第一次启动任务，我发现kafka中的历史数据不会被消费，而是从当前的数据开始消费，而第二次启动的时候才会从组的offset开始消费，有什么办法可以让第一次启动任务的时候可以消费kafka中的历史数据吗</a></p><p>273、<a href="https://t.zsxq.com/3ZjiEMv">1.使用flink定时处理离线数据，有时间戳字段，如何求出每分钟的最大值，类似于流处理窗口那样，2如果想自己实现批流统一，有什么好的合并方向吗？比如想让流处理使用批处理的一个算子。</a></p><p>274、<a href="https://t.zsxq.com/AIYnEQN">flink怎么实现流式数据批量对待？流的数据是自定义的source，读取的redis多个Hash表，需要控制批次的概念</a></p><p>275、<a href="https://t.zsxq.com/yJuFEYb">有人说不推荐在一个task中开多个线程，这个你怎么看？</a></p><p>276、<a href="https://t.zsxq.com/3f6YBmu">想做一个运行在hbase+es架构上的sql查询方案，flink sql能做吗，或者有没有其他的解决方案或者思路？</a></p><p>277、<a href="https://t.zsxq.com/jIAqVnm">正在紧急做第一个用到Flink的项目，咨询一下，Flink 1.8.1写入ES7就是用自带的Sink吗？有没有例子分享一下，我搜到的都是写ES6的。这种要求我知道不适合提，主要是急，自己试几下没成功。T T</a></p><p>278、<a href="https://t.zsxq.com/2fAiuzf">手动停止任务后，已经保存了最近一次保存点，任务重新启动后，如何使用上一次检查点？</a></p><p>279、<a href="https://t.zsxq.com/BIiImQN">批处理使用流环境（为了使用窗口），那如何确定批处理结束，就是我的任务可以知道批文件读取完事，并且处理完数据后关闭任务，如果不能，那批处理如何实现窗口功能</a></p><p>280、<a href="https://t.zsxq.com/Mjyzj66">如果限制只能在window 内进行去重，数据量还比较大，有什么好的方法吗？</a></p><p>281、<a href="https://t.zsxq.com/yv7Ujme">端到端exactly once有没有出文章</a></p><p>282、<a href="https://t.zsxq.com/IqNZFey">流怎么动态加？，流怎么动态删除？，参数怎么动态修改 （广播</a></p><p>283、<a href="https://t.zsxq.com/r7AqvBq">自定义的source数据源实现了有批次的概念，然后Flink将这个一个批次流注册为多个表join操作，有办法知道这个sql什么时候计算完成了？</a></p><p>284、<a href="https://t.zsxq.com/rvJiyf6">编译 Flink 报错，群主遇到过没，什么原因</a></p><p>285、[我现在是flink on yarn用zookeeper做HA现在在zk里查看检查点信息，为什么里面的文件是ip，而不是路径呢？我该如何拿到那个路径。</p><pre><code>- 排除rest api 方式获取，因为任务关了restapi就没了-排除history server，有点不好用](https://t.zsxq.com/nufIaey)</code></pre><p>286、<a href="https://t.zsxq.com/Fy3RfE6">在使用streamfilesink消费kafka之后进行hdfs写入的时候，当直接关闭flink程序的时候，下次再启动程序消费写入hdfs的时候，文件又是从part-0-0开始，这样就跟原来写入的冲突了，该文件就一直处于ingress状态。</a></p><p>287、<a href="https://t.zsxq.com/myNF2zj">现在有一个实时数据分析的需求，数据量不大，但要求sink到mysql，因为是实时更新的，我现在能想到的处理方法就是每次插入一条数据的时候，先从mysql读数据，如果有这条，就执行update，没有的话就insert，但是这样的话每写一条数据就有两次交互了。想问一下老师有没有更好的办法，或者flink有没有内置的api可以执行这种不确定是更新还是插入的操作</a></p><p>288、<a href="https://t.zsxq.com/ZFiMzrF">Flink设置了checkpoint，job manage会定期删除check point数据，但是task manage不删除，这个是什么原因</a></p><p>289、<a href="https://t.zsxq.com/z3RzJUV">请教一下使用rocksdb作为statebackend ，在哪里可以监控rocksdb io 内存指标呢</a></p><p>290、<a href="https://t.zsxq.com/AUjE2ZR">状态的使用场景，以及用法能出个文章不，这块不太了解</a></p><p>291、<a href="https://t.zsxq.com/aaynii6">请问一下  Flink 1.9  SQL API中distinct count 是如何实现高效的流式去重的？</a></p><p>292、<a href="https://t.zsxq.com/mmEyVJA">在算子内如何获取当前算子并行度以及当前是第几个task</a></p><p>293、<a href="https://t.zsxq.com/fIqNF6y">有没有flink1.9结合hive的demo。kafka到hive</a></p><p>294、<a href="https://t.zsxq.com/ne6UZrB">能给讲讲apache calcite吗</a></p><p>295、<a href="https://t.zsxq.com/VbUVFMr">请问一下像这种窗口操作，怎么保证程序异常重启后保持数据的状态呢？</a></p><p>296、<a href="https://t.zsxq.com/EMZFyZz">请问一下，我在使用kafkasource的时候，把接过来的Jsonstr转化成自定义的一个类型，用的是gson. fromJson（jsonstr,classOf[Entity]）报图片上的错误了，不知道怎么解决，在不转直接打印的情况下是没问题的</a></p><p>297、<a href="https://t.zsxq.com/IEieI6a">DataStream读数据库的表，做多表join，能设置时间窗口么，一天去刷一次。流程序会一直拉数据，数据库扛不住了</a></p><p>298、<a href="https://t.zsxq.com/IemmiY7">请问一下flink支持多路径通配读取吗？例如路径：s3n://pekdc2-deeplink-01/Kinesis/firehose/2019/07/03/<em>/</em>  ，通配读取找不到路径。是否需要特殊设置</a></p><p>299、<a href="https://t.zsxq.com/QvZFUNN">flink yarn环境部署 但是把容器的url地址删除。就会跳转到的hadoop的首页。怎么屏蔽hadoop的yarn首页地址呢？要不暴露这个地址用户能看到所有任务很危险</a></p><p>300、<a href="https://t.zsxq.com/2JiubeM">flink sql怎么写一个流，每秒输出当前时间呢</a></p><p>301、<a href="https://t.zsxq.com/bQ33BmM">因为想通过sql弄一个数据流。哈哈 另外想问一个问题，我把全局设置为根据处理时间的时间窗口，那么我在processAllWindowFunction里面要怎么知道进来的每个元素的处理时间是多少呢？这个元素进入这个时间窗口的依据是什么</a></p><p>302、<a href="https://t.zsxq.com/rB6ybYF">如何实现一个设备上报的数据存储到同一个hdfs文件中？</a></p><p>303、<a href="https://t.zsxq.com/MVfeeiu">我自己写的kafka生产者测试，数据格式十分简单（key,i）key是一个固定的不变的字符串，i是自增的，flink consumer这边我开了checkpoint. 并且是exactly once，然后程序很简单，就是flink读取kafka的数据然后直接打印出来，我发现比如我看到打印到key，10的时候我直接关掉程序，然后重新启动程序，按理来说应当是从上次的offset继续消费，也就是key,11，但实际上我看到的可能是从key，9开始，然后依次递增，这是是不是说明是重复消费了，那exactly one需要怎么样去保障？</a></p><p>304、<a href="https://t.zsxq.com/meqzJme">假设有一个数据源在源源不断的产生数据，到Flink的反压来到source端的时候，由于Flink处理数据的速度跟不上数据源产生数据的速度，<br>     问题1: 这个时候在Flink的source端会怎么处理呢？是将处理不完的数据丢弃还是进行缓存呢？<br>     问题2: 如果是缓存，怎么进行缓存呢？</a></p><p>305、<a href="https://t.zsxq.com/2fEeMny">一个stream 在sink多个时，这多个sink是串行 还是并行的。</a></p><p>306、<a href="https://t.zsxq.com/NJY76uf">我想在流上做一个窗口，触发窗口的条件是固定的时间间隔或者数据量达到预切值，两个条件只要有一个满足就触发，除了重写trigger在，还有什么别的方法吗？</a></p><p>307、<a href="https://t.zsxq.com/A6UN7eE">使用rocksdb作为状态后端，对于使用sql方式对时间字段进行group by，以达到去窗口化，但是这样没办法对之前的数据清理，导致磁盘空间很大，对于这种非编码方式，有什么办法设置ttl，清理以前的数据吗</a></p><p>308、<a href="https://t.zsxq.com/a2fUnEM">请问什么时间窗为什么会有TimeWindow{start=362160000, end=362220000}<br>     和 TimeWindow{start=1568025300000, end=1568025360000}这两种形式，我都用的是一分钟的TumblingEventTimeWindows，为什么会出现不同的情况？</a></p><p>309、<a href="https://t.zsxq.com/Y3jqjuj">比如我统计一天的订单量。但是某个数据延迟一天才到达。比如2019.08.01这一天订单量应该是1000，但是有个100的单据迟到了，在2019.08.02才到达，那么导致2019.08.01这一天统计的是900.后面怎么纠正这个错误的结果呢</a></p><p>310、<a href="https://t.zsxq.com/zJaMNne">flink streaming 模式下只使用堆内内存么</a></p><p>311、<a href="https://t.zsxq.com/EmMrvVb">如果考虑到集群的迁移，状态能迁移吗</a></p><p>312、<a href="https://t.zsxq.com/6EUFeqr">我们现在有一个业务场景，数据上报的值是这样的格式（时间，累加值），我们需要这样的格式数据（时间，当前值）。当前值=累加值-前一个数据的累加值。flink如何做到呢，有考虑过state机制，但是服务宕机后，state就被清空了</a></p><p>313、<a href="https://t.zsxq.com/y7U7Mzf">Flink  On  k8s 与 Flink on  Yarn相比的优缺点是什么？那个更适合在生产环境中使用呢</a></p><p>314、<a href="https://t.zsxq.com/zVNbaYn">有没有datahub链接flink的 连接器呀</a></p><p>315、<a href="https://t.zsxq.com/FQRNJ2j">单点resourcemanager 挂了，对任务会产生什么影响呢</a></p><p>316、<a href="https://t.zsxq.com/rnemUN3">flink监控binlog,跟另一张维表做join后，sink到MySQL的最终表。对于最终表的增删改操作，需要定义不同的sink么？</a></p><p>317、<a href="https://t.zsxq.com/JaaQFqB">请问窗口是在什么时候合并的呢？例如：数据进入windowoperator的processElement，如果不是sessionwindow，是否会进行窗口合并呢？</a></p><p>318、<a href="https://t.zsxq.com/AqNFM33">Flink中一条流能参与多路计算，并多处输出吗？他们之前会不会相互影响？</a></p><p>319、<a href="https://t.zsxq.com/nUzbiYj">keyBy算子定义是将一个流拆分成不相交的分区，每个分区包含具有相同的key的元素。我不明白的地方是: keyBy怎么设置分区数，是给这个算子设置并行度吗？ 分区数和slot数量是什么关系？</a></p><p>320、<a href="https://t.zsxq.com/66URfQb">动态cep-pattern，能否详细说下？滴滴方案未公布，您贴出来的几张图片是基于1.7的。或者有什么想法也可以讲解下，谢谢了</a></p><p>321、<a href="https://t.zsxq.com/maEQ3NR">问题1：使用常驻型session ./bin/yarn-session.sh -n 10 -s 3 -d启动，这个时候分配的资源是yarn 队列里面的, flink提交任务 flink run xx.jar,  其余机器是怎样获取到flink需要运行时的环境的，因为我只在集群的一台机器上有flink 安装包。</a></p><p>322、<a href="https://t.zsxq.com/YjEYjQz">flink task manager中slot间的内存隔离，cpu隔离是怎么实现的？flink 设计slot的概念有什么意义，为什么不像spark executor那样，内部没有做隔离？</a></p><p>323、<a href="https://t.zsxq.com/nuzvVzZ">spark和kafka集成，direct模式，spark的一个分区对应kafka的一个主题的一个分区。那flink和kafka集成的时候，怎么消费kafka的数据，假设kafka某个主题5个partition</a></p><p>324、<a href="https://t.zsxq.com/27u3ZZf">./bin/flink run -m yarn-cluster 执行的flink job ，作业自己打印的日志通过yarn application的log查看不了，只有集群自身的日志，程序中logger.info打印日志存放在哪，还是我打包的方式问题，打日志用的是slf4j。</a></p><p>325、<a href="https://t.zsxq.com/miuzFY3">在物联网平台中，需要对每个key下的数据做越限判断，由于每个key的越限值是不同的，越限值配置在实时数据库中。<br>     若将越限值加载到state中，由于key的量很大（大概3亿左右），会导致state太大，可能造成内存溢出。若在处理数据时从实时数据库中读取越限值，由于网络IO开销，可能造成实时性下降。请问该如何处理？谢谢</a></p><p>326、<a href="https://t.zsxq.com/amURvZR">如果我一个flink程序有多个window操作，时间戳和watermark是不是每个window都需要分配，还有就是事件时间是不是一定要在数据源中就存在某个字段</a></p><p>327、<a href="https://t.zsxq.com/eqFuBYz">有没有flink1.9刚支持的用ddl链接kafka并写入hbase的资料，我们公司想把离线的数仓逐渐转成实时的，写sql对于我们来说上手更快一些，就想找一些这方面的资料学习一下。</a></p><p>328、<a href="https://t.zsxq.com/yVvR3V3">flink1.9 进行了数据类型的转化时发生了不匹配的问题，  目前使用的Type被弃用，推荐使用是datatypes 类型，但是之前使用的Type类型的方法 对应的schema typeinformation 目前跟datatypes的返回值不对应，请问下  该怎么去调整适配？</a></p><p>329、<a href="https://t.zsxq.com/6AIQnEi">link中处理数据其中一条出了异常都会导致整个job挂掉?有没有方法(除了异常捕获)让这条数据记录错误日志就行 下面的数据接着处理呢? 粗略看过一些容错处理，是关于程度挂了重启后从检查点拉取数据，但是如果这条数据本身就问提(特别生产上，这样就导致job直接挂了，影响有点大)，那应该怎么过滤掉这条问题数据呢(异常捕获是最后的方法</a></p><p>330、<a href="https://t.zsxq.com/RBmi2vB">我在一个做日报的统计中使用rabbitmq做数据源，为什么rabbitmq中的数据一直处于unacked状态，每分钟触发一次窗口计算，并驱逐计算过的元素，我在测试环境数据都能ack,但是一到生产环境就不行了，也没有报错，有可能是哪里出了问题啊</a></p><p>331、<a href="https://t.zsxq.com/fuNfuBi">我们目前数据流向是这样的，kafka source ，etl，redis sink 。这样chk 是否可以保证端到端语义呢？</a></p><p>332、<a href="https://t.zsxq.com/mIeMzvf">1.在通过 yarn-session 提交 flink job 的时候。flink-core, flink-clients, flink-scala, flink-streaming-scala, scala-library, flink-connector-kafka-0.10 那些应该写 provided scope，那些应该写 compile scope，才是正确、避免依赖冲突的姿势？<br>    2.flink-dist_2.11-1.8.0.jar 究竟包含了哪些依赖？（这个文件打包方式不同于 springboot，无法清楚看到有哪些 jar 依赖）</a></p><p>333、<a href="https://t.zsxq.com/AQzj6Qv">Flink 中使用 count window 会有这样的问题就是，最后有部分数据一直没有达到 count 的值，然后窗口就一直不触发，这里看到个思路，可以将 time window + count window 组合起来</a></p><p>334、<a href="https://t.zsxq.com/VvR3Bai">flink流处理时，注册一个流数据为Table后，该流的历史数据也会一直在Table里面么？为什么每次来新数据，历史处理过得数据会重新被执行？</a></p><p>335、<a href="https://t.zsxq.com/jMfyNZv">available是变化数据，除了最新的数据被插入数据库，之前处理过数据又重新执行了几次</a></p><p>336、<a href="https://t.zsxq.com/m6Yrv7Q">这里两天在研究flink的广播变量，发现一个问题，DataSet数据集中获取广播变量，获取的内存地址是一样的（一台机器维护一个广播数据集）。在DataStream中获取广播变量就成了一个task维护一个数据集。（可能是我使用方式有问题）  所以想请教下星主，DataStream中获取一个画面变量可以如DataSet中一台机器维护一个数据吗？</a></p><p>337、<a href="https://t.zsxq.com/nqzZrbq">Flink程序开启checkpoint 机制后，用yarn命令多次killed以后，ckeckpoint目录下有多个job id，再次开辟资源重新启动程序，程序如何找到上一次jobid目录下，而不是找到其他的jobid目录下？默认是最后一个还是需要制定特定的jobid？</a></p><p>338、<a href="https://t.zsxq.com/RNzfQ7e">发展昨天的数据重复插入问题，是把kafka里进来的数据流registerDataStream注册为Table做join时，打印表的长度发现，数据会一直往表里追加，怎样才能来一条处理一条，不往上追加呀</a></p><p>339、<a href="https://t.zsxq.com/AqRvNNj">flink1.9 sql 有没有类似分区表那样的处理方式呢？我们现在有一个业务是1个source，但是要分别计算5分钟，10分钟，15分钟的数据。</a></p><p>340、<a href="https://t.zsxq.com/q3feIuv">我刚弄了个服务器，在启动基础的命令时候发现task没有启动起来，导致web页是三个0，我看了log也没有报错信息，请问您知道可能是什么问题吗？</a></p><p>241、<a href="https://t.zsxq.com/EIiyjeU">我自定义了个 Sink extends RichSinkFunction，有了 field： private transient Object lock;<br>     这个 lock 我直接初始化  private transient Object lock = new Object(); 就不行，在 invoke 里 使用lock时空指针，如果lock在 自定义 Sink 的 构造器初始化也不行。但是在 open 方法里初始化就可以，为什么？能解释一下 执行原理吗？如果一个slot 运行着5个 sink实例，那么 这个sink对象会new 5个还是1个？</a></p><p>342、<a href="https://t.zsxq.com/aMNnIy3">请问Kafka的broker 个数怎么估算？</a></p><p>343、<a href="https://t.zsxq.com/BU7iqbi">flink on yarn如何远程调试</a></p><p>344、<a href="https://t.zsxq.com/F6U7YbY">目前有个需求：就是源数据是dataA、dataB、DataC通过kafka三个topic获取，然后进行合并。<br>     但是有有几个问题，目前不知道怎么解决：<br>     dataA=”id:10001,info:<strong><em>,date:2019-08-01 12:23:33,entry1:1,entryInfo1:</em></strong>“<br>     dataB=”id:10001,org:<strong><em>,entry:1”  dataC=”id:10001,location:</em></strong>“<br>     (1) 如何将三个流合并？ (1) 数据中dataA是有时间的，但是dataB和dataC中都没有时间戳，那么如何解决eventTime及迟到乱序的问题？帮忙看下，谢谢</a></p><p>345、<a href="https://t.zsxq.com/JmIqfaE">我flink从kafka读json数据，在反序列化后中文部分变成了一串问号，请问如何做才能使中文正常</a></p><p>346、<a href="https://t.zsxq.com/3BMZfAM">我有好几个Flink程序（独立jar），在线业务数据分析时都会用到同样的一批MySQL中的配置数据(5千多条)，现在的实现方法是每一个程序都是独立把这些配置数据装到内存中，便于快速使用，但现在感觉有些浪费资源和结构不够美观，请问这类情况有什么其他的解决方案吗？谢谢</a></p><p>347、<a href="https://t.zsxq.com/RFMjYZn">Flink  checkpoint  选 RocksDBStateBackend 还是 FsStatebackEnd ，我们目前是任务执行一段时间之后 任务就会被卡死。</a></p><p>348、<a href="https://t.zsxq.com/uVv7uJU">flink on k8s的高可用、扩缩容这块目前还有哪些问题？</a></p><p>349、<a href="https://t.zsxq.com/zFq3fqb">有个问题问一下，是这样的现在Kafka4个分区每秒钟生产4000多到5000条日志数据，但是在消费者FLINK这边接收我只开了4个solt接收，这边只是接收后做切分存储，现在出现了延迟现象，我不清楚是我这边处切分慢了还是Flink接收kafka的数据慢了？Flink UI界面显示这两个背压高</a></p><p>等等等，还有很多，复制粘贴的我手累啊 😂</p><p>另外里面还会及时分享 Flink 的一些最新的资料（包括数据、视频、PPT、优秀博客，持续更新，保证全网最全，因为我知道 Flink 目前的资料还不多）</p><p><a href="https://t.zsxq.com/AybAimM">关于自己对 Flink 学习的一些想法和建议</a></p><p><a href="https://t.zsxq.com/iaEiyB2">Flink 全网最全资料获取，持续更新，点击可以获取</a></p><p>再就是星球用户给我提的一点要求：不定期分享一些自己遇到的 Flink 项目的实战，生产项目遇到的问题，是如何解决的等经验之谈！</p><p>1、<a href="https://t.zsxq.com/Zz3ny3V">如何查看自己的 Job 执行计划并获取执行计划图</a></p><p>2、<a href="https://t.zsxq.com/AIAQrnq">当实时告警遇到 Kafka 千万数据量堆积该咋办？</a></p><p>3、<a href="https://t.zsxq.com/QnYjy7M">如何在流数据中比两个数据的大小？多种解决方法</a></p><p>4、<a href="https://t.zsxq.com/6Q3vN3b">kafka 系列文章</a></p><p>5、<a href="https://t.zsxq.com/iiYfMBe">Flink环境部署、应用配置及运行应用程序</a></p><p>6、<a href="https://t.zsxq.com/yfYrvFA">监控平台该有架构是长这样子的</a></p><p>7、<a href="https://t.zsxq.com/beu7Mvj">《大数据“重磅炸弹”——实时计算框架 Flink》专栏系列文章目录大纲</a></p><p>8、<a href="https://t.zsxq.com/UvrRNJM">《大数据“重磅炸弹”——实时计算框架 Flink》Chat 付费文章</a></p><p>9、<a href="https://t.zsxq.com/zjQvjeM">Apache Flink 是如何管理好内存的？</a></p><p>10、<a href="https://t.zsxq.com/eYNBaAa">Flink On K8s</a></p><p>11、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-core</a></p><p>12、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-datadog</a></p><p>13、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-dropwizard</a></p><p>14、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-graphite</a></p><p>15、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-influxdb</a></p><p>16、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-jmx</a></p><p>17、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-slf4j</a></p><p>18、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-statsd</a></p><p>19、<a href="https://t.zsxq.com/Mnm2nI6">Flink-metrics-prometheus</a></p><p>20、<a href="https://t.zsxq.com/f6eAu3J">Flink 注解源码解析</a></p><p>21、<a href="https://t.zsxq.com/yVnaYR7">使用 InfluxDB 和 Grafana 搭建监控 Flink 的平台</a></p><p>22、<a href="https://t.zsxq.com/UVfqfae">一文搞懂Flink内部的Exactly Once和At Least Once</a></p><p>23、<a href="https://t.zsxq.com/eM3ZRf2">一文让你彻底了解大数据实时计算框架 Flink</a></p><p>当然，除了更新 Flink 相关的东西外，我还会更新一些大数据相关的东西，因为我个人之前不是大数据开发，所以现在也要狂补些知识！总之，希望进来的童鞋们一起共同进步！</p><p>1、<a href="https://t.zsxq.com/7I6Iyrf">Java 核心知识点整理.pdf</a></p><p>2、<a href="https://t.zsxq.com/myJYZRF">假如我是面试官，我会问你这些问题</a></p><p>3、<a href="https://t.zsxq.com/iUZnamE">Kafka 系列文章和学习视频</a></p><p>4、<a href="https://t.zsxq.com/r7eIeyJ">重新定义 Flink 第二期 pdf</a></p><p>5、<a href="https://t.zsxq.com/ZjiYrVr">GitChat Flink 文章答疑记录</a></p><p>6、<a href="https://t.zsxq.com/QZVJyz7">Java 并发课程要掌握的知识点</a></p><p>7、<a href="https://t.zsxq.com/VVN7YB2">Lightweight Asynchronous Snapshots for Distributed Dataflows</a></p><p>8、<a href="https://t.zsxq.com/VVN7YB2">Apache Flink™- Stream and Batch Processing in a Single Engine</a></p><p>9、<a href="https://t.zsxq.com/NjAQFi2">Flink状态管理与容错机制</a></p><p>10、<a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里的实践</a></p><p>11、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>12、<a href="https://t.zsxq.com/MvfUvzN">Flink 流批一体的技术架构以及在阿里的实践</a></p><p>13、<a href="https://t.zsxq.com/N37mUzB">Stream Processing with Apache Flink pdf</a></p><p>14、<a href="https://t.zsxq.com/m6EAaQ3">Flink 结合机器学习算法的监控平台实践</a></p><p>15、<a href="https://t.zsxq.com/emMBaQN">《大数据重磅炸弹-实时计算Flink》预备篇——大数据实时计算介绍及其常用使用场景 pdf 和视频</a></p><p>16、<a href="https://t.zsxq.com/fqfuVRR">《大数据重磅炸弹-实时计算Flink》开篇词 pdf 和视频</a></p><p>17、<a href="https://t.zsxq.com/rVBQFI6">四本 Flink 书</a></p><p>18、<a href="https://t.zsxq.com/rVBQFI6">流处理系统 的相关 paper</a></p><p>19、<a href="https://t.zsxq.com/FyzvRne">Apache Flink 1.9 特性解读</a></p><p>20、<a href="https://t.zsxq.com/FyzvRne">打造基于Flink Table API的机器学习生态</a></p><p>21、<a href="https://t.zsxq.com/FyzvRne">基于Flink on Kubernetes的大数据平台</a></p><p>22、<a href="https://t.zsxq.com/FyzvRne">基于Apache Flink的高性能机器学习算法库</a></p><p>23、<a href="https://t.zsxq.com/FyzvRne">Apache Flink在快手的应用与实践</a></p><p>24、<a href="https://t.zsxq.com/FyzvRne">Apache Flink-1.9与Hive的兼容性</a></p><p>25、<a href="https://t.zsxq.com/FyzvRne">打造基于Flink Table API的机器学习生态</a></p><p>26、<a href="https://t.zsxq.com/rVBQFI6">流处理系统的相关 paper</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>美团点评基于 Flink 的实时数仓平台实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/30/flink-meituan-real-time-warehouse/</id>
    <published>2019-12-29T16:00:00.000Z</published>
    <updated>2020-02-15T05:24:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>数据仓库的建设是“数据智能”必不可少的一环，也是大规模数据应用中必然面临的挑战，而 Flink 实时数仓在数据链路中扮演着极为重要的角色。本文中，美团点评高级技术专家鲁昊为大家分享了美团点评基于 Apache Flink 的实时数仓平台实践。</p><a id="more"></a><p>本文授权转自社区公众号，<a href="https://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;mid=2247485571&amp;idx=1&amp;sn=fcce8640538e3e5bf12f61722f2e247a&amp;chksm=fd3b86c1ca4c0fd782fecc046c37e78d6a12851de89867c56b753577e9bad2646085f2989011&amp;scene=38#wechat_redirect">原文地址</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-033916.png" alt=""></p><p>目录：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034000.png" alt=""></p><h2 id="一、美团点评实时计算演进"><a href="#一、美团点评实时计算演进" class="headerlink" title="一、美团点评实时计算演进"></a>一、美团点评实时计算演进</h2><h3 id="美团点评实时计算演进历程"><a href="#美团点评实时计算演进历程" class="headerlink" title="美团点评实时计算演进历程"></a>美团点评实时计算演进历程</h3><p>在 2016 年，美团点评就已经基于 Storm 实时计算引擎实现了初步的平台化。2017 年初，我们引入了 Spark Streaming 用于特定场景的支持，主要是在数据同步场景方面的尝试。在 2017 年底，美团点评实时计算平台引入了 Flink。相比于 Storm 和 Spark Streaming，Flink 在很多方面都具有优势。这个阶段我们进行了深度的平台化，主要关注点是安全、稳定和易用。从 19 年开始，我们致力于建设包括实时数仓、机器学习等特定场景的解决方案来为业务提供更好的支持。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034138.png" alt=""></p><h3 id="实时计算平台"><a href="#实时计算平台" class="headerlink" title="实时计算平台"></a>实时计算平台</h3><p>目前，美团点评的实时计算平台日活跃作业数量为万级，高峰时作业处理的消息量达到每秒 1.5 亿条，而机器规模也已经达到了几千台，并且有几千位用户正在使用实时计算服务。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034317.png" alt=""></p><h3 id="实时计算平台架构"><a href="#实时计算平台架构" class="headerlink" title="实时计算平台架构"></a>实时计算平台架构</h3><p>如下图所示的是美团点评实时计算平台的架构。</p><ul><li><p>最底层是收集层，这一层负责收集用户的实时数据，包括 Binlog、后端服务日志以及 IoT 数据，经过日志收集团队和 DB 收集团队的处理，数据将会被收集到 Kafka 中。这些数据不只是参与实时计算，也会参与离线计算。</p></li><li><p>收集层之上是存储层，这一层除了使用 Kafka 做消息通道之外，还会基于 HDFS 做状态数据存储以及基于 HBase 做维度数据的存储。</p></li><li><p>存储层之上是引擎层，包括 Storm 和 Flink。实时计算平台会在引擎层为用户提供一些框架的封装以及公共包和组件的支持。</p></li><li><p>在引擎层之上就是平台层了，平台层从数据、任务和资源三个视角去管理。</p></li><li><p>架构的最上层是应用层，包括了实时数仓、机器学习、数据同步以及事件驱动应用等。</p></li></ul><p>本次分享主要介绍实时数仓方面的建设情况。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034831.png" alt=""></p><p>从功能角度来看，美团点评的实时计算平台主要包括作业和资源管理两个方面的功能。其中，作业部分包括作业配置、作业发布以及作业状态三个方面的功能。</p><ul><li><p>在作业配置方面，则包括作业设置、运行时设置以及拓扑结构设置；</p></li><li><p>在作业发布方面，则包括版本管理、编译/发布/回滚等；</p></li><li><p>作业状态则包括运行时状态、自定义指标和报警以及命令/运行时日志等。</p></li></ul><p>在资源管理方面，则为用户提供了多租户资源隔离以及资源交付和部署的能力。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-034952.png" alt=""></p><h3 id="业务数仓实践"><a href="#业务数仓实践" class="headerlink" title="业务数仓实践"></a>业务数仓实践</h3><ul><li>流量</li></ul><p>前面提到，现在的美团点评实时计算平台更多地会关注在安全、易用和稳定方面，而应用上很大的一个场景就是业务数仓。接下来会为大家分享几个业务数仓的例子。</p><p>第一个例子是流量，流量数仓是流量类业务的基础服务，从业务通道而言，会有不同通道的埋点和不同页面的埋点数据，通过日志收集通道会进行基础明细层的拆分，按照业务维度划分不同的业务通道，如美团通道、外卖通道等。</p><p>基于业务通道还会进行一次更加细粒度的拆分，比如曝光日志、猜你喜欢、推荐等。以上这些包括两种使用方式，一种是以流的方式提供下游其他业务方使用，另外一方面就是做一些流量方面的实时分析。</p><p>下图中右边是流量数仓的架构图，自下向上分为四层，分别是 SDK 层，包括了前端、小程序以及 APP 的埋点；其上是收集层，埋点日志落地到 Nginx，通过日志收集通道收到 Kafka 中。在计算层，流量团队基于 Storm 能力实现了上层的 SQL 封装，并实现了 SQL 动态更新的特性，在 SQL 变更时不必重启作业。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035047.png" alt=""></p><ul><li>广告实时效果</li></ul><p>这里再举一个基于流量数仓的例子-广告实时效果验证。下图中左侧是广告实时效果的对比图。广告的打点一般分为请求（PV）打点、SPV（Server PV）打点、CPV（Client PV）曝光打点和 CPV 点击打点，在所有打点中都会包含一个流量的 requestID 和命中的实验路径。根据 requestID 和命中的实验路径可以将所有的日志进行 join，得到一个 request 中需要的所有数据，然后将数据存入 Durid 中进行分析，支持实际 CTR、预估 CTR 等效果验证。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035155.png" alt=""></p><ul><li>即时配送</li></ul><p>这里列举的另外一个业务数仓实践的例子是即时配送。实时数据在即时配送的运营策略上发挥了重要作用。以送达时间预估为例，交付时间衡量的是骑手送餐的交付难度，整个履约时间分为了多个时间段，配送数仓会基于 Storm 做特征数据的清洗、提取，供算法团队进行训练并得到时间预估的结果。这个过程涉及到商家、骑手以及用户的多方参与，数据的特征会非常多，数据量也会非常大。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035241.png" alt=""></p><ul><li>总结</li></ul><p>业务实时数仓大致分为三类场景：流量类、业务类和特征类，这三种场景各有不同。</p><ul><li><p>在数据模型上，流量类是扁平化的宽表，业务数仓更多是基于范式的建模，特征数据是 KV 存储。</p></li><li><p>从数据来源区分，流量数仓的数据来源一般是日志数据；业务数仓的数据来源是业务 binlog 数据；特征数仓的数据来源则多种多样。</p></li><li><p>从数据量而言，流量和特征数仓都是海量数据，每天百亿级以上，而业务数仓的数据量一般每天百万到千万级。</p></li><li><p>从数据更新频率而言，流量数据极少更新，则业务和特征数据更新较多。流量数据一般关注时序和趋势，业务数据和特征数据关注状态变更。</p></li><li><p>在数据准确性上，流量数据要求较低，而业务数据和特征数据要求较高。</p></li><li><p>在模型调整频率上，业务数据调整频率较高，流量数据和特征数据调整频率较低。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035349.png" alt=""></p><h2 id="二、基于-Flink-的实时数仓平台"><a href="#二、基于-Flink-的实时数仓平台" class="headerlink" title="二、基于 Flink 的实时数仓平台"></a>二、基于 Flink 的实时数仓平台</h2><p>上面为大家介绍了实时数仓的业务场景，接下来为大家介绍实时数仓的演进过程和美团点评的实时数仓平台建设思路。</p><h3 id="传统数仓模型"><a href="#传统数仓模型" class="headerlink" title="传统数仓模型"></a>传统数仓模型</h3><p>为了更有效地组织和管理数据，数仓建设往往会进行数据分层，一般自下而上分为四层：ODS（操作数据层）、DWD（数据明细层）、DWS（汇总层）和应用层。即时查询主要通过 Presto、Hive 和 Spark 实现。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035440.png" alt=""></p><h3 id="实时数仓模型"><a href="#实时数仓模型" class="headerlink" title="实时数仓模型"></a>实时数仓模型</h3><p>实时数仓的分层方式一般也遵守传统数据仓库模型，也分为了 ODS 操作数据集、DWD 明细层和 DWS 汇总层以及应用层。但实时数仓模型的处理的方式却和传统数仓有所差别，如明细层和汇总层的数据一般会放在 Kafka 上，维度数据一般考虑到性能问题则会放在 HBase 或者 Tair 等 KV 存储上，即席查询则可以使用 Flink 完成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035516.png" alt=""></p><h3 id="准实时数仓模型"><a href="#准实时数仓模型" class="headerlink" title="准实时数仓模型"></a>准实时数仓模型</h3><p>在以上两种数仓模型之外，我们发现业务方在实践过程中还有一种准实时数仓模型，其特点是不完全基于流去做，而是将明细层数据导入到 OLAP 存储中，基于 OLAP 的计算能力去做汇总并进行进一步的加工。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035550.png" alt=""></p><h3 id="实时数仓和传统数仓的对比"><a href="#实时数仓和传统数仓的对比" class="headerlink" title="实时数仓和传统数仓的对比"></a>实时数仓和传统数仓的对比</h3><p>实时数仓和传统数仓的对比主要可以从四个方面考虑：</p><ul><li><p>第一个是分层方式，离线数仓为了考虑到效率问题，一般会采取空间换时间的方式，层级划分会比较多；则实时数仓考虑到实时性问题，一般分层会比较少，另外也减少了中间流程出错的可能性。</p></li><li><p>第二个是事实数据存储方面，离线数仓会基于 HDFS，实时数仓则会基于消息队列（如 Kafka）。</p></li><li><p>第三个是维度数据存储，实时数仓会将数据放在 KV 存储上面。</p></li><li><p>第四个是数据加工过程，离线数仓一般以 Hive、Spark 等批处理为主，而实时数仓则是基于实时计算引擎如 Storm、Flink 等，以流处理为主。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035634.png" alt=""></p><h3 id="实时数仓建设方案对比"><a href="#实时数仓建设方案对比" class="headerlink" title="实时数仓建设方案对比"></a>实时数仓建设方案对比</h3><p>下图中对于实时数仓的两种建设方式，即准实时数仓和实时数仓两种方式进行了对比。它们的实现方式分别是基于 OLAP 引擎和流计算引擎，实时度则分别是分钟和秒级。</p><p>在调度开销方面，准实时数仓是批处理过程，因此仍然需要调度系统支持，虽然调度开销比离线数仓少一些，但是依然存在，而实时数仓却没有调度开销。</p><p>在业务灵活性方面，因为准实时数仓基于 OLAP 引擎实现，灵活性优于基于流计算的方式。</p><p>在对数据晚到的容忍度方面，因为准实时数仓可以基于一个周期内的数据进行全量计算，因此对于数据晚到的容忍度也是比较高的，而实时数仓使用的是增量计算，对于数据晚到的容忍度更低一些。</p><p>在扩展性方面，因为准实时数仓的计算和存储是一体的，因此相比于实时数仓，扩展性更弱一些。</p><p>在适用场景方面，准实时数仓主要用于有实时性要求但不太高、数据量不大以及多表关联复杂和业务变更频繁的场景，如交易类型的实时分析，实时数仓则更适用于实时性要求高、数据量大的场景，如实时特征、流量分发以及流量类型实时分析。</p><p>总结一下，基于 OLAP 引擎的建设方式是数据量不太大，业务流量不太高情况下为了提高时效性和开发效率的一个折中方案，从未来的发展趋势来看，基于流计算的实时数仓更具有发展前景。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035712.png" alt=""></p><h3 id="一站式解决方案"><a href="#一站式解决方案" class="headerlink" title="一站式解决方案"></a>一站式解决方案</h3><p>从业务实践过程中，我们看到了业务建设实时数仓的共同需求，包括发现不同业务的元数据是割裂的，业务开发也倾向于使用 SQL 方式同时开发离线数仓和实时数仓，需要更多的运维工具支持。因此我们规划了一站式解决方案，希望能够将整个流程贯通。</p><p>这里的一站式解决方案主要为用户提供了数据开发工作平台、元数据管理。同时我们考虑到业务从生产到应用过程中的问题，我们 OLAP 生产平台，从建模方式、生产任务管理和资源方面解决 OLAP 生产问题。左侧是我们已经具备数据安全体系、资源体系和数据治理，这些是离线数仓和实时数仓可以共用的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-035747.png" alt=""></p><h3 id="为何选择-Flink？"><a href="#为何选择-Flink？" class="headerlink" title="为何选择 Flink？"></a>为何选择 Flink？</h3><p>实时数仓平台建设之所以选择 Flink 是基于以下四个方面的考虑，这也是实时数仓方面关注的比较核心的问题。</p><ul><li><p>第一个是状态管理，实时数仓里面会进行很多的聚合计算，这些都需要对于状态进行访问和管理，Flink 在这方面比较成熟。</p></li><li><p>第二个是表义能力，Flink 提供极为丰富的多层次 API，包括 Stream API、Table API 以及 Flink SQL。</p></li><li><p>第三个是生态完善，实时数仓的用途广泛，用户对于多种存储有访问需求，Flink 对于这方面的支持也比较完善。</p></li></ul><p>最后一点就是 Flink 提供了流批统一的可能性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040023.png" alt=""></p><h3 id="实时数仓平台"><a href="#实时数仓平台" class="headerlink" title="实时数仓平台"></a>实时数仓平台</h3><ul><li>建设思路</li></ul><p>实时数仓平台的建设思路从外到内分为了四个层次，我们认为平台应该做的事情是为用户提供抽象的表达能力，分别是消息表达、数据表达、计算表达以及流和批统一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040153.png" alt=""></p><ul><li>实时数仓平台架构</li></ul><p>如下图所示的是美团点评的实时数仓平台架构，从下往上看，资源层和存储层复用了实时计算平台的能力，在引擎层则会基于 Flink Streaming 实现一些扩展能力，包括对 UDF 的集成和 Connector 的集成。再往上是基于 Flink SQL 独立出来的 SQL 层，主要负责解析、校验和优化。在这之上是平台层，包括开发工作台、元数据、UDF 平台以及 OLAP 平台。最上层则是平台所支持的实时数仓的应用，包括实时报表、实时 OLAP、实时 Dashboard 和实时特征等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040229.png" alt=""></p><ul><li>消息表达-数据接入</li></ul><p>在消息表达层面，因为 Binlog、埋点日志、后端日志以及 IoT 数据等的数据格式是不一致的，因此美团点评的实时数仓平台提供数据接入的流程，能够帮助大家把数据同步到 ODS 层。这里主要实现了两件事情，分别是统一消息协议和屏蔽处理细节。</p><p>如下图左侧是接入过程的一个例子，对于 Binlog 类型数据，实时数仓平台还为大家提供了分库分表的支持，能够将属于同一个业务的不同的分库分表数据根据业务规则收集到同一个 ODS 表中去。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040310.png" alt=""></p><ul><li>计算表达-扩展 DDL</li></ul><p>美团点评实时数仓平台基于 Flink 扩展了 DDL，这部分工作的主要目的是建设元数据体系，打通内部的主流实时存储，包括 KV 数据、OLAP 数据等。由于开发工作台和元数据体系是打通的，因此很多数据的细节并不需要大家在 DDL 中明确地声明出来，只需要在声明中写上数据的名字，和运行时的一些设置，比如 MQ 从最新消费还是最旧消费或者从某个时间戳消费即可，其他的数据访问方式是一致的。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040607.png" alt=""></p><ul><li>计算表达-UDF 平台</li></ul><p>对于 UDF 平台而言，需要从三个层面考虑：</p><p>首先是数据安全性。之前的数仓建设过程中，用户可以上传 Jar 包去直接引用 UDF，这样做是有危险性存在的，并且我们无法知道数据的流向。从数据安全的角度来考虑，平台会进行代码审计和血缘关系分析，对于历史风险组件或者存在问题的组件可以进行组件收敛。</p><p>第二个层面，在数据安全基础上我们还会关注 UDF 的运行质量，平台将会为用户提供模板、用例以及测试的管理，为用户屏蔽编译打包、Jar 包管理的过程，并且会在 UDF 模板中进行指标日志的埋点和异常处理。</p><p>第三个层面是 UDF 的复用能力，因为一个业务方开发的 UDF，其他业务方很可能也会使用，但是升级过程中可能会带来不兼容的问题，因此，平台为业务提供了项目管理、函数管理和版本管理的能力。</p><p>UDF 的应用其实非常广泛，UDF 平台并不是只支持实时数仓，也会同时支持离线数仓、机器学习以及查询服务等应用场景。下图中右侧展示的是 UDF 的使用案例，左图是 UDF 的开发流程，用户只需要关心注册流程，接下来的编译打包、测试以及上传等都由平台完成；右图是 UDF 的使用流程中，用户只需要声明 UDF，平台会进行解析校验、路径获取以及在作业提交的时候进行集成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-040705.png" alt=""></p><ul><li>实时数仓平台-Web IDE</li></ul><p>最后介绍一下实时数仓平台的开发工作台，以 Web IDE 的形式集成了模型、作业以及 UDF 的管理，用户可以在 Web IDE 上以 SQL 方式开发。平台会对 SQL 做一些版本的管理，并且支持用户回退到已部署成功的版本上去。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041116.png" alt=""></p><h2 id="三、未来发展与思考"><a href="#三、未来发展与思考" class="headerlink" title="三、未来发展与思考"></a>三、未来发展与思考</h2><h3 id="资源自动调优"><a href="#资源自动调优" class="headerlink" title="资源自动调优"></a>资源自动调优</h3><p>从整个实时计算角度来考虑，目前美团点评的实时计算平台的节点数已经达到了几千台，未来很可能会达到上万台，因此资源优化这件事情很快就会被提上日程。由于业务本身的流量存在高峰和低谷，对于一个实时任务来说，可能在高峰时需要很多资源，但是在低谷时并不需要那么多资源。</p><p>另外一方面，波峰本身也是会发生变化的，有可能随着业务的上涨使得原来分配的资源数量不够用。因此，资源自动调优有两个含义，一个是指能够适配作业的高峰流量上涨，自动适配 Max 值；另外一个含义是指使得作业能够在高峰过去之后自动适应流量减少，能够快速缩容。我们可以通过每个任务甚至是算子的历史运行情况，拟合得到算子、流量与资源的关系函数，在流量变化时同步调整资源量。</p><p>以上是资源优化的思路，除此之外还需要考虑当资源完成优化之后应该如何利用。为了保证可用性，实时和离线任务一般会分开部署，否则带宽、IO 都可能被离线计算打满导致实时任务延迟。而从资源使用率角度出发，则需要考虑实时和离线的混合部署，或者以流的方式来处理一些实时性要求并不是非常高的任务。这就要求更细粒度的资源隔离和更快的资源释放。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041159.png" alt=""></p><h3 id="推动实时数仓建设方式升级"><a href="#推动实时数仓建设方式升级" class="headerlink" title="推动实时数仓建设方式升级"></a>推动实时数仓建设方式升级</h3><p>实时数仓的建设一般分为几个步骤：</p><ul><li><p>首先，业务提出需求，后续会进行设计建模、业务逻辑开发和底层技术实现。美团点评的实时数仓建设思路是将技术实现统一表达，让业务关注逻辑开发，而逻辑开发也可以基于配置化手段实现自动构建。</p></li><li><p>再上一层是可以根据业务需求实现智能建模，将设计建模过程实现自动化。</p></li></ul><p>目前，美团点评的实时数仓平台建设工作还集中在统一表达的层次，距离理想状态仍然有比较长的一段路要走。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-04-041237.png" alt=""></p><p>Flink Forward Asia 2019 PPT 下载链接给你们准备好啦！公众号(zhisheng)里面回复 ffa 即可下载，也可以扫描下面的二维码关注，回复 ffa 即可下载。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-150817.jpg" alt="微信公众号"></p><h2 id="更多-Flink-博客"><a href="#更多-Flink-博客" class="headerlink" title="更多 Flink 博客"></a>更多 Flink 博客</h2><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。</p><p>本文的项目代码在 <a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据仓库的建设是“数据智能”必不可少的一环，也是大规模数据应用中必然面临的挑战，而 Flink 实时数仓在数据链路中扮演着极为重要的角色。本文中，美团点评高级技术专家鲁昊为大家分享了美团点评基于 Apache Flink 的实时数仓平台实践。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的监控告警系统</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/23/flink-monitor-alert/</id>
    <published>2019-12-22T16:00:00.000Z</published>
    <updated>2020-03-01T14:43:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>本人在 Flink 社区钉钉群直播的视频</p><a id="more"></a><h3 id="监控告警"><a href="#监控告警" class="headerlink" title="监控告警"></a>监控告警</h3><iframe height=720 width=1150 src="//player.bilibili.com/player.html?aid=90890878&cid=155203148&page=1"> </iframe><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="hhttp://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>扫码下面专栏二维码可以订阅该专栏</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-11-05-044731.jpg" alt=""></p><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本人在 Flink 社区钉钉群直播的视频&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
      <category term="监控告警" scheme="http://www.54tianzhisheng.cn/tags/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>基于 Apache Flink 的大规模准实时数据分析平台</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/10/flink-real-time-data-analysis-platform/</id>
    <published>2019-12-09T16:00:00.000Z</published>
    <updated>2020-01-04T03:42:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文来自 Flink Forward Asia 2019 Lyft 公司的分享，作者是徐赢和高立，感谢！</p><a id="more"></a><p>授权转载自社区公众号：<a href="https://mp.weixin.qq.com/s?__biz=MzU3Mzg4OTMyNQ==&amp;mid=2247485404&amp;idx=1&amp;sn=fc958616d6e3f3f3001f3e02bb784278&amp;chksm=fd3b899eca4c0088622f41d9a4a3183fbcb8b2f10cad82e34e64ddb1a0b453cad73f37bdd9a1&amp;scene=38#wechat_redirect">原文地址</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005544.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005601.png" alt=""></p><h2 id="一、Lyft-的流数据与场景"><a href="#一、Lyft-的流数据与场景" class="headerlink" title="一、Lyft 的流数据与场景"></a>一、Lyft 的流数据与场景</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005641.png" alt=""></p><h3 id="关于-Lyft"><a href="#关于-Lyft" class="headerlink" title="关于 Lyft"></a>关于 Lyft</h3><p>Lyft 是位于北美的一个共享交通平台，和大家所熟知的 Uber 和国内的滴滴类似，Lyft 也为民众提供共享出行的服务。Lyft 的宗旨是提供世界最好的交通方案来改善人们的生活。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005718.png" alt=""></p><h3 id="Lyft-的流数据场景"><a href="#Lyft-的流数据场景" class="headerlink" title="Lyft 的流数据场景"></a>Lyft 的流数据场景</h3><p>Lyft 的流数据可以大致分为三类，秒级别、分钟级别和不高于 5 分钟级别。分钟级别流数据中，自适应定价系统、欺诈和异常检测系统是最常用的，此外还有 Lyft 最新研发的机器学习特征工程。不高于 5 分钟级别的场景则包括准实时数据交互查询相关的系统。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005743.png" alt=""></p><h3 id="Lyft-数据分析平台架构"><a href="#Lyft-数据分析平台架构" class="headerlink" title="Lyft 数据分析平台架构"></a>Lyft 数据分析平台架构</h3><p>如下图所示的是 Lyft 之前的数据分析平台架构。Lyft 的大部分流数据都是来自于事件，而事件产生的来源主要有两种，分别是手机 APP 和后端服务，比如乘客、司机、支付以及保险等服务都会产生各种各样的事件，而这些事件都需要实时响应。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005814.png" alt=""></p><p>在分析平台这部分，事件会流向 AWS 的 Kinesis 上面，这里的 Kinesis 与 Apache Kafka 非常类似，是一种 AWS 上专有的 PubSub 服务，而这些数据流都会量化成文件，这些文件则都会存储在 AWS 的 S3 上面，并且很多批处理任务都会弹出一些数据子集。在分析系统方面，Lyft 使用的是开源社区中比较活跃的 presto 查询引擎。Lyft 数据分析平台的用户主要有四种，即数据工程师、数据分析师以及机器学习专家和深度学习专家，他们往往都是通过分析引擎实现与数据的交互。</p><h3 id="既往平台的问题"><a href="#既往平台的问题" class="headerlink" title="既往平台的问题"></a>既往平台的问题</h3><p>Lyft 之所以要基于 Apache Flink 实现大规模准实时数据分析平台，是因为以往的平台存在一些问题。比如较高的延迟，导入数据无法满足准实时查询的要求；并且基于 Kinesis Client Library 的流式数据导入性能不足；导入数据存在太多小文件导致下游操作性能不足；数据 ETL 大多是高延迟多日多步的架构；此外，以往的平台对于嵌套数据提供的支持也不足。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005837.png" alt=""></p><h2 id="二、准实时数据分析平台和架构"><a href="#二、准实时数据分析平台和架构" class="headerlink" title="二、准实时数据分析平台和架构"></a>二、准实时数据分析平台和架构</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005858.png" alt=""></p><h3 id="准实时平台架构"><a href="#准实时平台架构" class="headerlink" title="准实时平台架构"></a>准实时平台架构</h3><p>在新的准实时平台架构中，Lyft 采用 Flink 实现流数据持久化。Lyft 使用云端存储，而使用 Flink 直接向云端写一种叫做 Parquet 的数据格式，Parquet 是一种列数据存储格式，能够有效地支持交互式数据查询。Lyft 在 Parquet 原始数据上架构实时数仓，实时数仓的结构被存储在 Hive 的 Table 里面，Hive Table 的 metadata 存储在 Hive metastore 里面。</p><p>平台会对于原始数据做多级的非阻塞 ETL 加工，每一级都是非阻塞的(nonblocking)，主要是压缩和去重的操作，从而得到更高质量的数据。平台主要使用 Apache Airflow 对于 ETL 操作进行调度。所有的 Parquet 格式的原始数据都可以被 presto 查询，交互式查询的结果将能够以 BI 模型的方式显示给用户。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005915.png" alt=""></p><h3 id="平台设计"><a href="#平台设计" class="headerlink" title="平台设计"></a>平台设计</h3><p>Lyft 基于 Apache Flink 实现的大规模准实时数据分析平台具有几个特点：</p><ul><li><p>首先，平台借助 Flink 实现高速有效的流数据接入，使得云上集群规模缩减为原来的十分之一，因此大大降低了运维成本。</p></li><li><p>其次，Parquet 格式的数据支持交互式查询，当用户仅对于某几个列数据感兴趣时可以通过分区和选择列的方式过滤不必要的数据，从而提升查询的性能。</p></li><li><p>再次，基于 AWS 的云端存储，平台的数据无需特殊存储形式。</p></li><li><p>之后，多级 ETL 进程能够确保更好的性能和数据质量。</p></li><li><p>最后，还能够兼顾性能容错及可演进性。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005935.png" alt=""></p><h3 id="平台特征及应用"><a href="#平台特征及应用" class="headerlink" title="平台特征及应用"></a>平台特征及应用</h3><p>Lyft 准实时数据分析平台需要每天处理千亿级事件，能够做到数据延迟小于 5 分钟，而链路中使用的组件确保了数据完整性，同时基于 ETL 去冗余操作实现了数据单一性保证。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-005952.png" alt=""></p><p>数据科学家和数据工程师在建模时会需要进行自发的交互式查询，此外，平台也会提供实时机器学习模型正确性预警，以及实时数据面板来监控供需市场健康状况。</p><h3 id="基于-Flink-的准实时数据导入"><a href="#基于-Flink-的准实时数据导入" class="headerlink" title="基于 Flink 的准实时数据导入"></a>基于 Flink 的准实时数据导入</h3><p>下图可以看到当事件到达 Kinesis 之后就会被存储成为 EventBatch。通过 Flink-Kinesis 连接器可以将事件提取出来并送到 FlatMap 和 Record Counter 上面，FlatMap 将事件打撒并送到下游的 Global Record Aggregator 和 Tagging Partitioning 上面，每当做 CheckPoint 时会关闭文件并做一个持久化操作，针对于 StreamingFileSink 的特征，平台设置了每三分钟做一次 CheckPoint 操作，这样可以保证当事件进入 Kinesis 连接器之后在三分钟之内就能够持久化。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010016.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010035.png" alt=""></p><p>以上的方式会造成太多数量的小文件问题，因为数据链路支持成千上万种文件，因此使用了 Subtasks 记录本地事件权重，并通过全局记录聚合器来计算事件全局权重并广播到下游去。而 Operator 接收到事件权重之后将会将事件分配给 Sink。</p><h3 id="ETL-多级压缩和去重"><a href="#ETL-多级压缩和去重" class="headerlink" title="ETL 多级压缩和去重"></a>ETL 多级压缩和去重</h3><p>上述的数据链路也会做 ETL 多级压缩和去重工作，主要是 Parquet 原始数据会经过每小时的智能压缩去重的 ETL 工作，产生更大的 Parquet File。同理，对于小时级别压缩去重不够的文件，每天还会再进行一次压缩去重。对于新产生的数据会有一个原子性的分区交换，也就是说当产生新的数据之后，ETL Job 会让 Hive metastore 里的表分区指向新的数据和分区。这里的过程使用了启发性算法来分析哪些事件必须要经过压缩和去重以及压缩去重的时间间隔级别。此外，为了满足隐私和合规的要求，一些 ETL 数据会被保存数以年计的时间。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010112.png" alt=""></p><h2 id="三、平台性能及容错深入分析"><a href="#三、平台性能及容错深入分析" class="headerlink" title="三、平台性能及容错深入分析"></a>三、平台性能及容错深入分析</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010130.png" alt=""></p><h3 id="事件时间驱动的分区感测"><a href="#事件时间驱动的分区感测" class="headerlink" title="事件时间驱动的分区感测"></a>事件时间驱动的分区感测</h3><p>Flink 和 ETL 是通过事件时间驱动的分区感测实现同步的。S3 采用的是比较常见的分区格式，最后的分区是由时间戳决定的，时间戳则是基于 EventTime 的，这样的好处在于能够带来 Flink 和 ETL 共同的时间源，这样有助于同步操作。此外，基于事件时间能够使得一些回填操作和主操作实现类似的结果。Flink 处理完每个小时的事件后会向事件分区写入一个 Success 文件，这代表该小时的事件已经处理完毕，ETL 可以对于该小时的文件进行操作了。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010149.png" alt=""></p><p>Flink 本身的水印并不能直接用到 Lyft 的应用场景当中，主要是因为当 Flink 处理完时间戳并不意味着它已经被持久化到存储当中，此时就需要引入分区水印的概念，这样一来每个 Sink Source 就能够知道当前写入的分区，并且维护一个分区 ID，并且通过 Global State Aggregator 聚合每个分区的信息。每个 Subtasks 能够知道全局的信息，并将水印定义为分区时间戳中最小的一个。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010206.png" alt=""></p><p>ETL 主要有两个特点，分别是及时性和去重，而 ETL 的主要功能在于去重和压缩，最重要的是在非阻塞的情况下就进行去重。前面也提到 Smart ETL，所谓 Smart 就是智能感知，需要两个相应的信息来引导 Global State Aggregator，分别是分区完整性标识 SuccessFile，在每个分区还有几个相应的 States 统计信息能够告诉下游的 ETL 怎样去重和压缩以及操作的频率和范围。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010228.png" alt=""></p><h3 id="Schema-演进的挑战"><a href="#Schema-演进的挑战" class="headerlink" title="Schema 演进的挑战"></a>Schema 演进的挑战</h3><p>ETL 除了去重和压缩的挑战之外，还经常会遇到 Schema 的演化挑战。Schema 演化的挑战分为三个方面，即不同引擎的数据类型、嵌套结构的演变、数据类型演变对去重逻辑的影响。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010249.png" alt=""></p><h3 id="S3-深入分析"><a href="#S3-深入分析" class="headerlink" title="S3 深入分析"></a>S3 深入分析</h3><p>Lyft 的数据存储系统其实可以认为是数据湖，对于 S3 而言，Lyft 也有一些性能的优化考量。S3 本身内部也是有分区的，为了使其具有并行的读写性能，添加了 S3 的熵数前缀，在分区里面也增加了标记文件，这两种做法能够极大地降低 S3 的 IO 性能的影响。标识符对于能否触发 ETL 操作会产生影响，与此同时也是对于 presto 的集成，能够让 presto 决定什么情况下能够扫描多少个文件。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010306.png" alt=""></p><h3 id="Parquet-优化方案"><a href="#Parquet-优化方案" class="headerlink" title="Parquet 优化方案"></a>Parquet 优化方案</h3><p>Lyft 的准实时数据分析平台在 Parquet 方面做了很多优化，比如文件数据值大小范围统计信息、文件系统统计信息、基于主键数据值的排序加快 presto 的查询速度以及二级索引的生成。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010324.png" alt=""></p><h3 id="基于数据回填的平台容错机制"><a href="#基于数据回填的平台容错机制" class="headerlink" title="基于数据回填的平台容错机制"></a>基于数据回填的平台容错机制</h3><p>如下两个图所示的是 Lyft 准实时数据分析平台的基于数据回填的平台容错机制。对于 Flink 而言，因为平台的要求是达到准实时，而 Flink 的 Job 出现失效的时候可能会超过一定的时间，当 Job 重新开始之后就会形成两个数据流，主数据流总是从最新的数据开始往下执行，附加数据流则可以回溯到之前中断的位置进行执行直到中断结束的位置。这样的好处是既能保证主数据流的准实时特性，同时通过回填数据流保证数据的完整性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010340.png" alt=""></p><p>对于 ETL 而言，基于数据回填的平台容错机制则表现在 Airflow 的幂等调度系统、原子压缩和 HMS 交换操作、分区自建自修复体系和 Schema 整合。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010404.png" alt=""></p><h2 id="四、总结与未来展望"><a href="#四、总结与未来展望" class="headerlink" title="四、总结与未来展望"></a>四、总结与未来展望</h2><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010423.png" alt=""></p><h3 id="体验与经验教训"><a href="#体验与经验教训" class="headerlink" title="体验与经验教训"></a>体验与经验教训</h3><p>利用 Flink 能够准实时注入 Parquet 数据，使得交互式查询体验为可能。同时，Flink 在 Lyft 中的应用很多地方也需要提高，虽然 Flink 在大多数情况的延时都能够得到保证，但是重启和部署的时候仍然可能造成分钟级别的延时，这会对于 SLO 产生一定影响。</p><p>此外，Lyft 目前做的一件事情就是改善部署系统使其能够支持 Kubernetes，并且使得其能够接近 0 宕机时间的效果。因为 Lyft 准实时数据分析平台在云端运行，因此在将数据上传到 S3 的时候会产生一些随机的网络情况，造成 Sink Subtasks 的停滞，进而造成整个 Flink Job 的停滞。而通过引入一些 Time Out 机制来检测 Sink Subtasks 的停滞，使得整个 Flink Job 能够顺利运行下去。</p><p>ETL 分区感应能够降低成本和延迟，成功文件则能够表示什么时候处理完成。此外，S3 文件布局对性能提升的影响还是非常大的，目前而言引入熵数还属于经验总结，后续 Lyft 也会对于这些进行总结分析并且公开。因为使用 Parquet 数据，因此对于 Schema 的兼容性要求就非常高，如果引入了不兼容事件则会使得下游的 ETL 瘫痪，因此 Lyft 已经做到的就是在数据链路上游对于 Schema 的兼容性进行检查，检测并拒绝用户提交不兼容的 Schema。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010455.png" alt=""></p><h3 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h3><p>Lyft 对于准实时数据分析平台也有一些设想。</p><ul><li><p>首先，Lyft 希望将 Flink 部署在 Kubernetes 集群环境下运行，使得 Kubernetes 能够管理这些 Flink Job，同时也能够充分利用 Kubernetes 集群的高可扩展性。</p></li><li><p>其次，Lyft 也希望实现通用的流数据导入框架，准实时数据分析平台不仅仅支持事件，也能够支持数据库以及服务日志等数据。</p></li><li><p>再次，Lyft 希望平台能够实现 ETL 智能压缩以及事件驱动 ETL，使得回填等事件能够自动触发相应的 ETL 过程，实现和以前的数据的合并，同时将延时数据导入来对于 ETL 过程进行更新。</p></li><li><p>最后，Lyft 还希望准实时数据分析平台能够实现存储过程的改进以及查询优化，借助 Parquet 的统计数据来改善 presto 的查询性能，借助表格管理相关的开源软件对存储管理进行性能改善，同时实现更多的功能。</p></li></ul><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010514.png" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-010533.png" alt=""></p><p>Flink Forward Asia 2019 PPT 下载链接给你们准备好啦！公众号(zhisheng)里面回复 ffa 即可下载，也可以扫描下面的二维码关注，回复 ffa 即可下载。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-10-150817.jpg" alt="微信公众号"></p><h2 id="更多-Flink-博客"><a href="#更多-Flink-博客" class="headerlink" title="更多 Flink 博客"></a>更多 Flink 博客</h2><h3 id="Github-代码仓库"><a href="#Github-代码仓库" class="headerlink" title="Github 代码仓库"></a>Github 代码仓库</h3><p><a href="https://github.com/zhisheng17/flink-learning/">https://github.com/zhisheng17/flink-learning/</a></p><p>以后这个项目的所有代码都将放在这个仓库里，包含了自己学习 flink 的一些 demo 和博客。</p><p>本文的项目代码在 <a href="https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq">https://github.com/zhisheng17/flink-learning/tree/master/flink-learning-connectors/flink-learning-connectors-rabbitmq</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、实战、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文来自 Flink Forward Asia 2019 Lyft 公司的分享，作者是徐赢和高立，感谢！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>Flink Forward Asia 2019 PPT 下载</title>
    <link href="http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/"/>
    <id>http://www.54tianzhisheng.cn/2019/12/07/Flink_Forward_Asia_2019/</id>
    <published>2019-12-06T16:00:00.000Z</published>
    <updated>2019-12-08T02:43:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>Flink Forward Asia 2019 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面的 PPT。</p><a id="more"></a><h3 id="主会场"><a href="#主会场" class="headerlink" title="主会场"></a>主会场</h3><p>1、《Stateful Functions: Building general-purpose Applications and Services on Apache Flink》</p><p>2、《Apache Flink Heading Towards A Unified Engine》</p><p>3、《Storage Reimagined for a Streaming World》 </p><p>4、《Lyft 基于 Apache Flink 的大规模准实时数据分析平台》</p><h3 id="企业实践"><a href="#企业实践" class="headerlink" title="企业实践"></a>企业实践</h3><p>1、《Apache Flink 在字节跳动的实践与优化》</p><p>2、《Apache Flink在快手实时多维分析场景的应用》</p><p>3、《bilibili 实时平台的架构与实践》</p><p>4、《Apache Flink 资源动态调整及其实践》</p><p>5、《Apache Flink在滴滴的应用与实践》</p><p>6、《Apache Flink 在网易的实践》</p><p>7、《Apache Flink 在中国农业银行的探索和实践》</p><p>8、《基于 Apache Flink 的爱奇艺实时计算平台建设实践》</p><p>9、《实时计算在贝壳的实践》</p><p>10、《基于 Apache Flink 构建 CEP（Complex Event Process）引擎的挑战和实践》</p><h3 id="Apache-Flink-核心技术"><a href="#Apache-Flink-核心技术" class="headerlink" title="Apache Flink 核心技术"></a>Apache Flink 核心技术</h3><p>1、《Pluggable Shuffle Service and Unaligned Checkpoint》</p><p>2、《漂移计算 – 跨 DC 跨数据源的高性能 SQL 引擎》</p><p>3、《New Source API – Make it Easy! 》</p><p>4、《Stateful Functions: Unlocking the next wave of applications with Stream Processing》</p><p>5、《Apache Flink新场景——OLAP引擎》</p><p>6、《New Feature and Improvements on State Backends in Flink 1.10》</p><p>7、《阿里巴巴在 Apache Flink 大规模持久化存储的实践之道》</p><p>8、《Using Apache Flink as a Unified Data Processing Platform》</p><p>9、《深入探索 Apache Flink SQL 流批统一的查询引擎与最佳实践》   </p><p>10、《Apache Flink 流批一体的资源管理与任务调度》</p><h3 id="开源大数据生态"><a href="#开源大数据生态" class="headerlink" title="开源大数据生态"></a>开源大数据生态</h3><p>1、《YuniKorn 对 Apache Flink on K8s 的调度优化》</p><p>2、《流处理基准测试》</p><p>3、《Apache Flink and the Apache Way》</p><p>4、《Delivering stream data reliably with Pravega》</p><p>5、《Deep dive into Pyflink &amp; integration with Zeppelin》</p><p>6、《Apache Flink 与 Apache Hive 的集成》</p><p>7、《趣头条基于 Apache Flink+ClickHouse 构建实时数据分析平台》</p><p>8、《基于 Apache Flink 的边缘流式计算》</p><p>9、《基于 Apache Pulsar 和 Apache Flink 进行批流一体的弹性数据处理》</p><p>10、《The integretion of Apache Flink SQL and Apache Calcite》</p><h3 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h3><p>1、《美团点评基于 Apache Flink 的实时数仓平台实践》</p><p>2、《小米流式平台架构演进与实践》</p><p>3、《Netflix：Evolving Keystone to an Open Collaborative Real-time ETL Platform》</p><p>4、《菜鸟供应链实时数据技术架构的演进》</p><p>5、《OPPO 基于 Apache Flink 的实时数仓实践》</p><h3 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h3><p>1、《Deep Learning On Apache Flink》</p><p>2、《在 Apache Flink 上使用 Analytics-Zoo 进行大数据分析与深度学习模型推理的架构与实践》</p><p>3、《携程实时智能检测平台实践》</p><p>4、《基于Apache Flink的机器学习算法平台实践与开源》</p><p>5、《Apache Flink AI生态系统工作》</p><h3 id="如何获取上面这些-PPT？"><a href="#如何获取上面这些-PPT？" class="headerlink" title="如何获取上面这些 PPT？"></a>如何获取上面这些 PPT？</h3><p>上面的这些 PPT 本人已经整理好了，你可以关注微信公众号：<strong>zhisheng</strong>，然后在里面回复关键字: ffa 即可获取已放出的 PPT。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-12-08-024104.jpg" alt=""></p><p>另外你也可以加我微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt="">  </p><h2 id="更多-Flink-的文章"><a href="#更多-Flink-的文章" class="headerlink" title="更多 Flink 的文章"></a>更多 Flink 的文章</h2><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Flink Forward Asia 2019 在北京召开的，有主会场和几个分会场（企业实践、Apache Flink 核心技术、开源大数据生态、实时数仓、人工智能），内容涉及很多，可以查看下面的 PPT。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>阿里巴巴 Flink 踩坑经验：如何大幅降低 HDFS 压力？</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/30/flink-checkpoint-hdfs/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-01-11T05:55:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>众所周知，Flink 是当前最为广泛使用的计算引擎之一，它使用 Checkpoint 机制进行容错处理 [1]，Checkpoint 会将状态快照备份到分布式存储系统，供后续恢复使用。在 Alibaba 内部，我们使用的存储主要是 HDFS，当同一个集群的 Job 到达一定数量后，会对 HDFS 造成非常大的压力，本文将介绍一种大幅度降低 HDFS 压力的方法——小文件合并。</p><a id="more"></a><p>本文转自：<a href="">https://www.infoq.cn/article/OLlJNzQpTOHfyrgOG8xq</a></p><p>作者：邱从贤</p><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>不管使用 FsStateBackend、RocksDBStateBackend 还是 NiagaraStateBackend，Flink 在进行 Checkpoint 的时候，TM 会将状态快照写到分布式文件系统中，然后将文件句柄发给 JM，JM 完成全局 checkpoint 快照的存储，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144832.jpg" alt=""></p><p>对于全量 Checkpoint 来说，TM 将每个 Checkpoint 内部的数据都写到同一个文件，而对于 RocksDBStateBackend/NiagaraStateBackend 的增量 Checkpoint [2] 来说，则会将每个 sst 文件写到一个分布式系统的文件内。当作业量很大，且作业的并发很大时，则会对底层 HDFS 形成非常大的压力：1）大量的 RPC 请求会影响 RPC 的响应时间（如下图所示）；2）大量文件对 NameNode 内存造成很大压力。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144921.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-144902.jpg" alt=""></p><p>在 Flink 中曾经尝试使用 ByteStreamStateHandle 来解决小文件多的问题 [3]，将小于一定阈值的 state 直接发送到 JM，由 JM 统一写到分布式文件中，从而避免在 TM 端生成小文件。但是这个方案有一定的局限性，阈值设置太小，还会有很多小文件生成，阈值设置太大，则会导致 JM 内存消耗太多有 OOM 的风险。</p><h3 id="1-小文件合并方案"><a href="#1-小文件合并方案" class="headerlink" title="1 小文件合并方案"></a>1 小文件合并方案</h3><p>针对上面的问题我们提出一种解决方案——小文件合并。</p><p>在原来的实现中，每个 sst 文件会打开一个 CheckpointOutputStream，每个 CheckpointOutputStream 对应一个 FSDataOutputStream，将本地文件写往一个分布式文件，然后关闭 FSDataOutputStream，生成一个 StateHandle。如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145048.jpg" alt=""></p><p>小文件合并则会重用打开的 FSDataOutputStream，直至文件大小达到预设的阈值为止，换句话说多个 sst 文件会重用同一个 DFS 上的文件，每个 sst 文件占用 DFS 文件中的一部分，最终多个 StateHandle 共用一个物理文件，如下图所示。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145114.jpg" alt=""></p><p>在接下来的章节中我们会描述实现的细节，其中需要重点考虑的地方包括：</p><ul><li>并发 Checkpoint 的支持</li></ul><p>Flink 天生支持并发 Checkpoint，小文件合并方案则会将多个文件写往同一个分布式存储文件中，如果考虑不当，数据会写串或者损坏，因此我们需要有一种机制保证该方案的正确性，详细描述参考 2.1 节。</p><ul><li>防止误删文件</li></ul><p>我们使用引用计数来记录文件的使用情况，仅通过文件引用计数是否降为 0 进行判断删除，则可能误删文件，如何保证文件不会被错误删除，我们将会在 2.2 节进行阐述。</p><ul><li>降低空间放大</li></ul><p>使用小文件合并之后，只要文件中还有一个 statehandle 被使用，整个分布式文件就不能被删除，因此会占用更多的空间，我们在 2.3 节描述了解决该问题的详细方案。</p><ul><li>异常处理</li></ul><p>我们将在 2.4 节阐述如何处理异常情况，包括 JM 异常和 TM 异常的情况。</p><p>2.5 节中会详细描述在 Checkpoint 被取消或者失败后，如何取消 TM 端的 Snapshot，如果不取消 TM 端的 Snapshot，则会导致 TM 端实际运行的 Snapshot 比正常的多。</p><p>在第 3 节中阐述了小文件合并方案与现有方案的兼容性；第 4 节则会描述小文件合并方案的优势和不足；最后在第 5 节我们展示在生产环境下取得的效果。</p><h3 id="2-设计实现"><a href="#2-设计实现" class="headerlink" title="2 设计实现"></a>2 设计实现</h3><p>本节中我们会详细描述整个小文件合并的细节，以及其中的设计要点。</p><p>这里我们大致回忆一下 TM 端 Snapshot 的过程：</p><ul><li>TM 端 barrier 对齐</li><li>TM Snapshot 同步操作</li><li>TM Snapshot 异步操作</li></ul><p>其中上传 sst 文件到分布式存储系统在上面的第三步，同一个 Checkpoint 内的文件顺序上传，多个 Checkpoint 的文件上传可能同时进行。</p><h4 id="2-1-并发-Checkpoint-支持"><a href="#2-1-并发-Checkpoint-支持" class="headerlink" title="2.1 并发 Checkpoint 支持"></a>2.1 并发 Checkpoint 支持</h4><p>Flink 天生支持并发 Checkpoint，因此小文件合并方案也需要能够支持并发 Checkpoint，如果不同 Checkpoint 的 sst 文件同时写往一个分布式文件，则会导致文件内容损坏，后续无法从该文件进行 restore。</p><p>在 FLINK-11937[4] 的提案中，我们会将每个 Checkpoint 的 state 文件写到同一个 HDFS 文件，不同 Checkpoint 的 state 写到不同的 HDFS 文件 – 换句话说，HDFS 文件不跨 Checkpoint 共用，从而避免了多个客户端同时写入同一个文件的情况。</p><p>后续我们会继续推进跨 Checkpoint 共用文件的方案，当然在跨 Checkpoint 共用文件的方案中，并行的 Checkpoint 也会写往不同的 HDFS 文件。</p><h4 id="2-2-防止误删文件"><a href="#2-2-防止误删文件" class="headerlink" title="2.2 防止误删文件"></a>2.2 防止误删文件</h4><p>复用底层文件之后，我们使用引用计数追踪文件的使用情况，在文件引用数降为 0 的情况下删除文件。但是在某些情况下，文件引用数为 0 的时候，并不代表文件不会被继续使用，可能导致文件误删。下面我们会详细描述开启并发 Checkpoint 后可能导致文件误删的情况，以及解决方案。</p><p>以下图为例，maxConcurrentlyCheckpoint = 2</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145326.jpg" alt=""></p><p>上图中共有 3 个 Checkpoint，其中 chk-1 已经完成，chk-2 和 chk-3 都基于 chk-1 进行，chk-2 在 chk-3 前完成，chk-3 在注册 4.sst 的时候发现，发现 4.sst 在 chk-2 中已经注册过，会重用 chk-2 中 4.sst 对应的 stateHandle，然后取消 chk-3 中的 4.sst 的注册，并且删除 stateHandle，在处理完 chk-3 中 4.sst 之后，该 stateHandle 对应的分布式文件的引用计数为 0，如果我们这个时候删除分布式文件，则会同时删除 5.sst 对应的内容，导致后续无法从 chk-3 恢复。</p><p>这里的问题是如何在 stateHandle 对应的分布式文件引用计数降为 0 的时候正确判断是否还会继续引用该文件，因此在整个 Checkpoint 完成处理之后再判断某个分布式文件能否删除，如果真个 Checkpoint 完成发现文件没有被引用，则可以安全删除，否则不进行删除。</p><h4 id="2-3-降低空间放大"><a href="#2-3-降低空间放大" class="headerlink" title="2.3 降低空间放大"></a>2.3 降低空间放大</h4><p>使用小文件合并方案后，每个 sst 文件对应分布式文件中的一个 segment，如下图所示：</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145406.jpg" alt=""></p><p>文件仅能在所有 segment 都不再使用时进行删除，上图中有 4 个 segment，仅 segment-4 被使用，但是整个文件都不能删除，其中 segment[1-3] 的空间被浪费掉了，从实际生产环境中的数据可知，整体的空间放大率（实际占用的空间 / 真实有用的空间）在 1.3 - 1.6 之间。</p><p>为了解决空间放大的问题，在 TM 端起异步线程对放大率超过阈值的文件进行压缩。而且仅对已经关闭的文件进行压缩。</p><p>整个压缩的流程如下所示：</p><ul><li>计算每个文件的放大率</li><li>如果放大率较小则直接跳到步骤 7</li><li>如果文件 A 的放大率超过阈值，则生成一个对应的新文件 A‘（如果这个过程中创建文件失败，则由 TM 负责清理工作）</li><li>记录 A 与 A’ 的映射关系</li><li>在下一次 Checkpoint X 往 JM 发送落在文件 A 中的 StateHandle 时，则使用 A` 中的信息生成一个新的 StateHandle 发送给 JM</li><li>Checkpoint X 完成后，我们增加 A‘ 的引用计数，减少 A 的引用计数，在引用计数降为 0 后将文件 A 删除（如果 JM 增加了 A’ 的引用，然后出现异常，则会从上次成功的 Checkpoint 重新构建整个引用计数器）</li><li>文件压缩完成</li></ul><h4 id="2-4-异常情况处理"><a href="#2-4-异常情况处理" class="headerlink" title="2.4 异常情况处理"></a>2.4 异常情况处理</h4><p>在 Checkpoint 的过程中，主要有两种异常：JM 异常和 TM 异常，我们将分情况阐述。</p><h5 id="2-4-1-JM-异常"><a href="#2-4-1-JM-异常" class="headerlink" title="2.4.1 JM 异常"></a>2.4.1 JM 异常</h5><p>JM 端主要记录 StateHandle 以及文件的引用计数，引用计数相关数据不需要持久化到外存中，因此不需要特殊的处理，也不需要考虑 transaction 等相关操作，如果 JM 发送 failover，则可以直接从最近一次 complete Checkpoint 恢复，并重建引用计数即可。</p><h5 id="2-4-2-TM-异常"><a href="#2-4-2-TM-异常" class="headerlink" title="2.4.2 TM 异常"></a>2.4.2 TM 异常</h5><p>TM 异常可以分为两种：1）该文件在之前 Checkpoint 中已经汇报过给 JM；2）文件尚未汇报过给 JM，我们会分情况阐述。</p><p><strong>文件已经汇报过给 JM</strong></p><p>文件汇报过给 JM，因此在 JM 端有文件的引用计数，文件的删除由 JM 控制，当文件的引用计数变为 0 之后，JM 将删除该文件。</p><p><strong>文件尚未汇报给 JM</strong></p><p>该文件暂时尚未汇报过给 JM，该文件不再被使用，也不会被 JM 感知，成为孤儿文件。这种情况暂时有外围工具统一进行清理。</p><h4 id="2-5-取消-TM-端-snapshot"><a href="#2-5-取消-TM-端-snapshot" class="headerlink" title="2.5 取消 TM 端 snapshot"></a>2.5 取消 TM 端 snapshot</h4><p>像前面章节所说，我们需要在 Checkpoint 超时 / 失败时，取消 TM 端的 snapshot，而 Flink 则没有相应的通知机制，现在 FLINK-8871[5] 在追踪相应的优化，我们在内部增加了相关实现，当 Checkpoint 失败时会发送 RPC 数据给 TM，TM 端接受到相应的 RPC 消息后，会取消相应的 snapshot。</p><h3 id="3-兼容性"><a href="#3-兼容性" class="headerlink" title="3 兼容性"></a>3 兼容性</h3><p>小文件合并功能支持从之前的版本无缝迁移过来。从之前的 Checkpoint restore 的的步骤如下：</p><ul><li>每个 TM 分到自己需要 restore 的 state handle</li><li>TM 从远程下载 state handle 对应的数据</li><li>从本地进行恢复</li></ul><p>小文件合并主要影响的是第 2 步，从远程下载对应数据的时候对不同的 StateHandle 进行适配，因此不影响整体的兼容性。</p><h3 id="4-优势和不足"><a href="#4-优势和不足" class="headerlink" title="4 优势和不足"></a>4 优势和不足</h3><ul><li>优势：大幅度降低 HDFS 的压力：包括 RPC 压力以及 NameNode 内存的压力</li><li>不足：不支持 State 多线程上传的功能（State 上传暂时不是 Checkpoint 的瓶颈）</li></ul><h3 id="5-线上环境的结果"><a href="#5-线上环境的结果" class="headerlink" title="5 线上环境的结果"></a>5 线上环境的结果</h3><p>在该方案上线后，对 Namenode 的压力大幅降低，下面的截图来自线上生产集群，从数据来看，文件创建和关闭的 RPC 有明显下降，RPC 的响应时间也有大幅度降低，确保顺利度过双十一。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145805.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145821.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145834.jpg" alt=""></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/2020-01-10-145848.jpg" alt=""></p><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><p>[1] <a href="https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/checkpoints.html">https://ci.apache.org/projects/flink/flink-docs-stable/ops/state/checkpoints.html</a></p><p>[2] <a href="https://flink.apache.org/features/2018/01/30/incremental-checkpointing.html">https://flink.apache.org/features/2018/01/30/incremental-checkpointing.html</a></p><p>[3] <a href="https://www.slideshare.net/dataArtisans/stephan-ewen-experiences-running-flink-at-very-large-scale">https://www.slideshare.net/dataArtisans/stephan-ewen-experiences-running-flink-at-very-large-scale</a></p><p>[4] <a href="https://issues.apache.org/jira/browse/FLINK-11937">https://issues.apache.org/jira/browse/FLINK-11937</a></p><p>[5] <a href="https://issues.apache.org/jira/browse/FLINK-8871">https://issues.apache.org/jira/browse/FLINK-8871</a></p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;众所周知，Flink 是当前最为广泛使用的计算引擎之一，它使用 Checkpoint 机制进行容错处理 [1]，Checkpoint 会将状态快照备份到分布式存储系统，供后续恢复使用。在 Alibaba 内部，我们使用的存储主要是 HDFS，当同一个集群的 Job 到达一定数量后，会对 HDFS 造成非常大的压力，本文将介绍一种大幅度降低 HDFS 压力的方法——小文件合并。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>58 同城基于 Flink 的千亿级实时计算平台架构实践</title>
    <link href="http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/"/>
    <id>http://www.54tianzhisheng.cn/2019/11/30/flink-in-58/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-01-11T06:10:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>58 同城作为覆盖生活全领域的服务平台，业务覆盖招聘、房产、汽车、金融、二手及本地服务等各个方面。丰富的业务线和庞大的用户数每天产生海量用户数据需要实时化的计算分析，实时计算平台定位于为集团海量数据提供高效、稳定、分布式实时计算的基础服务。本文主要介绍 58 同城基于 Flink 打造的一站式实时计算平台 Wstream。</p><a id="more"></a><p>本文转自：<a href="https://mp.weixin.qq.com/s?__biz=MzI4NTA1MDEwNg==&amp;mid=2650784251&amp;idx=1&amp;sn=3f90f0eadad3b781200ec8b31d281dfd&amp;chksm=f3f9746ec48efd78b0e10fa9a3e9fe646ef385c9450762ed634194760b03a528b561dbcab321&amp;scene=27#wechat_redirect">dbaplus 社群公众号</a></p><p>作者：冯海涛 / 万石康，负责 58 同城实时计算平台建设。</p><h3 id="实时计算场景"><a href="#实时计算场景" class="headerlink" title="实时计算场景"></a>实时计算场景</h3><p>和很多互联网公司一样，实时计算在 58 拥有丰富的场景需求，主要包括以下几类：</p><ul><li>实时数据 ETL：实时消费 Kafka 数据进行清洗、转换、结构化处理用于下游计算处理。</li><li>实时数仓：实时化数据计算，仓库模型加工和存储。实时分析业务及用户各类指标，让运营更加实时化。</li><li>实时监控：对系统和用户行为进行实时检测和分析，如业务指标实时监控，运维线上稳定性监控，金融风控等。</li><li>实时分析：特征平台，用户画像，实时个性化推荐等。</li></ul><h3 id="平台演进"><a href="#平台演进" class="headerlink" title="平台演进"></a>平台演进</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060416.jpg" alt=""></p><p>在实时计算平台建设过程中，主要是跟进开源社区发展以及实际业务需求，计算框架经历了 Storm 到 Spark Streaming 到 Flink 的发展，同时建设一站式实时计算平台，旨在提升用户实时计算需求开发上线管理监控效率，优化平台管理。</p><p>实时计算引擎前期基于 Storm 和 Spark Streaming 构建, 很多情况下并不能很好的满足业务需求，如商业部门基于 Spark Streaming 构建的特征平台希望将计算延迟由分钟级降低到秒级，提升用户体验，运维监控平台基于 Storm 分析公司全量 nginx 日志对线上业务进行监控，需要秒级甚至毫秒级别的延迟，Storm 的吞吐能力成为瓶颈。</p><p>同时随着实时需求不断增加，场景更加丰富，在追求任务高吞吐低延迟的基础上，对计算过程中间状态管理，灵活窗口支持，以及 exactly once 语义保障的诉求越来越多。Apache Flink 开源之后，支持高吞吐低延迟的架构设计以及高可用的稳定性，同时拥有实时计算场景一系列特性以及支持实时 Sql 模型，使我们决定采用 Flink 作为新一代实时计算平台的计算引擎。</p><h3 id="平台规模"><a href="#平台规模" class="headerlink" title="平台规模"></a>平台规模</h3><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060445.jpg" alt=""></p><p>实时计算平台当前主要基于 Storm/Spark Streaming/Flink，集群共计 500 多台机器，每天处理数据量 6000 亿 +，其中 Flink 经过近一年的建设，任务占比已经达到 50%。</p><h3 id="Flink-稳定性"><a href="#Flink-稳定性" class="headerlink" title="Flink 稳定性"></a>Flink 稳定性</h3><p>Flink 作为实时计算集群，可用性要求远高于离线计算集群。为保障集群可用性，平台主要采用任务隔离以及高可用集群架构保障稳定性。</p><h4 id="任务隔离"><a href="#任务隔离" class="headerlink" title="任务隔离"></a>任务隔离</h4><p>在应用层面主要基于业务线以及场景进行机器隔离，队列资源分配管理，避免集群抖动造成全局影响。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060523.jpg" alt=""></p><h4 id="集群架构"><a href="#集群架构" class="headerlink" title="集群架构"></a>集群架构</h4><p>Flink 集群采用了 ON YARN 模式独立部署，为减少集群维护工作量，底层 HDFS 利用公司统一 HDFS Federation 架构下建立独立的 namespace，减少 Flink 任务在 checkpoint 采用 hdfs/rocksdb 作为状态存储后端场景下由于 hdfs 抖动出现频繁异常失败。</p><p>在资源隔离层面，引入 Node Label 机制实现重要任务运行在独立机器，不同计算性质任务运行在合适的机器下，最大化机器资源的利用率。同时在 YARN 资源隔离基础上增加 Cgroup 进行物理 cpu 隔离，减少任务间抢占影响，保障任务运行稳定性。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060546.jpg" alt=""></p><h3 id="平台化管理"><a href="#平台化管理" class="headerlink" title="平台化管理"></a>平台化管理</h3><p>Wstream 是一套基于 Apache Flink 构建的一站式、高性能实时大数据处理平台。提供 SQL 化流式数据分析能力，大幅降低数据实时分析门槛，支持通过 DDL 实现 source/sink 以及维表，支持 UDF/UDAF/UDTF，为用户提供更强大的数据实时处理能力。支持多样式应用构建方式 FlinkJar/Stream SQL/Flink-Storm，以满足不同用户的开发需求，同时通过调试，监控，诊断，探查结果等辅助手段完善任务生命周期管理。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060608.jpg" alt=""></p><p>###<br>流式 sql 能力建设<br>Stream SQL 是平台为了打造 sql 化实时计算能力，减小实时计算开发门槛，基于开源的 Flink，对底层 sql 模块进行扩展实现以下功能：</p><ul><li>支持自定义 DDL 语法（包括源表, 输出表, 维表）</li><li>支持自定义 UDF/UDTF/UDAF 语法</li><li>实现了流与维表的 join, 双流 join</li></ul><p>在支持大数据开源组件的同时，也打通了公司主流的实时存储平台。同时为用户提供基于 Sql client 的 cli 方式以及在 Wstream 集成了对实时 sql 能力的支持，为用户提供在线开发调试 sql 任务的编辑器，同时支持代码高亮，智能提示，语法校验及运行时校验，尽可能避免用户提交到集群的任务出现异常。</p><p>另外也为用户提供了向导化配置方式，解决用户定义 table 需要了解复杂的参数设置，用户只需关心业务逻辑处理，像开发离线 Hive 一样使用 sql 开发实时任务。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060642.jpg" alt=""></p><h3 id="Storm-任务迁移-Flink"><a href="#Storm-任务迁移-Flink" class="headerlink" title="Storm 任务迁移 Flink"></a>Storm 任务迁移 Flink</h3><p>在完善 Flink 平台建设的同时，我们也启动 Storm 任务迁移 Flink 计划，旨在提升实时计算平台整体效率，减少机器成本和运维成本。Flink-Storm 作为官方提供 Flink 兼容 Storm 程序为我们实现无缝迁移提供了可行性，但是作为 beta 版本，在实际使用过程中存在很多无法满足现实场景的情况，因此我们进行了大量改进，主要包括实现 Storm 任务 on yarn ，迁移之后任务 at least once 语义保障，兼容 Storm 的 tick tuple 机制等等。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060703.jpg" alt=""></p><p>通过对 Fink-Storm 的优化，在无需用户修改代码的基础上，我们已经顺利完成多个 Storm 版本集群任务迁移和集群下线，在保障实时性及吞吐量的基础上可以节约计算资源 40% 以上，同时借助 yarn 统一管理实时计算平台无需维护多套 Storm 集群，整体提升了平台资源利用率，减轻平台运维工作量。</p><h3 id="任务诊断"><a href="#任务诊断" class="headerlink" title="任务诊断"></a>任务诊断</h3><h4 id="指标监控"><a href="#指标监控" class="headerlink" title="指标监控"></a>指标监控</h4><p>Flink webUI 提供了大量的运行时信息供用户了解任务当前运行状况，但是存在无法获取历史 metrics 的问题导致用户无法了解任务历史运行状态，因此我们采用了 Flink 原生支持的 Prometheus 进行实时指标采集和存储。</p><p>Prometheus 是一个开源的监控和报警系统，通过 pushgateway 的方式实时上报 metrics，Prometheus 集群采用 Fedration 部署模式，meta 节点定时抓取所有子节点指标进行汇总，方便统一数据源提供给 Grafana 进行可视化以及告警配置。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060730.jpg" alt=""></p><h4 id="任务延迟"><a href="#任务延迟" class="headerlink" title="任务延迟"></a>任务延迟</h4><p>吞吐能力和延迟作为衡量实时任务性能最重要的指标，我们经常需要通过这两个指标来调整任务并发度和资源配置。Flink Metrics 提供 latencyTrackingInterval 参数启用任务延迟跟踪，打开会显著影响集群和任务性能，官方高度建议只在 debug 下使用。</p><p>在实践场景下，Flink 任务数据源基本都是 Kafka，因此我们采用 topic 消费堆积作为衡量任务延迟的指标，监控模块实时通过 Flink rest 获取任务正在消费 topic 的 offset，同时通过 Kafka JMX 获取对应 topic 的 logsize，采用 logsize– offset 作为 topic 的堆积。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060754.jpg" alt=""></p><h4 id="日志检索"><a href="#日志检索" class="headerlink" title="日志检索"></a>日志检索</h4><p>Flink 作为分布式计算引擎，所有任务会由 YARN 统一调度到任意的计算节点，因此任务的运行日志会分布在不同的机器，用户定位日志困难。我们通过调整 log4j 日志框架默认机制，按天切分任务日志，定期清理过期日志，避免异常任务频繁写满磁盘导致计算节点不可用的情况，同时在所有计算节点部署 agent 实时采集日志，汇聚写入 Kafka，通过日志分发平台实时将数据分发到 ES，方便用户进行日志检索和定位问题。</p><h3 id="Flink-优化"><a href="#Flink-优化" class="headerlink" title="Flink 优化"></a>Flink 优化</h3><p>在实际使用过程中，我们也针对业务场景进行了一些优化和扩展，主要包括：</p><p>1）Storm 任务需要 Storm 引擎提供 ack 机制保障消息传递 at least once 语义，迁移到 Flink 无法使用 ack 机制，我们通过定制 KafakSpout 实现 checkpoint 相关接口，通过 Flink checkpoint 机制实现消息传递不丢失。另外 Flink-Storm 默认只能支持 standalone 的提交方式，我们通过实现 yarn client 相关接口增加了 storm on yarn 的支持。</p><p>2）Flink 1.6 推荐的是一个 TaskManager 对应一个 slot 的使用方式，在申请资源的时候根据最大并发度申请对应数量的 TaskManger，这样导致的问题就是在任务设置 task slots 之后需要申请的资源大于实际资源。</p><p>我们通过在 ResoureManager 请求资源管理器 SlotManager 的时候增加 TaskManagerSlot 相关信息，用于维护申请到的待分配 TaskManager 和 slot，之后对于 SlotRequests 请求不是直接申请 TaskManager，而是先从 SlotManager 申请是否有足够 slot，没有才会启动新的 TaskManger, 这样就实现了申请资源等于实际消耗资源，避免任务在资源足够的情况下无法启动。</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2020-01-11-060824.jpg" alt=""></p><p>3）Kafak Connector 改造，增加自动换行支持，另外针对 08source 无法设置 client.id，通过将 client.id 生成机制优化成更有标识意义的 id，便于 Kafka 层面管控。</p><p>4）Flink 提交任务无法支持第三方依赖 jar 包和配置文件供 TaskManager 使用，我们通过修改 flink 启动脚本，增加相关参数支持外部传输文件，之后在任务启动过程中通过将对应的 jar 包和文件加入 classpath，借助 yarn 的文件管理机制实现类似 spark 对应的使用方式，方便用户使用。</p><p>5）业务场景存在大量实时写入 hdfs 需求，Flink 自带 BucketingSink 默认只支持 string 和 avro 格式，我们在此基础上同时支持了 LZO 及 Parquet 格式写入，极大提升数据写入性能。</p><h3 id="后续规划"><a href="#后续规划" class="headerlink" title="后续规划"></a>后续规划</h3><p>实时计算平台当前正在进行 Storm 任务迁移 Flink 集群，目前已经基本完成，大幅提升了平台资源利用率和计算效率。后续将继续调研完善 Flink 相关能力，推动 Flink 在更多的实时场景下的应用，包括实时规则引擎，实时机器学习等。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>GitHub Flink 学习代码地址：<a href="https://github.com/zhisheng17/flink-learning">https://github.com/zhisheng17/flink-learning</a></p><p>微信公众号：<strong>zhisheng</strong></p><p>另外我自己整理了些 Flink 的学习资料，目前已经全部放到微信公众号（zhisheng）了，你可以回复关键字：<strong>Flink</strong> 即可无条件获取到。另外也可以加我微信 你可以加我的微信：<strong>yuanblog_tzs</strong>，探讨技术！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-17-143454.jpg" alt=""></p><p>更多私密资料请加入知识星球！</p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-09-25-zsxq.jpg" alt=""></p><h3 id="专栏介绍"><a href="#专栏介绍" class="headerlink" title="专栏介绍"></a>专栏介绍</h3><p>首发地址：<a href="http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/">http://www.54tianzhisheng.cn/2019/11/15/flink-in-action/</a></p><p>专栏地址：<a href="https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f">https://gitbook.cn/gitchat/column/5dad4a20669f843a1a37cb4f</a></p><h3 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h3><p>1、<a href="http://www.54tianzhisheng.cn/2018/10/13/flink-introduction/">Flink 从0到1学习 —— Apache Flink 介绍</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2018/09/18/flink-install">Flink 从0到1学习 —— Mac 上搭建 Flink 1.6.0 环境并构建运行简单程序入门</a></p><p>3、<a href="http://www.54tianzhisheng.cn/2018/10/27/flink-config/">Flink 从0到1学习 —— Flink 配置文件详解</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2018/10/28/flink-sources/">Flink 从0到1学习 —— Data Source 介绍</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2018/10/30/flink-create-source/">Flink 从0到1学习 —— 如何自定义 Data Source ？</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2018/10/29/flink-sink/">Flink 从0到1学习 —— Data Sink 介绍</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2018/10/31/flink-create-sink/">Flink 从0到1学习 —— 如何自定义 Data Sink ？</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2018/11/04/Flink-Data-transformation/">Flink 从0到1学习 —— Flink Data transformation(转换)</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2018/12/08/Flink-Stream-Windows/">Flink 从0到1学习 —— 介绍 Flink 中的 Stream Windows</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2018/12/11/Flink-time/">Flink 从0到1学习 —— Flink 中的几种 Time 详解</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2018/12/30/Flink-ElasticSearch-Sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 ElasticSearch</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/01/05/Flink-run/">Flink 从0到1学习 —— Flink 项目如何运行？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/01/06/Flink-Kafka-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Kafka</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/01/13/Flink-JobManager-High-availability/">Flink 从0到1学习 —— Flink JobManager 高可用性配置</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/01/14/Flink-parallelism-slot/">Flink 从0到1学习 —— Flink parallelism 和 Slot 介绍</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/01/15/Flink-MySQL-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据批量写入到 MySQL</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/01/20/Flink-RabbitMQ-sink/">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RabbitMQ</a></p><p>18、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HBase</a></p><p>19、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 HDFS</a></p><p>20、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Redis</a></p><p>21、<a href="https://t.zsxq.com/uVbi2nq">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Cassandra</a></p><p>22、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 Flume</a></p><p>23、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 InfluxDB</a></p><p>24、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— Flink 读取 Kafka 数据写入到 RocketMQ</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/03/13/flink-job-jars/">Flink 从0到1学习 —— 你上传的 jar 包藏到哪里去了</a></p><p>26、<a href="https://t.zsxq.com/zV7MnuJ">Flink 从0到1学习 —— 你的 Flink job 日志跑到哪里去了</a></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/02/28/blink/">阿里巴巴开源的 Blink 实时计算框架真香</a></p><p>28、<a href="http://www.54tianzhisheng.cn/2019/03/28/flink-additional-data/">Flink 从0到1学习 —— Flink 中如何管理配置？</a></p><p>29、<a href="http://www.54tianzhisheng.cn/2019/06/12/flink-split/">Flink 从0到1学习—— Flink 不可以连续 Split(分流)？</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/06/13/flink-book-paper/">Flink 从0到1学习—— 分享四本 Flink 国外的书和二十多篇 Paper 论文</a></p><p>31、<a href="http://www.54tianzhisheng.cn/2019/06/14/flink-architecture-deploy-test/">Flink 架构、原理与部署测试</a></p><p>32、<a href="http://www.54tianzhisheng.cn/2019/06/15/Stream-processing/">为什么说流处理即未来？</a></p><p>33、<a href="http://www.54tianzhisheng.cn/2019/06/16/flink-sql-oppo/">OPPO 数据中台之基石：基于 Flink SQL 构建实时数据仓库</a></p><p>34、<a href="http://www.54tianzhisheng.cn/2019/06/17/flink-vs-storm/">流计算框架 Flink 与 Storm 的性能对比</a></p><p>35、<a href="http://www.54tianzhisheng.cn/2019/06/18/flink-state/">Flink状态管理和容错机制介绍</a></p><p>36、<a href="http://www.54tianzhisheng.cn/2019/06/20/flink-kafka-Exactly-Once/">Apache Flink 结合 Kafka 构建端到端的 Exactly-Once 处理</a></p><p>37、<a href="http://www.54tianzhisheng.cn/2019/06/21/flink-in-360/">360深度实践：Flink与Storm协议级对比</a></p><p>38、<a href="http://www.54tianzhisheng.cn/2019/06/26/flink-TensorFlow/">如何基于Flink+TensorFlow打造实时智能异常检测平台？只看这一篇就够了</a></p><p>39、<a href="http://www.54tianzhisheng.cn/2019/07/01/flink-1.9-preview/">Apache Flink 1.9 重大特性提前解读</a></p><p>40、<a href="http://www.54tianzhisheng.cn/2019/12/31/Flink-resources/">Flink 全网最全资源（视频、博客、PPT、入门、原理、实战、性能调优、源码解析、问答等持续更新）</a></p><p>41、<a href="https://mp.weixin.qq.com/s/ok-YwuVbwAVtJz7hUCiZxg">Flink 灵魂两百问，这谁顶得住？</a></p><p>42、<a href="http://www.54tianzhisheng.cn/2019/08/18/flink-side-output/">Flink 从0到1学习 —— 如何使用 Side Output 来分流？</a></p><p>43、<a href="http://www.54tianzhisheng.cn/2019/08/06/flink-streaming-system/">你公司到底需不需要引入实时计算引擎？</a></p><p>44、<a href="http://www.54tianzhisheng.cn/2019/08/19/flink/">一文让你彻底了解大数据实时计算引擎 Flink</a></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1、<a href="http://www.54tianzhisheng.cn/2019/01/30/Flink-code-compile/">Flink 源码解析 —— 源码编译运行</a></p><p>2、<a href="http://www.54tianzhisheng.cn/2019/03/14/Flink-code-structure/">Flink 源码解析 —— 项目结构一览</a></p><p>3、<a href="http://www.54tianzhisheng.cn/tags/Flink/">Flink 源码解析—— local 模式启动流程</a></p><p>4、<a href="http://www.54tianzhisheng.cn/2019/03/15/Flink-code-Standalone-start/">Flink 源码解析 —— standalone session 模式启动流程</a></p><p>5、<a href="http://www.54tianzhisheng.cn/2019/03/16/Flink-code-Standalone-JobManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Job Manager 启动</a></p><p>6、<a href="http://www.54tianzhisheng.cn/2019/03/17/Flink-code-Standalone-TaskManager-start/">Flink 源码解析 —— Standalone Session Cluster 启动流程深度分析之 Task Manager 启动</a></p><p>7、<a href="http://www.54tianzhisheng.cn/2019/03/18/Flink-code-batch-wordcount-start/">Flink 源码解析 —— 分析 Batch WordCount 程序的执行过程</a></p><p>8、<a href="http://www.54tianzhisheng.cn/2019/03/19/Flink-code-streaming-wordcount-start/">Flink 源码解析 —— 分析 Streaming WordCount 程序的执行过程</a></p><p>9、<a href="http://www.54tianzhisheng.cn/2019/03/21/Flink-code-JobGraph/">Flink 源码解析 —— 如何获取 JobGraph？</a></p><p>10、<a href="http://www.54tianzhisheng.cn/2019/03/20/Flink-code-StreamGraph/">Flink 源码解析 —— 如何获取 StreamGraph？</a></p><p>11、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-jobmanager/">Flink 源码解析 —— Flink JobManager 有什么作用？</a></p><p>12、<a href="http://www.54tianzhisheng.cn/2019/03/25/Flink-code-taskmanager/">Flink 源码解析 —— Flink TaskManager 有什么作用？</a></p><p>13、<a href="http://www.54tianzhisheng.cn/2019/03/27/Flink-code-JobManager-submitJob/">Flink 源码解析 —— JobManager 处理 SubmitJob 的过程</a></p><p>14、<a href="http://www.54tianzhisheng.cn/2019/03/28/Flink-code-TaskManager-submitJob/">Flink 源码解析 —— TaskManager 处理 SubmitJob 的过程</a></p><p>15、<a href="http://www.54tianzhisheng.cn/2019/03/23/Flink-code-checkpoint/">Flink 源码解析 —— 深度解析 Flink Checkpoint 机制</a></p><p>16、<a href="http://www.54tianzhisheng.cn/2019/03/22/Flink-code-serialize/">Flink 源码解析 —— 深度解析 Flink 序列化机制</a></p><p>17、<a href="http://www.54tianzhisheng.cn/2019/03/24/Flink-code-memory-management/">Flink 源码解析 —— 深度解析 Flink 是如何管理好内存的？</a></p><p>18、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-core</a></p><p>19、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-datadog</a></p><p>20、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-dropwizard</a></p><p>21、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-graphite</a></p><p>22、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-influxdb</a></p><p>23、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-jmx</a></p><p>24、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-slf4j</a></p><p>25、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-statsd</a></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/02/Flink-code-metrics/">Flink Metrics 源码解析 —— Flink-metrics-prometheus</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-150037.jpg" alt=""></p><p>26、<a href="http://www.54tianzhisheng.cn/2019/07/03/Flink-code-Annotations/">Flink Annotations 源码解析</a></p><p><img src="http://zhisheng-blog.oss-cn-hangzhou.aliyuncs.com/img/2019-07-26-145923.jpg" alt=""></p><p>27、<a href="http://www.54tianzhisheng.cn/2019/03/26/Flink-code-ExecutionGraph/">Flink 源码解析 —— 如何获取 ExecutionGraph ？</a></p><p>28、<a href="https://t.zsxq.com/UvrRNJM">大数据重磅炸弹——实时计算框架 Flink</a></p><p>29、<a href="https://t.zsxq.com/QVFqjea">Flink Checkpoint-轻量级分布式快照</a></p><p>30、<a href="http://www.54tianzhisheng.cn/2019/07/04/Flink-code-clients/">Flink Clients 源码解析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;58 同城作为覆盖生活全领域的服务平台，业务覆盖招聘、房产、汽车、金融、二手及本地服务等各个方面。丰富的业务线和庞大的用户数每天产生海量用户数据需要实时化的计算分析，实时计算平台定位于为集团海量数据提供高效、稳定、分布式实时计算的基础服务。本文主要介绍 58 同城基于 Flink 打造的一站式实时计算平台 Wstream。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Flink" scheme="http://www.54tianzhisheng.cn/tags/Flink/"/>
    
      <category term="大数据" scheme="http://www.54tianzhisheng.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="流式计算" scheme="http://www.54tianzhisheng.cn/tags/%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
